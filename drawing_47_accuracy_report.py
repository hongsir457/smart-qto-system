#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾çº¸47è¯†åˆ«å‡†ç¡®æ€§ç»¼åˆåˆ†ææŠ¥å‘Š
"""

import psycopg2
import json
import re
from datetime import datetime

def generate_accuracy_report():
    """ç”Ÿæˆå›¾çº¸47è¯†åˆ«å‡†ç¡®æ€§åˆ†ææŠ¥å‘Š"""
    try:
        # è¿æ¥æ•°æ®åº“
        conn = psycopg2.connect(
            host="dbconn.sealoshzh.site",
            port=48982,
            database="postgres",
            user="postgres",
            password="2xn59xgm"
        )
        cursor = conn.cursor()
        
        # è·å–å›¾çº¸47çš„å®Œæ•´ä¿¡æ¯
        cursor.execute('''
            SELECT id, filename, file_path, recognition_results, ocr_results, 
                   created_at, updated_at, status
            FROM drawings WHERE id = 47
        ''')
        row = cursor.fetchone()
        
        if not row:
            print("æœªæ‰¾åˆ°å›¾çº¸47")
            return
        
        print("=" * 80)
        print("å›¾çº¸47è¯†åˆ«å‡†ç¡®æ€§ç»¼åˆåˆ†ææŠ¥å‘Š")
        print("=" * 80)
        print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"å›¾çº¸ID: {row[0]}")
        print(f"æ–‡ä»¶å: {row[1]}")
        print(f"åˆ›å»ºæ—¶é—´: {row[5]}")
        print(f"æ›´æ–°æ—¶é—´: {row[6]}")
        print(f"å¤„ç†çŠ¶æ€: {row[7]}")
        print()
        
        # 1. å›¾æ¡†è¯†åˆ«å‡†ç¡®æ€§åˆ†æ
        print("ğŸ“‹ 1. å›¾æ¡†è¯†åˆ«å‡†ç¡®æ€§åˆ†æ")
        print("-" * 50)
        
        # ä»æ–‡ä»¶ååˆ†æé¢„æœŸå†…å®¹
        filename = row[1]
        expected_title = "ä¸€å±‚æŸ±ç»“æ„æ”¹é€ åŠ å›ºå¹³é¢å›¾"
        
        print(f"é¢„æœŸå›¾å: {expected_title}")
        print(f"å®é™…æ–‡ä»¶å: {filename}")
        
        # åˆ†æOCRç»“æœ
        ocr_results = row[4]
        if ocr_results and 'text' in ocr_results and 'text' in ocr_results['text']:
            ocr_text = ocr_results['text']['text']
            
            # æ£€æŸ¥å›¾åè¯†åˆ«
            title_found = False
            title_keywords = ['ä¸€å±‚', 'æŸ±', 'ç»“æ„', 'æ”¹é€ ', 'åŠ å›º', 'å¹³é¢å›¾']
            found_keywords = []
            
            for keyword in title_keywords:
                if keyword in ocr_text:
                    found_keywords.append(keyword)
            
            print(f"å›¾åå…³é”®è¯è¯†åˆ«: {len(found_keywords)}/{len(title_keywords)}")
            print(f"å·²è¯†åˆ«å…³é”®è¯: {', '.join(found_keywords)}")
            print(f"æœªè¯†åˆ«å…³é”®è¯: {', '.join(set(title_keywords) - set(found_keywords))}")
            
            # æ£€æŸ¥æ¯”ä¾‹å°º
            scale_patterns = [r'1\s*:\s*\d+', r'æ¯”ä¾‹.*1.*:.*\d+']
            scale_found = False
            for pattern in scale_patterns:
                if re.search(pattern, ocr_text, re.IGNORECASE):
                    scale_found = True
                    break
            
            print(f"æ¯”ä¾‹å°ºè¯†åˆ«: {'âœ… å·²è¯†åˆ«' if scale_found else 'âŒ æœªè¯†åˆ«'}")
            
            # æ£€æŸ¥è®¾è®¡å•ä½
            company_found = 'SHANGHAI INSTALLATION ENGINEERING GROUP' in ocr_text
            print(f"è®¾è®¡å•ä½è¯†åˆ«: {'âœ… å·²è¯†åˆ«' if company_found else 'âŒ æœªè¯†åˆ«'}")
            
        else:
            print("âŒ OCRç»“æœä¸ºç©ºæˆ–æ ¼å¼å¼‚å¸¸")
        
        print()
        
        # 2. æ„ä»¶è¯†åˆ«å‡†ç¡®æ€§åˆ†æ
        print("ğŸ” 2. æ„ä»¶è¯†åˆ«å‡†ç¡®æ€§åˆ†æ")
        print("-" * 50)
        
        recognition_results = row[3]
        if recognition_results:
            # åˆ†æåŸå§‹è¯†åˆ«ç»“æœ
            if 'recognition' in recognition_results:
                original_results = recognition_results['recognition']
                print("åŸå§‹è¯†åˆ«ç»“æœ:")
                for component_type, data in original_results.items():
                    if isinstance(data, list):
                        count = len(data)
                    else:
                        count = data
                    print(f"  {component_type}: {count}ä¸ª")
            
            # åˆ†æè½¬æ¢åç»“æœ
            if 'converted' in recognition_results:
                converted_results = recognition_results['converted']
                total_components = sum(len(components) for components in converted_results.values())
                print(f"\nè½¬æ¢åæ„ä»¶æ€»æ•°: {total_components}ä¸ª")
                
                for component_type, components in converted_results.items():
                    if components:
                        print(f"  {component_type}: {len(components)}ä¸ª")
            
            # åˆ†æå·¥ç¨‹é‡è®¡ç®—ç»“æœ
            if 'quantities' in recognition_results:
                quantity_results = recognition_results['quantities']
                print(f"\nå·¥ç¨‹é‡è®¡ç®—ç»“æœ:")
                
                total_volume = 0
                for component_type, data in quantity_results.items():
                    if component_type != 'total' and isinstance(data, dict) and 'total_volume' in data:
                        volume = data['total_volume']
                        total_volume += volume
                        print(f"  {component_type}: {volume:.3f} mÂ³")
                
                if 'total' in quantity_results:
                    total_data = quantity_results['total']
                    if isinstance(total_data, dict) and 'volume' in total_data:
                        print(f"  æ€»ä½“ç§¯: {total_data['volume']:.3f} mÂ³")
                    else:
                        print(f"  æ€»ä½“ç§¯: {total_volume:.3f} mÂ³")
        
        print()
        
        # 3. å‡†ç¡®æ€§è¯„ä¼°
        print("ğŸ“Š 3. å‡†ç¡®æ€§è¯„ä¼°")
        print("-" * 50)
        
        # åŸºäºæ–‡ä»¶åçš„é¢„æœŸåˆ†æ
        print("åŸºäºæ–‡ä»¶åçš„é¢„æœŸåˆ†æ:")
        print("  - å›¾çº¸ç±»å‹: æŸ±ç»“æ„æ”¹é€ åŠ å›ºå¹³é¢å›¾")
        print("  - ä¸»è¦æ„ä»¶: åº”ä»¥æŸ±å­ä¸ºä¸»")
        print("  - æ¬¡è¦æ„ä»¶: å¯èƒ½åŒ…å«åŸºç¡€ã€å°‘é‡æ¢")
        print("  - ä¸åº”åŒ…å«: å¤§é‡å¢™ä½“ã€æ¿")
        
        print("\nå®é™…è¯†åˆ«ç»“æœè¯„ä¼°:")
        if recognition_results and 'recognition' in recognition_results:
            original_results = recognition_results['recognition']
            
            # æŸ±å­è¯†åˆ«è¯„ä¼° - ä¿®å¤æ•°æ®ç±»å‹é—®é¢˜
            columns_data = original_results.get('columns', [])
            walls_data = original_results.get('walls', [])
            beams_data = original_results.get('beams', [])
            foundations_data = original_results.get('foundations', [])
            slabs_data = original_results.get('slabs', [])
            
            # è·å–æ•°é‡
            columns = len(columns_data) if isinstance(columns_data, list) else columns_data
            walls = len(walls_data) if isinstance(walls_data, list) else walls_data
            beams = len(beams_data) if isinstance(beams_data, list) else beams_data
            foundations = len(foundations_data) if isinstance(foundations_data, list) else foundations_data
            slabs = len(slabs_data) if isinstance(slabs_data, list) else slabs_data
            
            print(f"  âœ… æŸ±å­è¯†åˆ«: {columns}ä¸ª (ç¬¦åˆé¢„æœŸ)")
            print(f"  âœ… åŸºç¡€è¯†åˆ«: {foundations}ä¸ª (ç¬¦åˆé¢„æœŸ)")
            
            if walls > columns * 2:
                print(f"  âš ï¸  å¢™ä½“è¯†åˆ«: {walls}ä¸ª (å¯èƒ½è¿‡å¤šï¼Œéœ€è¦éªŒè¯)")
            else:
                print(f"  âœ… å¢™ä½“è¯†åˆ«: {walls}ä¸ª (æ•°é‡åˆç†)")
            
            if beams > columns:
                print(f"  âš ï¸  æ¢è¯†åˆ«: {beams}ä¸ª (å¯èƒ½è¿‡å¤šï¼Œéœ€è¦éªŒè¯)")
            else:
                print(f"  âœ… æ¢è¯†åˆ«: {beams}ä¸ª (æ•°é‡åˆç†)")
            
            if slabs > 0:
                print(f"  âš ï¸  æ¿è¯†åˆ«: {slabs}ä¸ª (æŸ±åŠ å›ºå›¾ä¸åº”æœ‰æ¿)")
            else:
                print(f"  âœ… æ¿è¯†åˆ«: {slabs}ä¸ª (ç¬¦åˆé¢„æœŸ)")
        
        print()
        
        # 4. é—®é¢˜è¯†åˆ«å’Œå»ºè®®
        print("ğŸ”§ 4. é—®é¢˜è¯†åˆ«å’Œæ”¹è¿›å»ºè®®")
        print("-" * 50)
        
        issues = []
        suggestions = []
        
        # å›¾æ¡†è¯†åˆ«é—®é¢˜
        if not found_keywords or len(found_keywords) < len(title_keywords) * 0.7:
            issues.append("å›¾åè¯†åˆ«ä¸å®Œæ•´")
            suggestions.append("ä¼˜åŒ–OCRç®—æ³•ï¼Œæé«˜å¯¹å›¾çº¸æ ‡é¢˜çš„è¯†åˆ«å‡†ç¡®ç‡")
        
        if not scale_found:
            issues.append("æ¯”ä¾‹å°ºè¯†åˆ«å¤±è´¥")
            suggestions.append("å¢å¼ºæ¯”ä¾‹å°ºè¯†åˆ«æ¨¡å¼ï¼Œæ”¯æŒæ›´å¤šæ ¼å¼")
        
        # æ„ä»¶è¯†åˆ«é—®é¢˜
        if recognition_results and 'recognition' in recognition_results:
            original_results = recognition_results['recognition']
            walls_data = original_results.get('walls', [])
            columns_data = original_results.get('columns', [])
            
            walls = len(walls_data) if isinstance(walls_data, list) else walls_data
            columns = len(columns_data) if isinstance(columns_data, list) else columns_data
            
            if walls > columns * 3:
                issues.append("å¢™ä½“è¯†åˆ«æ•°é‡å¼‚å¸¸åé«˜")
                suggestions.append("æ£€æŸ¥æ„ä»¶åˆ†ç±»ç®—æ³•ï¼Œé¿å…å°†æŸ±å­è¯¯è¯†åˆ«ä¸ºå¢™ä½“")
        
        if issues:
            print("å‘ç°çš„é—®é¢˜:")
            for i, issue in enumerate(issues, 1):
                print(f"  {i}. {issue}")
            
            print("\næ”¹è¿›å»ºè®®:")
            for i, suggestion in enumerate(suggestions, 1):
                print(f"  {i}. {suggestion}")
        else:
            print("âœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼Œè¯†åˆ«ç»“æœåŸºæœ¬å‡†ç¡®")
        
        print()
        
        # 5. æ€»ä½“è¯„åˆ†
        print("â­ 5. æ€»ä½“è¯„åˆ†")
        print("-" * 50)
        
        # è®¡ç®—è¯„åˆ†
        frame_score = 0
        if found_keywords:
            frame_score += (len(found_keywords) / len(title_keywords)) * 30
        if scale_found:
            frame_score += 10
        if company_found:
            frame_score += 10
        
        component_score = 0
        if recognition_results and 'recognition' in recognition_results:
            original_results = recognition_results['recognition']
            columns_data = original_results.get('columns', [])
            walls_data = original_results.get('walls', [])
            
            columns = len(columns_data) if isinstance(columns_data, list) else columns_data
            walls = len(walls_data) if isinstance(walls_data, list) else walls_data
            
            # æŸ±å­è¯†åˆ«å¾—åˆ†
            if columns > 0:
                component_score += 20
            
            # æ„ä»¶æ¯”ä¾‹åˆç†æ€§å¾—åˆ†
            if walls <= columns * 3:
                component_score += 15
            
            # å·¥ç¨‹é‡è®¡ç®—å¾—åˆ†
            if 'quantities' in recognition_results:
                component_score += 15
        
        total_score = frame_score + component_score
        
        print(f"å›¾æ¡†è¯†åˆ«å¾—åˆ†: {frame_score:.1f}/50")
        print(f"æ„ä»¶è¯†åˆ«å¾—åˆ†: {component_score:.1f}/50")
        print(f"æ€»ä½“å¾—åˆ†: {total_score:.1f}/100")
        
        if total_score >= 80:
            grade = "ä¼˜ç§€"
        elif total_score >= 70:
            grade = "è‰¯å¥½"
        elif total_score >= 60:
            grade = "åŠæ ¼"
        else:
            grade = "éœ€è¦æ”¹è¿›"
        
        print(f"è¯„çº§: {grade}")
        
        conn.close()
        
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    generate_accuracy_report() 