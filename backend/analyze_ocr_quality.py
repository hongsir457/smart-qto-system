#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCRè´¨é‡åˆ†æå·¥å…·
åˆ†æOCRè¯†åˆ«ç»“æœçš„å‡†ç¡®æ€§ã€å®Œæ•´æ€§å’Œå¯ç”¨æ€§
"""

import sys
import os
import re
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from app.services.drawing import extract_text

def analyze_ocr_quality(image_path, expected_keywords=None):
    """
    åˆ†æOCRè¯†åˆ«è´¨é‡
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        expected_keywords: æœŸæœ›è¯†åˆ«çš„å…³é”®è¯åˆ—è¡¨
    """
    print("ğŸ” OCRè´¨é‡åˆ†æå·¥å…·")
    print("=" * 80)
    print(f"ğŸ“ åˆ†æå›¾ç‰‡: {image_path}")
    print("=" * 80)
    
    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    # æ‰§è¡ŒOCRè¯†åˆ«
    print("\nğŸ”§ æ‰§è¡ŒOCRè¯†åˆ«...")
    start_time = time.time()
    
    try:
        result = extract_text(image_path)
        processing_time = time.time() - start_time
        
        # é€‚é…extract_textçš„è¿”å›æ ¼å¼
        if result and isinstance(result, dict):
            if "text" in result:
                # æˆåŠŸè¯†åˆ«
                text = result.get('text', '')
                print(f"âœ… OCRè¯†åˆ«æˆåŠŸ")
                print(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
                print(f"ğŸ“ è¯†åˆ«å­—ç¬¦æ•°: {len(text)} å­—ç¬¦")
                
                # åˆ†æè¯†åˆ«è´¨é‡
                analyze_text_quality(text, expected_keywords)
                
            elif "error" in result:
                # è¯†åˆ«å¤±è´¥
                print(f"âŒ OCRè¯†åˆ«å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
            elif "warning" in result:
                # æœ‰è­¦å‘Šä½†å¯èƒ½æœ‰éƒ¨åˆ†ç»“æœ
                print(f"âš ï¸ OCRè¯†åˆ«è­¦å‘Š: {result.get('warning', 'æœªçŸ¥è­¦å‘Š')}")
                text = result.get('text', '')
                if text:
                    analyze_text_quality(text, expected_keywords)
                    
        else:
            print(f"âŒ OCRè¯†åˆ«è¿”å›æ ¼å¼å¼‚å¸¸: {type(result)}")
            
    except Exception as e:
        print(f"âŒ OCRè¯†åˆ«å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()

def analyze_text_quality(text, expected_keywords=None):
    """åˆ†ææ–‡æœ¬è´¨é‡"""
    print("\nğŸ“Š æ–‡æœ¬è´¨é‡åˆ†æ")
    print("-" * 50)
    
    # 1. åŸºæœ¬ç»Ÿè®¡
    lines = text.split('\n')
    non_empty_lines = [line.strip() for line in lines if line.strip()]
    
    print(f"ğŸ“„ æ€»è¡Œæ•°: {len(lines)}")
    print(f"ğŸ“ éç©ºè¡Œæ•°: {len(non_empty_lines)}")
    print(f"ğŸ“Š å¹³å‡è¡Œé•¿åº¦: {sum(len(line) for line in non_empty_lines) / len(non_empty_lines) if non_empty_lines else 0:.1f} å­—ç¬¦")
    
    # 2. æ•°å­—è¯†åˆ«åˆ†æ
    numbers = re.findall(r'\d+', text)
    dimensions = re.findall(r'\d+\s*[xXÃ—]\s*\d+', text)
    areas = re.findall(r'\d+\.?\d*\s*mÂ²', text)
    
    print(f"\nğŸ”¢ æ•°å­—è¯†åˆ«:")
    print(f"   - æ•°å­—æ€»æ•°: {len(numbers)}")
    print(f"   - å°ºå¯¸æ ‡æ³¨: {len(dimensions)} ä¸ª")
    print(f"   - é¢ç§¯æ ‡æ³¨: {len(areas)} ä¸ª")
    
    if dimensions:
        print(f"   - å°ºå¯¸ç¤ºä¾‹: {dimensions[:3]}")
    if areas:
        print(f"   - é¢ç§¯ç¤ºä¾‹: {areas[:3]}")
    
    # 3. å…³é”®è¯è¯†åˆ«åˆ†æ
    if expected_keywords:
        print(f"\nğŸ¯ å…³é”®è¯è¯†åˆ«åˆ†æ:")
        found_keywords = []
        missing_keywords = []
        
        for keyword in expected_keywords:
            if keyword.lower() in text.lower():
                found_keywords.append(keyword)
            else:
                missing_keywords.append(keyword)
        
        recognition_rate = len(found_keywords) / len(expected_keywords) * 100
        print(f"   - è¯†åˆ«ç‡: {recognition_rate:.1f}% ({len(found_keywords)}/{len(expected_keywords)})")
        
        if found_keywords:
            print(f"   - å·²è¯†åˆ«: {', '.join(found_keywords)}")
        if missing_keywords:
            print(f"   - æœªè¯†åˆ«: {', '.join(missing_keywords)}")
    
    # 4. æ–‡æœ¬è´¨é‡è¯„ä¼°
    print(f"\nğŸ“ˆ æ–‡æœ¬è´¨é‡è¯„ä¼°:")
    
    # è®¡ç®—å¯è¯»æ€§
    readable_chars = sum(1 for c in text if c.isalnum() or c.isspace() or c in '.,:-()[]{}')
    readability = readable_chars / len(text) * 100 if text else 0
    print(f"   - å¯è¯»æ€§: {readability:.1f}%")
    
    # è®¡ç®—ä¿¡æ¯å¯†åº¦
    info_density = len(non_empty_lines) / len(text) * 1000 if text else 0
    print(f"   - ä¿¡æ¯å¯†åº¦: {info_density:.2f} è¡Œ/åƒå­—ç¬¦")
    
    # 5. å¸¸è§é”™è¯¯åˆ†æ
    print(f"\nâš ï¸ å¸¸è§è¯†åˆ«é”™è¯¯:")
    
    # æ£€æŸ¥å¸¸è§OCRé”™è¯¯
    common_errors = {
        'Oå’Œ0æ··æ·†': len(re.findall(r'[A-Z]0|0[A-Z]', text)),
        'Iå’Œ1æ··æ·†': len(re.findall(r'[A-Z]1|1[A-Z]', text)),
        'ç‰¹æ®Šå­—ç¬¦é”™è¯¯': len(re.findall(r'[^\w\s\d.,:\-()[\]{}Ã—xXÂ²]', text)),
        'ç©ºæ ¼å¼‚å¸¸': len(re.findall(r'\s{3,}', text))
    }
    
    error_found = False
    for error_type, count in common_errors.items():
        if count > 0:
            print(f"   - {error_type}: {count} å¤„")
            error_found = True
    
    if not error_found:
        print("   - æœªå‘ç°æ˜æ˜¾é”™è¯¯")
    
    # 6. å»ºç­‘å›¾çº¸ç‰¹å®šåˆ†æ
    print(f"\nğŸ—ï¸ å»ºç­‘å›¾çº¸ç‰¹å®šåˆ†æ:")
    
    # æˆ¿é—´è¯†åˆ«
    room_keywords = ['room', 'kitchen', 'bathroom', 'bedroom', 'living', 'balcony']
    found_rooms = [kw for kw in room_keywords if kw.lower() in text.lower()]
    print(f"   - è¯†åˆ«æˆ¿é—´: {len(found_rooms)} ä¸ª ({', '.join(found_rooms)})")
    
    # ææ–™è§„æ ¼
    material_keywords = ['concrete', 'wall', 'floor', 'ceiling', 'thickness', 'mm']
    found_materials = [kw for kw in material_keywords if kw.lower() in text.lower()]
    print(f"   - ææ–™ä¿¡æ¯: {len(found_materials)} é¡¹")
    
    # å›¾çº¸ä¿¡æ¯
    drawing_keywords = ['scale', 'drawing', 'project', 'date', 'plan']
    found_drawing_info = [kw for kw in drawing_keywords if kw.lower() in text.lower()]
    print(f"   - å›¾çº¸ä¿¡æ¯: {len(found_drawing_info)} é¡¹")
    
    # 7. è´¨é‡è¯„åˆ†
    print(f"\nâ­ æ€»ä½“è´¨é‡è¯„åˆ†:")
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    keyword_score = len(found_keywords) / len(expected_keywords) * 100 if expected_keywords else 80
    content_score = min(100, len(non_empty_lines) * 5)  # æ¯è¡Œ5åˆ†ï¼Œæœ€é«˜100åˆ†
    readability_score = readability
    
    overall_score = (keyword_score * 0.4 + content_score * 0.3 + readability_score * 0.3)
    
    print(f"   - å…³é”®è¯è¯†åˆ«: {keyword_score:.1f}/100")
    print(f"   - å†…å®¹ä¸°å¯Œåº¦: {content_score:.1f}/100")
    print(f"   - æ–‡æœ¬å¯è¯»æ€§: {readability_score:.1f}/100")
    print(f"   - ç»¼åˆè¯„åˆ†: {overall_score:.1f}/100")
    
    # è¯„çº§
    if overall_score >= 90:
        grade = "ä¼˜ç§€ ğŸŒŸ"
    elif overall_score >= 80:
        grade = "è‰¯å¥½ ğŸ‘"
    elif overall_score >= 70:
        grade = "ä¸­ç­‰ ğŸ‘Œ"
    elif overall_score >= 60:
        grade = "åŠæ ¼ âœ…"
    else:
        grade = "éœ€æ”¹è¿› âš ï¸"
    
    print(f"   - è´¨é‡ç­‰çº§: {grade}")
    
    # 8. æ˜¾ç¤ºå®Œæ•´è¯†åˆ«ç»“æœ
    print(f"\nğŸ“‹ å®Œæ•´è¯†åˆ«ç»“æœ:")
    print("-" * 50)
    print(text)
    print("-" * 50)

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python analyze_ocr_quality.py <å›¾ç‰‡è·¯å¾„> [å…³é”®è¯1,å…³é”®è¯2,...]")
        print("ç¤ºä¾‹: python analyze_ocr_quality.py demo_building_plan.png")
        print("ç¤ºä¾‹: python analyze_ocr_quality.py complex_building_plan.png LIVING,KITCHEN,BEDROOM")
        return
    
    image_path = sys.argv[1]
    
    # è§£ææœŸæœ›å…³é”®è¯
    expected_keywords = None
    if len(sys.argv) > 2:
        expected_keywords = [kw.strip() for kw in sys.argv[2].split(',')]
    
    # é»˜è®¤å»ºç­‘å›¾çº¸å…³é”®è¯
    if not expected_keywords:
        expected_keywords = [
            'LIVING ROOM', 'KITCHEN', 'BEDROOM', 'BATHROOM', 
            'BALCONY', 'PLAN', 'SCALE', 'AREA', 'PROJECT'
        ]
    
    analyze_ocr_quality(image_path, expected_keywords)

if __name__ == "__main__":
    main() 