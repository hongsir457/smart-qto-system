#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Sealosè¯†åˆ«ç»“æœè°ƒè¯•æŸ¥çœ‹å·¥å…·
ç”¨äºæŸ¥çœ‹å’Œä¸‹è½½ä¿å­˜åœ¨Sealosä¸Šçš„ä¸€é˜¶æ®µè¯†åˆ«ç»“æœ
"""

import json
import os
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_sealos_config():
    """åŠ è½½Sealosé…ç½®"""
    from dotenv import load_dotenv
    load_dotenv('sealos_config.env')
    
    config = {
        "S3_ENDPOINT": os.getenv("S3_ENDPOINT"),
        "S3_ACCESS_KEY": os.getenv("S3_ACCESS_KEY"),
        "S3_SECRET_KEY": os.getenv("S3_SECRET_KEY"),
        "S3_BUCKET": os.getenv("S3_BUCKET"),
        "S3_REGION": os.getenv("S3_REGION", "us-east-1")
    }
    
    return config

def init_s3_service():
    """åˆå§‹åŒ–S3æœåŠ¡"""
    try:
        from app.services.s3_service import S3Service
        s3_service = S3Service()
        logger.info("âœ… S3æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        return s3_service
    except Exception as e:
        logger.error(f"âŒ S3æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def download_extraction_result(s3_service, s3_key: str, local_dir: str = "debug_downloads"):
    """
    ä»Sealosä¸‹è½½è¯†åˆ«ç»“æœæ–‡ä»¶
    
    Args:
        s3_service: S3æœåŠ¡å®ä¾‹
        s3_key: S3æ–‡ä»¶é”®
        local_dir: æœ¬åœ°ä¸‹è½½ç›®å½•
    """
    try:
        # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
        Path(local_dir).mkdir(exist_ok=True)
        
        # æå–æ–‡ä»¶å
        filename = Path(s3_key).name
        local_path = Path(local_dir) / filename
        
        # ä¸‹è½½æ–‡ä»¶
        success = s3_service.download_file(s3_key, str(local_path))
        
        if success:
            logger.info(f"âœ… æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {local_path}")
            return str(local_path)
        else:
            logger.error(f"âŒ æ–‡ä»¶ä¸‹è½½å¤±è´¥: {s3_key}")
            return None
            
    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}")
        return None

def analyze_extraction_result(file_path: str):
    """
    åˆ†æä¸‹è½½çš„è¯†åˆ«ç»“æœæ–‡ä»¶
    
    Args:
        file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"\nğŸ“„ åˆ†ææ–‡ä»¶: {Path(file_path).name}")
        print("=" * 60)
        
        # å…ƒä¿¡æ¯
        meta = data.get("meta", {})
        print(f"ğŸ†” è¯†åˆ«ID: {meta.get('extraction_id', 'N/A')}")
        print(f"â° è¯†åˆ«æ—¶é—´: {meta.get('extraction_time', 'N/A')}")
        print(f"ğŸ¯ é˜¶æ®µ: {meta.get('stage', 'N/A')}")
        print(f"ğŸ¤– AIæ¨¡å‹: {meta.get('ai_model', 'N/A')}")
        print(f"ğŸ–¼ï¸ æºå›¾ç‰‡: {meta.get('source_image', 'N/A')}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = data.get("statistics", {})
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  - è¯†åˆ«æ„ä»¶æ•°é‡: {stats.get('total_components', 0)}")
        print(f"  - æºæ–‡æœ¬æ•°é‡: {stats.get('source_texts', 0)}")
        print(f"  - æå–æ–¹æ³•: {stats.get('extraction_method', 'N/A')}")
        print(f"  - æ˜¯å¦æˆåŠŸ: {stats.get('success', False)}")
        
        # æ„ä»¶è¯¦æƒ…
        components = data.get("components", [])
        print(f"\nğŸ—ï¸ æ„ä»¶è¯¦æƒ… ({len(components)} ä¸ª):")
        
        for i, comp in enumerate(components, 1):
            print(f"  {i}. {comp.get('name', 'æœªçŸ¥æ„ä»¶')}")
            print(f"     ç¼–å·: {comp.get('component_id', 'N/A')}")
            print(f"     ç±»å‹: {comp.get('component_type', 'N/A')}")
            print(f"     å°ºå¯¸: {comp.get('dimensions', 'N/A')}")
            print(f"     ææ–™: {comp.get('material', 'N/A')}")
            print(f"     é…ç­‹: {comp.get('reinforcement', 'N/A')}")
            print(f"     ç½®ä¿¡åº¦: {comp.get('confidence', 0.0):.2f}")
            print(f"     æ¥æº: {comp.get('source', 'N/A')}")
            print()
        
        # è°ƒè¯•ä¿¡æ¯
        debug_info = data.get("debug_info", {})
        if debug_info:
            print(f"ğŸ”§ è°ƒè¯•ä¿¡æ¯:")
            for key, value in debug_info.items():
                print(f"  - {key}: {value}")
        
        return data
        
    except Exception as e:
        logger.error(f"âŒ æ–‡ä»¶åˆ†æå¤±è´¥: {e}")
        return None

def analyze_ocr_result(file_path: str):
    """
    åˆ†æä¸‹è½½çš„OCRåŸå§‹ç»“æœæ–‡ä»¶
    
    Args:
        file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"\nğŸ“– OCRç»“æœåˆ†æ: {Path(file_path).name}")
        print("=" * 60)
        
        # å…ƒä¿¡æ¯
        meta = data.get("meta", {})
        print(f"ğŸ†” OCR ID: {meta.get('ocr_id', 'N/A')}")
        print(f"â° è¯†åˆ«æ—¶é—´: {meta.get('ocr_time', 'N/A')}")
        print(f"ğŸ¯ é˜¶æ®µ: {meta.get('stage', 'N/A')}")
        print(f"ğŸ¤– OCRå¼•æ“: {meta.get('ocr_engine', 'N/A')}")
        print(f"ğŸ–¼ï¸ æºå›¾ç‰‡: {meta.get('source_image', 'N/A')}")
        
        # å¤„ç†ä¿¡æ¯
        processing = data.get("processing_info", {})
        print(f"\nâš™ï¸ å¤„ç†ä¿¡æ¯:")
        print(f"  çŠ¶æ€: {processing.get('status', 'N/A')}")
        print(f"  æ–‡æœ¬æ•°é‡: {processing.get('total_texts', 0)}")
        print(f"  å¤„ç†æ—¶é—´: {processing.get('processing_time', 0.0)}ç§’")
        print(f"  æ¨¡æ‹Ÿæ¨¡å¼: {processing.get('mock_mode', False)}")
        print(f"  å¼•æ“çŠ¶æ€: {processing.get('engine_status', 'N/A')}")
        
        # æ‘˜è¦ä¿¡æ¯
        summary = data.get("summary", {})
        print(f"\nğŸ“Š æ‘˜è¦ç»Ÿè®¡:")
        print(f"  æ–‡æœ¬æ€»æ•°: {summary.get('text_count', 0)}")
        print(f"  é«˜ç½®ä¿¡åº¦æ–‡æœ¬: {summary.get('high_confidence_count', 0)}")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {summary.get('average_confidence', 0.0):.3f}")
        print(f"  æ‰€æœ‰æ–‡æœ¬: {summary.get('all_text', 'N/A')}")
        
        # åŸå§‹æ–‡æœ¬è¯¦æƒ…
        raw_texts = data.get("raw_texts", [])
        print(f"\nğŸ“ è¯†åˆ«æ–‡æœ¬è¯¦æƒ… ({len(raw_texts)} ä¸ª):")
        
        for i, text_item in enumerate(raw_texts, 1):
            bbox = text_item.get("bbox", {})
            print(f"  {i}. \"{text_item.get('text', 'N/A')}\"")
            print(f"     â”œâ”€ ç½®ä¿¡åº¦: {text_item.get('confidence', 0.0):.3f}")
            print(f"     â”œâ”€ ä½ç½®: ({bbox.get('center_x', 0):.0f}, {bbox.get('center_y', 0):.0f})")
            print(f"     â”œâ”€ å°ºå¯¸: {bbox.get('width', 0):.0f}Ã—{bbox.get('height', 0):.0f}")
            print(f"     â””â”€ é¢ç§¯: {text_item.get('bbox_area', 0.0):.0f}åƒç´ Â²")
            print()
        
        # è¾¹ç•Œæ¡†åˆ†æ
        debug_info = data.get("debug_info", {})
        bbox_analysis = debug_info.get("bbox_analysis", {})
        if bbox_analysis:
            print(f"ğŸ”§ è¾¹ç•Œæ¡†åˆ†æ:")
            print(f"  è¾¹ç•Œæ¡†æ•°é‡: {bbox_analysis.get('bbox_count', 0)}")
            print(f"  æ€»é¢ç§¯: {bbox_analysis.get('total_area', 0.0):.0f}åƒç´ Â²")
            print(f"  å¹³å‡é¢ç§¯: {bbox_analysis.get('average_area', 0.0):.0f}åƒç´ Â²")
            print(f"  æœ€å¤§é¢ç§¯: {bbox_analysis.get('max_area', 0.0):.0f}åƒç´ Â²")
            print(f"  æœ€å°é¢ç§¯: {bbox_analysis.get('min_area', 0.0):.0f}åƒç´ Â²")
            print(f"  å¹³å‡æ–‡æœ¬é•¿åº¦: {bbox_analysis.get('average_text_length', 0.0):.1f}å­—ç¬¦")
            print(f"  æœ€é•¿æ–‡æœ¬: {bbox_analysis.get('longest_text', 0)}å­—ç¬¦")
        
        print(f"\nâœ… OCRç»“æœåˆ†æå®Œæˆï¼")
        print(f"ğŸ“ æœ¬åœ°æ–‡ä»¶è·¯å¾„: {file_path}")
        
        return data
        
    except Exception as e:
        logger.error(f"âŒ OCRç»“æœåˆ†æå¤±è´¥: {e}")
        return None

def view_recent_extraction_results(s3_service, limit: int = 5):
    """
    æŸ¥çœ‹æœ€è¿‘çš„è¯†åˆ«ç»“æœï¼ˆæ¨¡æ‹ŸåŠŸèƒ½ï¼‰
    
    Args:
        s3_service: S3æœåŠ¡å®ä¾‹
        limit: æ˜¾ç¤ºæ•°é‡é™åˆ¶
    """
    print(f"\nğŸ” æŸ¥çœ‹æœ€è¿‘ {limit} ä¸ªè¯†åˆ«ç»“æœ:")
    print("=" * 60)
    
    # æ„ä»¶æå–ç»“æœç¤ºä¾‹
    extraction_sample_keys = [
        "extraction_results/ef144f3f-2b92-4792-bd27-6bcbec9b2d41.json"
    ]
    
    # OCRåŸå§‹ç»“æœç¤ºä¾‹
    ocr_sample_keys = [
        "ocr_results/e36e0ccc-489e-42a2-804d-328e58f74b84.json"
    ]
    
    print("ğŸ’¡ æ‰‹åŠ¨æŸ¥çœ‹è¯†åˆ«ç»“æœ:")
    print("è¯·å°†å·²çŸ¥çš„S3é”®æ·»åŠ åˆ°ä¸‹é¢çš„åˆ—è¡¨ä¸­è¿›è¡ŒæŸ¥çœ‹")
    
    print(f"\nğŸ—ï¸ æ„ä»¶æå–ç»“æœ:")
    for i, key in enumerate(extraction_sample_keys, 1):
        print(f"   ğŸ“„ ç»“æœ {i}: {key}")
        
        # å°è¯•ä¸‹è½½å¹¶åˆ†æ
        local_file = download_extraction_result(s3_service, key)
        if local_file:
            analyze_extraction_result(local_file)
    
    print(f"\nğŸ“– OCRåŸå§‹ç»“æœ:")
    for i, key in enumerate(ocr_sample_keys, 1):
        print(f"   ğŸ“„ ç»“æœ {i}: {key}")
        
        # å°è¯•ä¸‹è½½å¹¶åˆ†æ
        local_file = download_extraction_result(s3_service, key)
        if local_file:
            analyze_ocr_result(local_file)

def interactive_debug_menu(s3_service):
    """äº¤äº’å¼è°ƒè¯•èœå•"""
    while True:
        print("\n" + "=" * 60)
        print("ğŸ”§ Sealosè¯†åˆ«ç»“æœè°ƒè¯•å·¥å…·")
        print("=" * 60)
        print("1. æŸ¥çœ‹æœ€è¿‘è¯†åˆ«ç»“æœ")
        print("2. ä¸‹è½½æŒ‡å®šS3é”®çš„ç»“æœ")
        print("3. åˆ†ææœ¬åœ°ç»“æœæ–‡ä»¶")
        print("4. åˆ†æOCRåŸå§‹ç»“æœæ–‡ä»¶")
        print("5. æ˜¾ç¤ºSealosé…ç½®")
        print("0. é€€å‡º")
        print("=" * 60)
        
        choice = input("è¯·é€‰æ‹©æ“ä½œ (0-5): ").strip()
        
        if choice == "0":
            print("ğŸ‘‹ é€€å‡ºè°ƒè¯•å·¥å…·")
            break
        elif choice == "1":
            view_recent_extraction_results(s3_service)
        elif choice == "2":
            s3_key = input("è¯·è¾“å…¥S3é”®: ").strip()
            if s3_key:
                local_file = download_extraction_result(s3_service, s3_key)
                if local_file:
                    analyze_extraction_result(local_file)
        elif choice == "3":
            file_path = input("è¯·è¾“å…¥æœ¬åœ°æ–‡ä»¶è·¯å¾„: ").strip()
            if file_path and Path(file_path).exists():
                analyze_extraction_result(file_path)
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        elif choice == "4":
            file_path = input("è¯·è¾“å…¥OCRç»“æœæ–‡ä»¶è·¯å¾„: ").strip()
            if file_path and Path(file_path).exists():
                analyze_ocr_result(file_path)
            else:
                print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        elif choice == "5":
            config = load_sealos_config()
            print("\nğŸ”§ Sealosé…ç½®:")
            for key, value in config.items():
                if "KEY" in key and value:
                    # éšè—æ•æ„Ÿä¿¡æ¯
                    display_value = value[:8] + "***" if len(value) > 8 else "***"
                else:
                    display_value = value
                print(f"  {key}: {display_value}")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨Sealosè¯†åˆ«ç»“æœè°ƒè¯•å·¥å…·")
    
    # åˆå§‹åŒ–S3æœåŠ¡
    s3_service = init_s3_service()
    if not s3_service:
        print("âŒ S3æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return
    
    # å¯åŠ¨äº¤äº’å¼èœå•
    interactive_debug_menu(s3_service)

if __name__ == "__main__":
    main() 