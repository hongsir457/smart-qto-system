"""
æµ‹è¯•ä¼˜åŒ–åçš„ç³»ç»Ÿ
éªŒè¯å„ä¸ªä¼˜åŒ–ç»„ä»¶çš„åŠŸèƒ½
"""

import asyncio
import os
import json
import time
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å¯¼å…¥ä¼˜åŒ–ç»„ä»¶
from app.services.adaptive_slicing_engine import AdaptiveSlicingEngine
from app.services.unified_ocr_pipeline import UnifiedOCRPipeline
from app.services.cross_modal_validation_engine import CrossModalValidationEngine
from app.services.intelligent_fusion_engine import IntelligentFusionEngine
from app.services.standardized_output_engine import StandardizedOutputEngine

class OptimizedSystemTester:
    """ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_output_dir = "test_optimized_output"
        os.makedirs(self.test_output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.adaptive_slicer = AdaptiveSlicingEngine()
        self.ocr_pipeline = UnifiedOCRPipeline()
        self.cross_modal_validator = CrossModalValidationEngine()
        self.fusion_engine = IntelligentFusionEngine()
        self.output_engine = StandardizedOutputEngine()
    
    async def run_complete_test(self, test_image_path: str = None):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        try:
            logger.info("ğŸš€ å¼€å§‹ä¼˜åŒ–ç³»ç»Ÿå®Œæ•´æµ‹è¯•")
            start_time = time.time()
            
            # ä½¿ç”¨æ¨¡æ‹Ÿå›¾ç‰‡è·¯å¾„
            if not test_image_path:
                test_image_path = self._create_mock_image()
            
            task_id = f"test_task_{int(time.time())}"
            
            # Step 1: è‡ªé€‚åº”åˆ‡ç‰‡æµ‹è¯•
            logger.info("=" * 60)
            logger.info("ğŸ”§ Step 1: è‡ªé€‚åº”åˆ‡ç‰‡å¼•æ“æµ‹è¯•")
            slice_result = await self.test_adaptive_slicing(test_image_path, task_id)
            
            if not slice_result["success"]:
                logger.error("âŒ è‡ªé€‚åº”åˆ‡ç‰‡æµ‹è¯•å¤±è´¥")
                return
            
            # Step 2~2.5: ç»Ÿä¸€OCRå¤„ç†æµ‹è¯•
            logger.info("=" * 60)
            logger.info("ğŸ”§ Step 2~2.5: ç»Ÿä¸€OCRå¤„ç†ç®¡é“æµ‹è¯•")
            ocr_result = await self.test_unified_ocr_pipeline(slice_result["slices"], task_id)
            
            if not ocr_result["success"]:
                logger.error("âŒ ç»Ÿä¸€OCRå¤„ç†æµ‹è¯•å¤±è´¥")
                return
            
            # Step 3~4: è·¨æ¨¡æ€éªŒè¯æµ‹è¯•
            logger.info("=" * 60)
            logger.info("ğŸ”§ Step 3~4: è·¨æ¨¡æ€éªŒè¯å¼•æ“æµ‹è¯•")
            validation_result = await self.test_cross_modal_validation(ocr_result, task_id)
            
            if not validation_result["success"]:
                logger.error("âŒ è·¨æ¨¡æ€éªŒè¯æµ‹è¯•å¤±è´¥")
                return
            
            # Step 5: æ™ºèƒ½èåˆæµ‹è¯•
            logger.info("=" * 60)
            logger.info("ğŸ”§ Step 5: æ™ºèƒ½èåˆå¼•æ“æµ‹è¯•")
            fusion_result = await self.test_intelligent_fusion(
                ocr_result, validation_result, task_id
            )
            
            if not fusion_result["success"]:
                logger.error("âŒ æ™ºèƒ½èåˆæµ‹è¯•å¤±è´¥")
                return
            
            # Step 6: æ ‡å‡†åŒ–è¾“å‡ºæµ‹è¯•
            logger.info("=" * 60)
            logger.info("ğŸ”§ Step 6: æ ‡å‡†åŒ–è¾“å‡ºå¼•æ“æµ‹è¯•")
            output_result = await self.test_standardized_output(fusion_result, task_id)
            
            if not output_result["success"]:
                logger.error("âŒ æ ‡å‡†åŒ–è¾“å‡ºæµ‹è¯•å¤±è´¥")
                return
            
            # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            total_time = time.time() - start_time
            await self.generate_test_report(task_id, {
                "slice_result": slice_result,
                "ocr_result": ocr_result,
                "validation_result": validation_result,
                "fusion_result": fusion_result,
                "output_result": output_result,
                "total_time": total_time
            })
            
            logger.info("=" * 60)
            logger.info(f"âœ… ä¼˜åŒ–ç³»ç»Ÿå®Œæ•´æµ‹è¯•æˆåŠŸå®Œæˆ! æ€»ç”¨æ—¶: {total_time:.2f}s")
            
        except Exception as e:
            logger.error(f"âŒ ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
    
    async def test_adaptive_slicing(self, image_path: str, task_id: str) -> dict:
        """æµ‹è¯•è‡ªé€‚åº”åˆ‡ç‰‡å¼•æ“"""
        try:
            logger.info("ğŸ”„ æµ‹è¯•è‡ªé€‚åº”åˆ‡ç‰‡å¼•æ“...")
            
            slice_output_dir = os.path.join(self.test_output_dir, f"{task_id}_slices")
            result = self.adaptive_slicer.adaptive_slice(image_path, slice_output_dir)
            
            if result["success"]:
                logger.info(f"âœ… è‡ªé€‚åº”åˆ‡ç‰‡æˆåŠŸ: ç”Ÿæˆ {result['slice_count']} ä¸ªåˆ‡ç‰‡")
                logger.info(f"ğŸ“Š åˆ‡ç‰‡ç­–ç•¥: {result['slice_strategy']['type']}")
                logger.info(f"ğŸ“ å›¾æ¡†æ£€æµ‹: {'æˆåŠŸ' if result['frame_detected'] else 'å¤±è´¥'}")
                logger.info(f"ğŸ“Š å†…å®¹å¯†åº¦: {result['content_density']['density_ratio']:.3f}")
            else:
                logger.error(f"âŒ è‡ªé€‚åº”åˆ‡ç‰‡å¤±è´¥: {result.get('error')}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ è‡ªé€‚åº”åˆ‡ç‰‡æµ‹è¯•å¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}
    
    async def test_unified_ocr_pipeline(self, slices: list, task_id: str) -> dict:
        """æµ‹è¯•ç»Ÿä¸€OCRå¤„ç†ç®¡é“"""
        try:
            logger.info("ğŸ”„ æµ‹è¯•ç»Ÿä¸€OCRå¤„ç†ç®¡é“...")
            
            # å‡†å¤‡åˆ‡ç‰‡ä¿¡æ¯
            slice_infos = []
            for i, slice_data in enumerate(slices[:5]):  # é™åˆ¶æµ‹è¯•5ä¸ªåˆ‡ç‰‡
                slice_infos.append({
                    "slice_id": slice_data.get("slice_id", f"slice_{i}"),
                    "filename": slice_data.get("filename", f"slice_{i}.png"),
                    "slice_path": slice_data.get("slice_path", "mock_path"),
                    "x_offset": slice_data.get("x_offset", 0),
                    "y_offset": slice_data.get("y_offset", 0),
                    "width": slice_data.get("width", 512),
                    "height": slice_data.get("height", 512)
                })
            
            result = await self.ocr_pipeline.process_slices(slice_infos, task_id)
            
            if result.stage == "unified_ocr_complete":
                logger.info(f"âœ… ç»Ÿä¸€OCRå¤„ç†æˆåŠŸ")
                logger.info(f"ğŸ“ è¯†åˆ«ç»“æœ: {len(result.slice_results)} ä¸ªåˆ‡ç‰‡")
                logger.info(f"ğŸ§¹ æ¸…æ´—æ•°æ®: {len(result.cleaned_data.component_labels)} ä¸ªæ„ä»¶æ ‡ç­¾")
                logger.info(f"ğŸ“Š è´¨é‡è¯„åˆ†: {result.quality_metrics['overall_quality']:.3f}")
                
                return {"success": True, "ocr_output": result}
            else:
                logger.error(f"âŒ ç»Ÿä¸€OCRå¤„ç†å¤±è´¥: {result.stage}")
                return {"success": False, "error": result.stage}
            
        except Exception as e:
            logger.error(f"âŒ ç»Ÿä¸€OCRå¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}
    
    async def test_cross_modal_validation(self, ocr_result: dict, task_id: str) -> dict:
        """æµ‹è¯•è·¨æ¨¡æ€éªŒè¯å¼•æ“"""
        try:
            logger.info("ğŸ”„ æµ‹è¯•è·¨æ¨¡æ€éªŒè¯å¼•æ“...")
            
            # æ¨¡æ‹ŸVisionç»“æœ
            mock_vision_output = {
                "detected_components": [
                    {
                        "label": "C1",
                        "type": "column",
                        "bbox": {"x": 100, "y": 100, "width": 50, "height": 50},
                        "confidence": 0.9
                    },
                    {
                        "label": "L1",
                        "type": "beam",
                        "bbox": {"x": 200, "y": 150, "width": 100, "height": 30},
                        "confidence": 0.85
                    }
                ]
            }
            
            # è½¬æ¢OCRç»“æœæ ¼å¼
            ocr_output_dict = {
                "slice_results": []
            }
            
            if hasattr(ocr_result["ocr_output"], "slice_results"):
                for result in ocr_result["ocr_output"].slice_results:
                    ocr_output_dict["slice_results"].append({
                        "slice_id": result.slice_id,
                        "raw_text": result.raw_text,
                        "coordinates": result.coordinates,
                        "confidence": result.confidence
                    })
            
            result = await self.cross_modal_validator.validate_cross_modal_results(
                ocr_output_dict, mock_vision_output, task_id
            )
            
            if result["success"]:
                report = result["validation_report"]
                metrics = report["overall_metrics"]
                
                logger.info(f"âœ… è·¨æ¨¡æ€éªŒè¯æˆåŠŸ")
                logger.info(f"ğŸ¯ å¯¹é½ç½®ä¿¡åº¦: {metrics['alignment_confidence']:.3f}")
                logger.info(f"ğŸ“ ç©ºé—´ä¸€è‡´æ€§: {metrics['spatial_consistency']:.3f}")
                logger.info(f"ğŸ”— åŒ¹é…å¯¹æ•°: {metrics['matched_pairs']}")
                logger.info(f"âœ… ä¸€è‡´æ€§ç‡: {metrics['consistency_rate']:.3f}")
            else:
                logger.error(f"âŒ è·¨æ¨¡æ€éªŒè¯å¤±è´¥: {result.get('error')}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ è·¨æ¨¡æ€éªŒè¯æµ‹è¯•å¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}
    
    async def test_intelligent_fusion(self, ocr_result: dict, validation_result: dict, task_id: str) -> dict:
        """æµ‹è¯•æ™ºèƒ½èåˆå¼•æ“"""
        try:
            logger.info("ğŸ”„ æµ‹è¯•æ™ºèƒ½èåˆå¼•æ“...")
            
            # å‡†å¤‡èåˆè¾“å…¥
            ocr_results_dict = {
                "slice_results": []
            }
            
            if hasattr(ocr_result["ocr_output"], "slice_results"):
                for result in ocr_result["ocr_output"].slice_results:
                    ocr_results_dict["slice_results"].append({
                        "slice_id": result.slice_id,
                        "raw_text": result.raw_text,
                        "coordinates": result.coordinates,
                        "confidence": result.confidence
                    })
            
            vision_results = {
                "detected_components": [
                    {
                        "label": "C1",
                        "type": "column",
                        "bbox": {"x": 100, "y": 100, "width": 50, "height": 50},
                        "confidence": 0.9
                    }
                ]
            }
            
            validation_report = validation_result.get("validation_report", {})
            
            result = await self.fusion_engine.fuse_multi_modal_results(
                ocr_results_dict, vision_results, validation_report, task_id
            )
            
            if result["success"]:
                report = result["fusion_report"]
                summary = report["fusion_summary"]
                metrics = report["quality_metrics"]
                
                logger.info(f"âœ… æ™ºèƒ½èåˆæˆåŠŸ")
                logger.info(f"ğŸ”§ èåˆå€™é€‰: {summary['total_candidates']}")
                logger.info(f"âš”ï¸ å†²çªç»„: {summary['conflict_groups']}")
                logger.info(f"ğŸ¯ èåˆæ„ä»¶: {summary['fused_components']}")
                logger.info(f"ğŸ“Š æ•´ä½“è´¨é‡: {metrics['overall_quality']:.3f}")
            else:
                logger.error(f"âŒ æ™ºèƒ½èåˆå¤±è´¥: {result.get('error')}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½èåˆæµ‹è¯•å¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}
    
    async def test_standardized_output(self, fusion_result: dict, task_id: str) -> dict:
        """æµ‹è¯•æ ‡å‡†åŒ–è¾“å‡ºå¼•æ“"""
        try:
            logger.info("ğŸ”„ æµ‹è¯•æ ‡å‡†åŒ–è¾“å‡ºå¼•æ“...")
            
            # å‡†å¤‡èåˆæ„ä»¶æ•°æ®
            fused_components = []
            if fusion_result["success"]:
                fusion_report = fusion_result["fusion_report"]
                for comp_data in fusion_report.get("fused_components", []):
                    fused_components.append({
                        "component_id": comp_data.get("component_id", "unknown"),
                        "type": comp_data.get("type", "unknown"),
                        "label": comp_data.get("label", ""),
                        "dimensions": comp_data.get("dimensions", {}),
                        "confidence": comp_data.get("confidence", 0.0)
                    })
            
            # å¦‚æœæ²¡æœ‰èåˆæ„ä»¶ï¼Œåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
            if not fused_components:
                fused_components = [
                    {
                        "component_id": "test_column_1",
                        "type": "column",
                        "label": "C1",
                        "dimensions": {"length": 0.4, "width": 0.4, "height": 3.0},
                        "confidence": 0.9
                    },
                    {
                        "component_id": "test_beam_1",
                        "type": "beam",
                        "label": "L1",
                        "dimensions": {"length": 6.0, "width": 0.3, "height": 0.5},
                        "confidence": 0.85
                    }
                ]
            
            project_info = {
                "project_name": "ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•é¡¹ç›®",
                "drawing_number": f"TEST-{task_id}",
                "scale": "1:100",
                "date": time.strftime("%Y-%m-%d")
            }
            
            result = await self.output_engine.generate_quantity_list(
                fused_components, project_info, task_id
            )
            
            if result["success"]:
                quantity_list = result["quantity_list"]
                total_summary = quantity_list["total_summary"]
                
                logger.info(f"âœ… æ ‡å‡†åŒ–è¾“å‡ºæˆåŠŸ")
                logger.info(f"ğŸ“Š æ€»æ„ä»¶æ•°: {total_summary['total_components']}")
                logger.info(f"âœ… åˆè§„æ„ä»¶: {total_summary['compliant_components']}")
                logger.info(f"ğŸ“ˆ åˆè§„ç‡: {total_summary['compliance_rate']:.3f}")
                logger.info(f"ğŸ—ï¸ æ„ä»¶ç±»å‹: {total_summary['component_types']}")
                
                # æµ‹è¯•å¤šæ ¼å¼å¯¼å‡º
                from dataclasses import asdict
                from app.services.standardized_output_engine import QuantityList
                
                # é‡å»ºQuantityListå¯¹è±¡ç”¨äºå¯¼å‡ºæµ‹è¯•
                export_test_result = await self._test_export_formats(quantity_list, task_id)
                result["export_test"] = export_test_result
                
            else:
                logger.error(f"âŒ æ ‡å‡†åŒ–è¾“å‡ºå¤±è´¥: {result.get('error')}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ ‡å‡†åŒ–è¾“å‡ºæµ‹è¯•å¼‚å¸¸: {e}")
            return {"success": False, "error": str(e)}
    
    async def _test_export_formats(self, quantity_list_dict: dict, task_id: str) -> dict:
        """æµ‹è¯•å¯¼å‡ºæ ¼å¼"""
        try:
            logger.info("ğŸ“¤ æµ‹è¯•å¤šæ ¼å¼å¯¼å‡º...")
            
            export_dir = os.path.join(self.test_output_dir, f"{task_id}_exports")
            os.makedirs(export_dir, exist_ok=True)
            
            # åˆ›å»ºç®€åŒ–çš„å¯¼å‡ºæµ‹è¯•
            export_results = {}
            
            # JSONå¯¼å‡ºæµ‹è¯•
            json_path = os.path.join(export_dir, f"{task_id}_quantity_list.json")
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(quantity_list_dict, f, ensure_ascii=False, indent=2)
            
            export_results["json"] = {
                "success": True,
                "file_path": json_path,
                "file_size": os.path.getsize(json_path)
            }
            
            logger.info(f"âœ… å¯¼å‡ºæµ‹è¯•å®Œæˆ: JSONæ ¼å¼")
            
            return {
                "success": True,
                "export_results": export_results
            }
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºæµ‹è¯•å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def _create_mock_image(self) -> str:
        """åˆ›å»ºæ¨¡æ‹Ÿå›¾ç‰‡æ–‡ä»¶"""
        mock_image_path = os.path.join(self.test_output_dir, "mock_drawing.png")
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿå›¾ç‰‡æ–‡ä»¶ï¼ˆå®é™…é¡¹ç›®ä¸­åº”è¯¥æœ‰çœŸå®å›¾ç‰‡ï¼‰
        try:
            from PIL import Image, ImageDraw
            
            # åˆ›å»º800x600çš„ç™½è‰²å›¾åƒ
            img = Image.new('RGB', (800, 600), 'white')
            draw = ImageDraw.Draw(img)
            
            # ç»˜åˆ¶ä¸€äº›ç®€å•çš„çŸ©å½¢ä½œä¸ºæ¨¡æ‹Ÿæ„ä»¶
            draw.rectangle([100, 100, 150, 400], outline='black', width=2)  # æŸ±å­
            draw.rectangle([50, 200, 200, 230], outline='black', width=2)   # æ¢
            
            # æ·»åŠ ä¸€äº›æ–‡å­—
            draw.text((160, 250), "C1", fill='black')
            draw.text((210, 210), "L1", fill='black')
            
            img.save(mock_image_path)
            logger.info(f"ğŸ“· åˆ›å»ºæ¨¡æ‹Ÿå›¾ç‰‡: {mock_image_path}")
            
        except ImportError:
            # å¦‚æœPILä¸å¯ç”¨ï¼Œåˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶
            with open(mock_image_path, 'w') as f:
                f.write("mock image file")
            logger.info(f"ğŸ“„ åˆ›å»ºæ¨¡æ‹Ÿå›¾ç‰‡æ–‡ä»¶: {mock_image_path}")
        
        return mock_image_path
    
    async def generate_test_report(self, task_id: str, test_results: dict):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        try:
            report = {
                "task_id": task_id,
                "test_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "total_time": test_results["total_time"],
                "test_summary": {
                    "adaptive_slicing": test_results["slice_result"]["success"],
                    "unified_ocr": test_results["ocr_result"]["success"],
                    "cross_modal_validation": test_results["validation_result"]["success"],
                    "intelligent_fusion": test_results["fusion_result"]["success"],
                    "standardized_output": test_results["output_result"]["success"]
                },
                "performance_metrics": {
                    "slice_count": test_results["slice_result"].get("slice_count", 0),
                    "ocr_quality": test_results["ocr_result"].get("ocr_output", {}).quality_metrics.get("overall_quality", 0) if hasattr(test_results["ocr_result"].get("ocr_output", {}), "quality_metrics") else 0,
                    "validation_consistency": test_results["validation_result"].get("validation_report", {}).get("overall_metrics", {}).get("consistency_rate", 0),
                    "fusion_quality": test_results["fusion_result"].get("fusion_report", {}).get("quality_metrics", {}).get("overall_quality", 0),
                    "output_compliance": test_results["output_result"].get("quantity_list", {}).get("total_summary", {}).get("compliance_rate", 0)
                },
                "optimization_benefits": {
                    "adaptive_slicing_efficiency": "æ˜¾è‘—æå‡åˆ‡ç‰‡é€‚åº”æ€§",
                    "unified_processing": "æ ‡å‡†åŒ–OCRå¤„ç†æµç¨‹",
                    "cross_modal_validation": "æé«˜è¯†åˆ«å‡†ç¡®æ€§",
                    "intelligent_fusion": "æ™ºèƒ½å†²çªè§£å†³",
                    "standardized_output": "è§„èŒƒåŒ–å·¥ç¨‹é‡è¾“å‡º"
                }
            }
            
            report_path = os.path.join(self.test_output_dir, f"{task_id}_test_report.json")
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“‹ æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
            # æ‰“å°å…³é”®æŒ‡æ ‡
            logger.info("=" * 60)
            logger.info("ğŸ“Š ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•å…³é”®æŒ‡æ ‡:")
            logger.info(f"   â±ï¸  æ€»ç”¨æ—¶: {test_results['total_time']:.2f}s")
            logger.info(f"   ğŸ”§ åˆ‡ç‰‡æ•°é‡: {report['performance_metrics']['slice_count']}")
            logger.info(f"   ğŸ“ OCRè´¨é‡: {report['performance_metrics']['ocr_quality']:.3f}")
            logger.info(f"   ğŸ¯ éªŒè¯ä¸€è‡´æ€§: {report['performance_metrics']['validation_consistency']:.3f}")
            logger.info(f"   ğŸ”— èåˆè´¨é‡: {report['performance_metrics']['fusion_quality']:.3f}")
            logger.info(f"   âœ… è¾“å‡ºåˆè§„ç‡: {report['performance_metrics']['output_compliance']:.3f}")
            logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•")
    
    tester = OptimizedSystemTester()
    await tester.run_complete_test()
    
    logger.info("ğŸ¯ ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main()) 