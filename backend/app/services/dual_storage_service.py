import asyncio
import json
import logging
from typing import Dict, Any, Optional, Union
from io import BytesIO
from pathlib import Path
import requests
import os

from .s3_service import S3Service
from .sealos_storage import SealosStorage

logger = logging.getLogger(__name__)

class DualStorageService:
    _instance = None
    _initialized = False

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(DualStorageService, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if DualStorageService._initialized:
            return
        DualStorageService._initialized = True
        self.s3_service = None
        self.sealos_service = None
        self.active_service = None
        
        try:
            self._initialize_services()
            logger.info("åŒé‡å­˜å‚¨æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"åŒé‡å­˜å‚¨æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")

    def is_available(self) -> bool:
        """åªè¦æœ‰ä¸€ä¸ªä¸»ç”¨å­˜å‚¨å¯ç”¨å°±è¿”å›Trueï¼Œå¹¶è¾“å‡ºè°ƒè¯•æ—¥å¿—"""
        logger = logging.getLogger(__name__)
        available = self.active_service is not None
        logger.info(f"[DualStorageService][is_available] called: active_service={type(self.active_service).__name__ if self.active_service else None}, result={available}")
        return available

    def _initialize_services(self):
        """åˆå§‹åŒ–åŒé‡å­˜å‚¨æœåŠ¡ï¼Œä¼˜å…ˆä½¿ç”¨S3"""
        logger = logging.getLogger(__name__)
        self.s3_service = S3Service()
        self.sealos_storage = SealosStorage()

        # æ£€æŸ¥S3é…ç½®å®Œæ•´æ€§
        s3_config_complete = all([
            self.s3_service.endpoint_url,
            self.s3_service.access_key,
            self.s3_service.secret_key,
            self.s3_service.bucket_name
        ])

        logger.info(f"[DualStorageService][_initialize_services] S3é…ç½®å®Œæ•´: {s3_config_complete}")
        logger.info(f"[DualStorageService][_initialize_services] S3 endpoint: {self.s3_service.endpoint_url}, bucket: {self.s3_service.bucket_name}")
        logger.info(f"[DualStorageService][_initialize_services] Sealos endpoint: {getattr(self.sealos_storage, 'endpoint_url', None)}")

        # ä¼˜å…ˆS3
        if s3_config_complete:
            try:
                logger.info("âœ… S3é…ç½®å®Œæ•´ï¼Œå°†S3ä½œä¸ºä¸»å­˜å‚¨ã€‚")
                self.primary_storage = self.s3_service
                self.active_service = self.s3_service
                self.fallback_storage = self.sealos_storage
                logger.info(f"[DualStorageService][_initialize_services] active_service set to S3Service")
            except Exception as e:
                logger.warning(f"âš ï¸ S3åˆå§‹åŒ–å¼‚å¸¸: {e}")
                self.primary_storage = None
        else:
            logger.warning("âš ï¸ S3é…ç½®ä¸å®Œæ•´ï¼Œå°†Sealoså­˜å‚¨ä½œä¸ºä¸»å­˜å‚¨ã€‚")
            self.primary_storage = self.sealos_storage
            self.active_service = self.sealos_storage
            self.fallback_storage = None
            logger.info(f"[DualStorageService][_initialize_services] active_service set to SealosStorage")

        # å¦‚æœS3å’ŒSealoséƒ½ä¸å¯ç”¨ï¼Œactive_serviceä¸ºNone
        if not self.active_service:
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„ä¸»ç”¨å­˜å‚¨ï¼Œactive_service=None")

        # æœ¬åœ°å­˜å‚¨è·¯å¾„
        self.local_storage_path = Path("storage/dual_storage_fallback")
        self.local_storage_path.mkdir(parents=True, exist_ok=True)
        logger.info(f"[DualStorageService][_initialize_services] æœ¬åœ°å­˜å‚¨è·¯å¾„: {self.local_storage_path}")
        
    def upload_file_sync(self, file_obj: Union[BytesIO, bytes], 
                        s3_key: str,
                        content_type: str = "application/octet-stream") -> Dict[str, Any]:
        """
        åŒæ­¥æ–‡ä»¶ä¸Šä¼ ï¼ˆä¸‰å±‚å­˜å‚¨ç­–ç•¥ï¼‰
        
        Args:
            file_obj: æ–‡ä»¶å¯¹è±¡æˆ–å­—èŠ‚æ•°æ®
            s3_key: å®Œæ•´çš„S3å­˜å‚¨é”® (åŒ…å«æ–‡ä»¶å¤¹è·¯å¾„)
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            ä¸Šä¼ ç»“æœä¿¡æ¯
        """
        storage_results = {
            "success": False,
            "primary_storage": None,
            "backup_storage": None,
            "final_url": None,
            "storage_method": None,
            "error": None
        }
        
        try:
            # ç¬¬ä¸€å±‚ï¼šS3Serviceä¸»å­˜å‚¨
            try:
                if isinstance(file_obj, bytes):
                    file_obj = BytesIO(file_obj)
                
                s3_result = self.s3_service.upload_file_sync(
                    file_obj=file_obj,
                    s3_key=s3_key,
                    content_type=content_type
                )
                
                storage_results["primary_storage"] = s3_result
                storage_results["final_url"] = s3_result.get("s3_url")
                storage_results["storage_method"] = "s3_primary"
                storage_results["success"] = True
                
                logger.info(f"âœ… S3ä¸»å­˜å‚¨ä¸Šä¼ æˆåŠŸ: {s3_key}")
                return storage_results
                
            except Exception as e:
                logger.warning(f"âš ï¸ S3ä¸»å­˜å‚¨ä¸Šä¼ å¤±è´¥: {e}")
                storage_results["error"] = f"S3ä¸»å­˜å‚¨å¤±è´¥: {e}"
            
            # ç¬¬äºŒå±‚ï¼šæœ¬åœ°å­˜å‚¨é™çº§
            try:
                # ä¸ºäº†æœ¬åœ°é™çº§ï¼Œéœ€è¦ä»s3_keyè§£ææ–‡ä»¶åå’Œæ–‡ä»¶å¤¹
                parts = s3_key.split('/')
                file_name = parts[-1]
                folder = '/'.join(parts[:-1]) if len(parts) > 1 else ""

                local_result = self._upload_to_local_sync(file_obj, file_name, folder)
                storage_results["backup_storage"] = local_result
                storage_results["final_url"] = local_result.get("local_url")
                storage_results["storage_method"] = "local_fallback"
                storage_results["success"] = True
                
                logger.info(f"âœ… æœ¬åœ°å­˜å‚¨é™çº§æˆåŠŸ: {s3_key}")
                return storage_results
                
            except Exception as e:
                logger.error(f"âŒ æœ¬åœ°å­˜å‚¨ä¹Ÿå¤±è´¥: {e}")
                storage_results["error"] += f"; æœ¬åœ°å­˜å‚¨å¤±è´¥: {e}"
            
            # æ‰€æœ‰å­˜å‚¨éƒ½å¤±è´¥
            storage_results["success"] = False
            raise Exception(f"æ‰€æœ‰å­˜å‚¨æ–¹å¼éƒ½å¤±è´¥: {storage_results['error']}")
            
        except Exception as e:
            logger.error(f"âŒ åŒé‡å­˜å‚¨ä¸Šä¼ å®Œå…¨å¤±è´¥: {e}")
            storage_results["error"] = str(e)
            return storage_results

    async def upload_file_async(self, file_data: bytes, 
                              file_path: str,
                              content_type: str = "application/octet-stream") -> str:
        """
        å¼‚æ­¥æ–‡ä»¶ä¸Šä¼ ï¼ˆä¸‰å±‚å­˜å‚¨ç­–ç•¥ï¼‰
        
        Args:
            file_data: æ–‡ä»¶æ•°æ®
            file_path: å­˜å‚¨è·¯å¾„
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            æ–‡ä»¶è®¿é—®URL
        """
        try:
            # ç¬¬ä¸€å±‚ï¼šS3Serviceä¸»å­˜å‚¨
            try:
                # ğŸ”§ ä¿®å¤ï¼šå°†bytesè½¬æ¢ä¸ºBytesIOå¯¹è±¡
                from io import BytesIO
                file_obj = BytesIO(file_data)
                
                # S3Serviceçš„upload_fileæ–¹æ³•æœŸæœ›æ–‡ä»¶å¯¹è±¡ï¼Œéœ€è¦åˆ†è§£è·¯å¾„
                import os
                folder, file_name = os.path.dirname(file_path), os.path.basename(file_path)
                if not folder:
                    folder = "drawings"  # é»˜è®¤æ–‡ä»¶å¤¹
                
                result = self.s3_service.upload_file(file_obj, file_name, content_type, folder)
                url = result.get("s3_url", "")
                logger.info(f"âœ… S3å¼‚æ­¥å­˜å‚¨ä¸Šä¼ æˆåŠŸ: {file_path}")
                return url
            except Exception as e:
                logger.warning(f"âš ï¸ S3å¼‚æ­¥å­˜å‚¨ä¸Šä¼ å¤±è´¥: {e}")
            
            # ç¬¬äºŒå±‚ï¼šSealoså¤‡ä»½å­˜å‚¨
            try:
                if hasattr(self, 'sealos_storage') and self.sealos_storage:
                    url = await self.sealos_storage.upload_file(file_data, file_path, content_type)
                    logger.info(f"âœ… Sealoså¤‡ä»½å­˜å‚¨ä¸Šä¼ æˆåŠŸ: {file_path}")
                    return url
                else:
                    logger.debug("Sealoså­˜å‚¨æœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡")
            except Exception as e:
                logger.warning(f"âš ï¸ Sealoså¤‡ä»½å­˜å‚¨ä¸Šä¼ å¤±è´¥: {e}")
            
            # ç¬¬ä¸‰å±‚ï¼šæœ¬åœ°å­˜å‚¨é™çº§
            try:
                url = await self._upload_to_local_async(file_data, file_path)
                logger.info(f"âœ… æœ¬åœ°å¼‚æ­¥å­˜å‚¨é™çº§æˆåŠŸ: {file_path}")
                return url
            except Exception as e:
                logger.error(f"âŒ æœ¬åœ°å¼‚æ­¥å­˜å‚¨ä¹Ÿå¤±è´¥: {e}")
            
            raise Exception("æ‰€æœ‰å¼‚æ­¥å­˜å‚¨æ–¹å¼éƒ½å¤±è´¥")
            
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥åŒé‡å­˜å‚¨ä¸Šä¼ å¤±è´¥: {e}")
            raise

    def upload_content_sync(self, content: str, 
                          s3_key: str,
                          content_type: str = "application/json") -> Dict[str, Any]:
        """
        åŒæ­¥å†…å®¹ä¸Šä¼ 
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            s3_key: å­˜å‚¨é”®
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            ä¸Šä¼ ç»“æœä¿¡æ¯
        """
        try:
            # è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
            content_bytes = content.encode('utf-8')
            file_obj = BytesIO(content_bytes)
            
            # ä¿®æ”¹ï¼šç›´æ¥è°ƒç”¨ï¼Œä¸å†æ‹†åˆ† s3_key
            return self.upload_file_sync(
                file_obj=file_obj,
                s3_key=s3_key,
                content_type=content_type
            )
            
        except Exception as e:
            logger.error(f"åŒæ­¥å†…å®¹ä¸Šä¼ å¤±è´¥: {e}")
            raise

    async def upload_content_async(self, content: str, 
                                 key: str,
                                 content_type: str = "application/json") -> str:
        """
        å¼‚æ­¥å†…å®¹ä¸Šä¼ 
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            key: å­˜å‚¨é”®
            content_type: å†…å®¹ç±»å‹
            
        Returns:
            æ–‡ä»¶è®¿é—®URL
        """
        try:
            content_bytes = content.encode('utf-8')
            return await self.upload_file_async(content_bytes, key, content_type)
        except Exception as e:
            logger.error(f"å¼‚æ­¥å†…å®¹ä¸Šä¼ å¤±è´¥: {e}")
            raise

    def _upload_to_local_sync(self, file_obj: Union[BytesIO, bytes], 
                            file_name: str, 
                            folder: str) -> Dict[str, Any]:
        """åŒæ­¥æœ¬åœ°å­˜å‚¨"""
        try:
            # åˆ›å»ºç›®å½•
            local_folder = self.local_storage_path / folder
            local_folder.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜æ–‡ä»¶
            file_path = local_folder / file_name
            
            if isinstance(file_obj, BytesIO):
                file_obj.seek(0)
                with open(file_path, 'wb') as f:
                    f.write(file_obj.read())
            elif isinstance(file_obj, bytes):
                with open(file_path, 'wb') as f:
                    f.write(file_obj)
            else:
                raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶å¯¹è±¡ç±»å‹")
            
            return {
                "local_path": str(file_path),
                "local_url": f"file://{file_path.absolute()}",
                "size": file_path.stat().st_size
            }
            
        except Exception as e:
            logger.error(f"æœ¬åœ°åŒæ­¥å­˜å‚¨å¤±è´¥: {e}")
            raise

    async def _upload_to_local_async(self, file_data: bytes, file_path: str) -> str:
        """å¼‚æ­¥æœ¬åœ°å­˜å‚¨"""
        try:
            # åˆ›å»ºå®Œæ•´è·¯å¾„
            full_path = self.local_storage_path / file_path
            full_path.parent.mkdir(parents=True, exist_ok=True)
            
            # å¼‚æ­¥å†™å…¥æ–‡ä»¶
            def write_file():
                with open(full_path, 'wb') as f:
                    f.write(file_data)
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œæ–‡ä»¶å†™å…¥
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, write_file)
            
            return f"file://{full_path.absolute()}"
            
        except Exception as e:
            logger.error(f"æœ¬åœ°å¼‚æ­¥å­˜å‚¨å¤±è´¥: {e}")
            raise

    def upload_txt_content(self, content: str, 
                         file_name: str, 
                         folder: str = "txt_content") -> Dict[str, Any]:
        """
        ä¸Šä¼ TXTæ–‡æœ¬å†…å®¹ï¼ˆåŒæ­¥ï¼‰
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            file_name: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            folder: å­˜å‚¨æ–‡ä»¶å¤¹
            
        Returns:
            ä¸Šä¼ ç»“æœä¿¡æ¯
        """
        try:
            # ç¡®ä¿æ–‡ä»¶åæœ‰.txtæ‰©å±•å
            if not file_name.endswith('.txt'):
                file_name += '.txt'
            
            return self.upload_content_sync(
                content=content,
                s3_key=f"{folder}/{file_name}",
                content_type="text/plain"
            )
            
        except Exception as e:
            logger.error(f"TXTå†…å®¹ä¸Šä¼ å¤±è´¥: {e}")
            raise

    async def upload_json_content_async(self, data: Dict[str, Any], 
                                      file_path: str) -> str:
        """
        å¼‚æ­¥ä¸Šä¼ JSONå†…å®¹
        
        Args:
            data: è¦åºåˆ—åŒ–çš„æ•°æ®
            file_path: å­˜å‚¨è·¯å¾„
            
        Returns:
            æ–‡ä»¶è®¿é—®URL
        """
        try:
            json_content = json.dumps(data, ensure_ascii=False, indent=2)
            return await self.upload_content_async(
                content=json_content,
                key=file_path,
                content_type="application/json"
            )
        except Exception as e:
            logger.error(f"JSONå†…å®¹å¼‚æ­¥ä¸Šä¼ å¤±è´¥: {e}")
            raise

    def get_storage_status(self) -> Dict[str, Any]:
        """è·å–å­˜å‚¨æœåŠ¡çŠ¶æ€"""
        status = {
            "s3_service_available": False,
            "s3_storage_available": False,
            "sealos_storage_available": False,
            "local_storage_available": False,
            "local_storage_path": str(self.local_storage_path)
        }
        
        try:
            # æ£€æŸ¥S3Service
            if hasattr(self.s3_service, 's3_client'):
                status["s3_service_available"] = True
        except:
            pass
        
        try:
            # æ£€æŸ¥æœ¬åœ°å­˜å‚¨
            if self.local_storage_path.exists():
                status["local_storage_available"] = True
        except:
            pass
        
        # å…¶ä»–å­˜å‚¨æœåŠ¡éœ€è¦å¼‚æ­¥æ£€æŸ¥
        status["note"] = "S3Storageå’ŒSealosStorageçŠ¶æ€éœ€è¦å¼‚æ­¥æ£€æŸ¥"
        
        return status

    def cleanup_local_storage(self, days_old: int = 7) -> Dict[str, Any]:
        """
        æ¸…ç†æœ¬åœ°å­˜å‚¨ä¸­çš„æ—§æ–‡ä»¶
        
        Args:
            days_old: æ¸…ç†å¤šå°‘å¤©å‰çš„æ–‡ä»¶
            
        Returns:
            æ¸…ç†ç»“æœç»Ÿè®¡
        """
        import time
        from datetime import datetime, timedelta
        
        cleanup_stats = {
            "files_checked": 0,
            "files_deleted": 0,
            "space_freed_mb": 0,
            "errors": []
        }
        
        try:
            cutoff_time = time.time() - (days_old * 24 * 60 * 60)
            
            for file_path in self.local_storage_path.rglob("*"):
                if file_path.is_file():
                    cleanup_stats["files_checked"] += 1
                    
                    try:
                        if file_path.stat().st_mtime < cutoff_time:
                            file_size = file_path.stat().st_size
                            file_path.unlink()
                            cleanup_stats["files_deleted"] += 1
                            cleanup_stats["space_freed_mb"] += file_size / (1024 * 1024)
                    except Exception as e:
                        cleanup_stats["errors"].append(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
            logger.info(f"æœ¬åœ°å­˜å‚¨æ¸…ç†å®Œæˆ: åˆ é™¤äº† {cleanup_stats['files_deleted']} ä¸ªæ–‡ä»¶, "
                       f"é‡Šæ”¾äº† {cleanup_stats['space_freed_mb']:.2f} MBç©ºé—´")
            
        except Exception as e:
            logger.error(f"æœ¬åœ°å­˜å‚¨æ¸…ç†å¤±è´¥: {e}")
            cleanup_stats["errors"].append(str(e))
        
        return cleanup_stats

    def download_file(self, s3_key: str, local_path: str) -> bool:
        """
        åŒé‡å­˜å‚¨æ–‡ä»¶ä¸‹è½½ï¼ˆåŒæ­¥ï¼‰
        å°è¯•ä»S3ã€Sealosã€æœ¬åœ°å­˜å‚¨ä¾æ¬¡ä¸‹è½½
        
        Args:
            s3_key: S3å­˜å‚¨é”®æˆ–URL
            local_path: æœ¬åœ°ä¿å­˜è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        try:
            logger.info(f"ğŸ”„ å¼€å§‹åŒé‡å­˜å‚¨ä¸‹è½½: {s3_key} â†’ {local_path}")
            
            # æ–¹æ³•1: å°è¯•ä»S3ä¸‹è½½
            try:
                logger.info("ğŸ“¥ å°è¯•ä»S3å­˜å‚¨ä¸‹è½½...")
                # ä»URLä¸­æå–S3 key
                actual_s3_key = s3_key
                if s3_key.startswith('http'):
                    from urllib.parse import urlparse
                    parsed_url = urlparse(s3_key)
                    # ä»URLè·¯å¾„ä¸­æå–S3 keyï¼ˆå»æ‰bucketåç§°ï¼‰
                    path_parts = parsed_url.path.strip('/').split('/')
                    if len(path_parts) >= 2:
                        # è·³è¿‡bucketåç§°ï¼Œå–åé¢çš„è·¯å¾„ä½œä¸ºs3_key
                        actual_s3_key = '/'.join(path_parts[1:])
                    else:
                        actual_s3_key = path_parts[-1] if path_parts else s3_key
                    logger.info(f"ğŸ“¥ å¼€å§‹ä»S3ä¸‹è½½æ–‡ä»¶: {s3_key} â†’ {local_path}")
                    logger.info(f"ğŸ“¥ æå–çš„S3 Key: {actual_s3_key}")
                
                if self.s3_service.download_file(actual_s3_key, local_path):
                    logger.info("âœ… S3ä¸‹è½½æˆåŠŸ")
                    return True
                else:
                    logger.warning("âš ï¸ S3ä¸‹è½½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")
            except Exception as e:
                logger.error(f"âŒ S3ä¸‹è½½å¤±è´¥: {e}")
                logger.warning("âš ï¸ S3ä¸‹è½½å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ")

            # æ–¹æ³•2: å°è¯•ä»Sealoså­˜å‚¨ä¸‹è½½ï¼ˆå¦‚æœURLåŒ…å«sealosåŸŸåï¼‰
            if "sealos.run" in s3_key or "sealos.io" in s3_key:
                try:
                    logger.info("ğŸ“¥ å°è¯•ä»Sealoså­˜å‚¨ä¸‹è½½...")
                    
                    # ä½¿ç”¨requestsè¿›è¡ŒåŒæ­¥HTTPä¸‹è½½
                    headers = {
                        'Authorization': f'Bearer {self.sealos_storage.access_key}'
                    }
                    
                    logger.info(f"ğŸ“¥ SealosåŒæ­¥ä¸‹è½½: {s3_key}")
                    response = requests.get(s3_key, headers=headers, timeout=30)
                    
                    if response.status_code == 200:
                        # ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°è·¯å¾„
                        with open(local_path, 'wb') as f:
                            f.write(response.content)
                        logger.info("âœ… Sealosä¸‹è½½æˆåŠŸ")
                        return True
                    else:
                        logger.warning(f"âš ï¸ Sealosä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ Sealosä¸‹è½½å¼‚å¸¸: {e}")

            # æ–¹æ³•3: å°è¯•ä»æœ¬åœ°å­˜å‚¨ä¸‹è½½
            try:
                logger.info("ğŸ“¥ å°è¯•ä»æœ¬åœ°å­˜å‚¨ä¸‹è½½...")
                # ä»s3_keyä¸­æå–ç›¸å¯¹è·¯å¾„
                if s3_key.startswith('http'):
                    # å¦‚æœæ˜¯URLï¼Œæå–æ–‡ä»¶å
                    from urllib.parse import urlparse
                    parsed_url = urlparse(s3_key)
                    path_parts = parsed_url.path.strip('/').split('/')
                    relative_path = '/'.join(path_parts[1:]) if len(path_parts) > 1 else path_parts[-1]
                else:
                    relative_path = s3_key
                
                # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„åˆ†éš”ç¬¦
                local_stored_path = self.local_storage_path / relative_path
                
                logger.info(f"ğŸ“¥ æ£€æŸ¥æœ¬åœ°å­˜å‚¨è·¯å¾„: {local_stored_path}")
                
                if local_stored_path.exists():
                    # å¤åˆ¶æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
                    import shutil
                    shutil.copy2(local_stored_path, local_path)
                    logger.info(f"âœ… æœ¬åœ°å­˜å‚¨ä¸‹è½½æˆåŠŸ: {local_stored_path}")
                    return True
                else:
                    logger.warning(f"âš ï¸ æœ¬åœ°å­˜å‚¨ä¸­æœªæ‰¾åˆ°æ–‡ä»¶: {local_stored_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ æœ¬åœ°å­˜å‚¨ä¸‹è½½å¼‚å¸¸: {e}")

            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
            logger.error(f"âŒ åŒé‡å­˜å‚¨ä¸‹è½½å¤±è´¥: æ‰€æœ‰å­˜å‚¨æ–¹å¼éƒ½æ— æ³•ä¸‹è½½æ–‡ä»¶ {s3_key}")
            return False
            
        except Exception as e:
            logger.error(f"âŒ åŒé‡å­˜å‚¨ä¸‹è½½å¼‚å¸¸: {e}")
            return False

    async def download_file_async(self, file_key: str, local_path: str) -> bool:
        """å¼‚æ­¥ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°è·¯å¾„"""
        try:
            if self.s3_service:
                success = await self.s3_service.download_file_async(file_key, local_path)
                if success:
                    return True
            
            # å°è¯•HTTPä¸‹è½½
            if hasattr(self, '_try_http_download'):
                return await self._try_http_download(file_key, local_path)
                
            return False
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥ä¸‹è½½æ–‡ä»¶å¤±è´¥ {file_key}: {e}")
            return False

    async def download_content_async(self, file_key: str) -> Optional[Dict[str, Any]]:
        """å¼‚æ­¥ä¸‹è½½æ–‡ä»¶å†…å®¹å¹¶è§£æä¸ºJSON"""
        try:
            # æ–¹æ³•1: ä½¿ç”¨S3ç›´æ¥ä¸‹è½½å†…å®¹
            if self.s3_service and hasattr(self.s3_service, 'download_content_async'):
                content = await self.s3_service.download_content_async(file_key)
                if content:
                    return json.loads(content) if isinstance(content, str) else content
            
            # æ–¹æ³•2: ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä¸‹è½½
            import tempfile
            import aiofiles
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as temp_file:
                temp_path = temp_file.name
            
            try:
                # ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶
                download_success = await self.download_file_async(file_key, temp_path)
                if download_success:
                    # è¯»å–ä¸´æ—¶æ–‡ä»¶å†…å®¹
                    async with aiofiles.open(temp_path, 'r', encoding='utf-8') as f:
                        content = await f.read()
                        return json.loads(content)
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
            
            # æ–¹æ³•3: å°è¯•HTTPä¸‹è½½å†…å®¹
            if hasattr(self, '_try_http_download_content'):
                return await self._try_http_download_content(file_key)
                
            return None
            
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥ä¸‹è½½å†…å®¹å¤±è´¥ {file_key}: {e}")
            return None

    def download_content_sync(self, file_key: str) -> Optional[Dict[str, Any]]:
        """åŒæ­¥ä¸‹è½½æ–‡ä»¶å†…å®¹å¹¶è§£æä¸ºJSON"""
        try:
            # æ–¹æ³•1: ä½¿ç”¨S3ç›´æ¥ä¸‹è½½å†…å®¹
            if self.s3_service and hasattr(self.s3_service, 'download_content_sync'):
                content = self.s3_service.download_content_sync(file_key)
                if content:
                    return json.loads(content) if isinstance(content, str) else content
            
            # æ–¹æ³•2: ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä¸‹è½½
            import tempfile
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as temp_file:
                temp_path = temp_file.name
            
            try:
                # ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶
                download_success = self.download_file_sync(file_key, temp_path)
                if download_success:
                    # è¯»å–ä¸´æ—¶æ–‡ä»¶å†…å®¹
                    with open(temp_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        return json.loads(content)
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ åŒæ­¥ä¸‹è½½å†…å®¹å¤±è´¥ {file_key}: {e}")
            return None

    def download_file_sync(self, file_key: str, local_path: str) -> bool:
        """åŒæ­¥ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°è·¯å¾„"""
        try:
            if self.s3_service:
                success = self.s3_service.download_file_sync(file_key, local_path)
                if success:
                    return True
            
            # å°è¯•HTTPä¸‹è½½
            if hasattr(self, '_try_http_download_sync'):
                return self._try_http_download_sync(file_key, local_path)
                
            return False
        except Exception as e:
            logger.error(f"âŒ åŒæ­¥ä¸‹è½½æ–‡ä»¶å¤±è´¥ {file_key}: {e}")
            return False