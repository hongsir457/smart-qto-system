#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå›¾åƒå¤„ç†å™¨ç»„ä»¶
è´Ÿè´£å›¾åƒé¢„å¤„ç†ã€ç¼–ç å’ŒVisionåˆ†æ
"""
import logging
import base64
import os
from typing import Dict, Any, List, Optional
from PIL import Image
import io

logger = logging.getLogger(__name__)

class AIImageProcessor:
    """AIå›¾åƒå¤„ç†å™¨"""
    
    def __init__(self, core_analyzer):
        """åˆå§‹åŒ–å›¾åƒå¤„ç†å™¨"""
        self.core_analyzer = core_analyzer
        
    def _prepare_images(self, image_paths: List[str]) -> List[Dict[str, Any]]:
        """
        å‡†å¤‡å›¾åƒæ•°æ®ï¼Œè½¬æ¢ä¸ºOpenAI Vision APIæ‰€éœ€æ ¼å¼
        
        Args:
            image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: å¤„ç†åçš„å›¾åƒæ•°æ®åˆ—è¡¨
        """
        images_data = []
        
        for image_path in image_paths:
            try:
                if not os.path.exists(image_path):
                    logger.error(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    continue
                    
                # è¯»å–å›¾åƒæ–‡ä»¶
                with open(image_path, 'rb') as image_file:
                    image_data = image_file.read()
                
                # å‹ç¼©å›¾åƒï¼ˆå¦‚æœéœ€è¦ï¼‰
                compressed_data = self._compress_image_if_needed(image_data)
                
                # è½¬æ¢ä¸ºbase64ç¼–ç 
                base64_image = base64.b64encode(compressed_data).decode('utf-8')
                
                # æ£€æµ‹å›¾åƒæ ¼å¼
                image_format = self._detect_image_format(image_path)
                
                images_data.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/{image_format};base64,{base64_image}",
                        "detail": "high"  # é«˜è¯¦ç»†åº¦åˆ†æ
                    }
                })
                
                logger.info(f"âœ… å›¾åƒå¤„ç†å®Œæˆ: {image_path}")
                
            except Exception as e:
                logger.error(f"âŒ å›¾åƒå¤„ç†å¤±è´¥ {image_path}: {e}")
                continue
        
        logger.info(f"ğŸ“· å…±å¤„ç† {len(images_data)} å¼ å›¾åƒ")
        return images_data

    def _compress_image_if_needed(self, image_data: bytes, max_size_mb: float = 20.0) -> bytes:
        """
        å¦‚æœå›¾åƒè¿‡å¤§åˆ™å‹ç¼©å›¾åƒ
        
        Args:
            image_data: åŸå§‹å›¾åƒæ•°æ®
            max_size_mb: æœ€å¤§å…è®¸å¤§å°ï¼ˆMBï¼‰
            
        Returns:
            bytes: å‹ç¼©åçš„å›¾åƒæ•°æ®
        """
        image_size_mb = len(image_data) / (1024 * 1024)
        
        if image_size_mb <= max_size_mb:
            return image_data
        
        logger.info(f"ğŸ”„ å›¾åƒå¤§å° {image_size_mb:.2f}MB è¶…è¿‡é™åˆ¶ï¼Œå¼€å§‹å‹ç¼©...")
        
        try:
            # ä½¿ç”¨PILè¿›è¡Œå‹ç¼©
            image = Image.open(io.BytesIO(image_data))
            
            # è®¡ç®—å‹ç¼©æ¯”ä¾‹
            compression_ratio = max_size_mb / image_size_mb
            new_width = int(image.width * compression_ratio ** 0.5)
            new_height = int(image.height * compression_ratio ** 0.5)
            
            # è°ƒæ•´å›¾åƒå¤§å°
            resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # ä¿å­˜å‹ç¼©åçš„å›¾åƒ
            compressed_buffer = io.BytesIO()
            if image.format:
                resized_image.save(compressed_buffer, format=image.format, quality=85)
            else:
                resized_image.save(compressed_buffer, format='JPEG', quality=85)
            
            compressed_data = compressed_buffer.getvalue()
            compressed_size_mb = len(compressed_data) / (1024 * 1024)
            
            logger.info(f"âœ… å›¾åƒå‹ç¼©å®Œæˆ: {image_size_mb:.2f}MB â†’ {compressed_size_mb:.2f}MB")
            return compressed_data
            
        except Exception as e:
            logger.error(f"âŒ å›¾åƒå‹ç¼©å¤±è´¥: {e}")
            return image_data

    def _detect_image_format(self, image_path: str) -> str:
        """æ£€æµ‹å›¾åƒæ ¼å¼"""
        extension = os.path.splitext(image_path)[1].lower()
        format_map = {
            '.jpg': 'jpeg',
            '.jpeg': 'jpeg',
            '.png': 'png',
            '.webp': 'webp',
            '.gif': 'gif'
        }
        return format_map.get(extension, 'jpeg')

    def generate_qto_from_local_images(self, 
                                     image_paths: List[str], 
                                     context_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        åŸºäºæœ¬åœ°å›¾åƒè·¯å¾„ç”Ÿæˆå·¥ç¨‹é‡æ¸…å•
        
        Args:
            image_paths: æœ¬åœ°å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            context_data: ä¸Šä¸‹æ–‡æ•°æ®
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        if not self.core_analyzer.is_available():
            return {"error": "AI Analyzer Service is not available."}
        
        if not image_paths:
            return {"error": "No image paths provided."}
        
        # å‡†å¤‡å›¾åƒæ•°æ®
        images_data = self._prepare_images(image_paths)
        if not images_data:
            return {"error": "No valid images could be processed."}
        
        # è°ƒç”¨å›¾åƒåˆ†æ
        return self.generate_qto_from_encoded_images(images_data, context_data)

    def generate_qto_from_encoded_images(self, 
                                       images_data: List[Dict[str, Any]], 
                                       context_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        åŸºäºç¼–ç å›¾åƒæ•°æ®ç”Ÿæˆå·¥ç¨‹é‡æ¸…å•
        
        Args:
            images_data: ç¼–ç åçš„å›¾åƒæ•°æ®åˆ—è¡¨
            context_data: ä¸Šä¸‹æ–‡æ•°æ®
            
        Returns:
            Dict[str, Any]: åˆ†æç»“æœ
        """
        if not self.core_analyzer.is_available():
            return {"error": "AI Analyzer Service is not available."}
        
        logger.info("ğŸ¤– å¼€å§‹Visionå›¾åƒåˆ†æ...")
        
        try:
            # å¯¼å…¥æç¤ºè¯æ„å»ºå™¨
            from .ai_prompt_builder import PromptBuilder
            prompt_builder = PromptBuilder()
            
            # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
            system_prompt = prompt_builder.build_enhanced_system_prompt()
            
            # æ„å»ºç”¨æˆ·æ¶ˆæ¯
            user_message = self._build_vision_user_message(images_data, context_data)
            
            # è°ƒç”¨OpenAI Vision API
            from app.core.config import settings
            response = self.core_analyzer.client.chat.completions.create(
                model=settings.OPENAI_VISION_MODEL or settings.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=settings.OPENAI_TEMPERATURE,
                max_tokens=settings.OPENAI_MAX_TOKENS,
                response_format={"type": "json_object"}
            )
            
            # è§£æå“åº”
            response_text = response.choices[0].message.content
            
            if not response_text:
                logger.error("Vision APIè¿”å›ç©ºå“åº”")
                return {"error": "Empty response from Vision API"}
            
            try:
                import json
                qto_data = json.loads(response_text)
                
                # éªŒè¯ç»“æœçœŸå®æ€§
                authenticity_errors = self.core_analyzer._validate_response_authenticity(qto_data)
                has_mock_patterns = self.core_analyzer._check_for_mock_data_patterns(qto_data)
                
                result = {
                    "success": True,
                    "qto_data": qto_data,
                    "analysis_metadata": {
                        "source": "vision_analysis",
                        "image_count": len(images_data),
                        "authenticity_check": {
                            "errors": authenticity_errors,
                            "has_mock_patterns": has_mock_patterns
                        }
                    }
                }
                
                if authenticity_errors or has_mock_patterns:
                    result["warnings"] = {
                        "authenticity_issues": authenticity_errors,
                        "possible_mock_data": has_mock_patterns
                    }
                
                logger.info("âœ… Visionå›¾åƒåˆ†æå®Œæˆ")
                return result
                
            except json.JSONDecodeError as e:
                logger.error(f"Vision APIå“åº”JSONè§£æå¤±è´¥: {e}")
                return {
                    "error": "Invalid JSON response from Vision API",
                    "raw_response": response_text
                }
        
        except Exception as e:
            logger.error(f"âŒ Visionå›¾åƒåˆ†æå¼‚å¸¸: {e}", exc_info=True)
            return {"error": str(e)}

    def _build_vision_user_message(self, 
                                 images_data: List[Dict[str, Any]], 
                                 context_data: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """æ„å»ºVision APIçš„ç”¨æˆ·æ¶ˆæ¯"""
        
        # åŸºç¡€æ–‡æœ¬æç¤º
        text_prompt = """
        # å»ºç­‘æ–½å·¥å›¾çº¸å·¥ç¨‹é‡åˆ†æä»»åŠ¡

        ## ä»»åŠ¡è¯´æ˜
        è¯·ä»”ç»†åˆ†ææä¾›çš„å»ºç­‘æ–½å·¥å›¾çº¸ï¼ŒåŸºäºå›¾çº¸å®é™…å¯è§å†…å®¹ç”Ÿæˆå‡†ç¡®çš„å·¥ç¨‹é‡æ¸…å•ã€‚

        ## å…³é”®è¦æ±‚
        1. **çœŸå®æ€§ç¬¬ä¸€**ï¼šåªåˆ†æå›¾çº¸ä¸Šå®é™…å¯è§çš„å†…å®¹ï¼Œä¸¥ç¦ç¼–é€ æ•°æ®
        2. **ç²¾ç¡®è¯†åˆ«**ï¼šå‡†ç¡®è¯»å–æ„ä»¶ç¼–å·ã€å°ºå¯¸æ ‡æ³¨ã€é…ç­‹ä¿¡æ¯
        3. **è§„èŒƒè®¡ç®—**ï¼šæŒ‰ç…§å›½å®¶å·¥ç¨‹é‡è®¡ç®—è§„èŒƒè¿›è¡Œè®¡ç®—
        4. **è´¨é‡æ§åˆ¶**ï¼šæ ‡æ³¨ä¿¡æ¯ç¼ºå¤±æˆ–ä¸æ¸…æ™°çš„éƒ¨åˆ†

        ## åˆ†æé‡ç‚¹
        - å›¾æ¡†ä¿¡æ¯ï¼šé¡¹ç›®åç§°ã€å›¾çº¸ç¼–å·ã€è®¾è®¡å•ä½ç­‰
        - æ„ä»¶ä¿¡æ¯ï¼šç¼–å·ã€ç±»å‹ã€å°ºå¯¸ã€ä½ç½®
        - é…ç­‹ä¿¡æ¯ï¼šä¸»ç­‹ã€ç®ç­‹è§„æ ¼å’Œå¸ƒç½®
        - æ··å‡åœŸç­‰çº§ï¼šä¸åŒæ„ä»¶çš„å¼ºåº¦ç­‰çº§

        è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¦æ±‚è¾“å‡ºåˆ†æç»“æœã€‚
        """
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        message_content = [
            {"type": "text", "text": text_prompt}
        ]
        
        # æ·»åŠ å›¾åƒå†…å®¹
        for image_data in images_data:
            message_content.append(image_data)
        
        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        if context_data:
            context_text = self._build_context_text(context_data)
            if context_text:
                message_content.append({
                    "type": "text", 
                    "text": f"\n## ä¸Šä¸‹æ–‡ä¿¡æ¯\n{context_text}"
                })
        
        return message_content

    def _build_context_text(self, context_data: Dict[str, Any]) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡æ–‡æœ¬"""
        context_parts = []
        
        if context_data.get('drawing_id'):
            context_parts.append(f"- å›¾çº¸ID: {context_data['drawing_id']}")
        
        if context_data.get('batch_id'):
            context_parts.append(f"- æ‰¹æ¬¡ID: {context_data['batch_id']}")
        
        if context_data.get('slice_info'):
            slice_info = context_data['slice_info']
            context_parts.append(f"- åˆ‡ç‰‡ä¿¡æ¯: {slice_info.get('total_slices', 0)} ä¸ªåˆ‡ç‰‡")
        
        if context_data.get('processing_stage'):
            context_parts.append(f"- å¤„ç†é˜¶æ®µ: {context_data['processing_stage']}")
        
        return "\n".join(context_parts) if context_parts else "" 