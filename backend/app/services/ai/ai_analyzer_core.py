#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåˆ†æå™¨æ ¸å¿ƒç»„ä»¶
è´Ÿè´£åŸºç¡€é…ç½®ã€å®¢æˆ·ç«¯åˆå§‹åŒ–å’Œæ ¸å¿ƒåˆ†æåŠŸèƒ½
"""
import logging
import json
import time
from datetime import datetime
from typing import Dict, Any, List, Optional

# å¯¼å…¥OpenAIå®¢æˆ·ç«¯å’Œé…ç½®
try:
    from openai import OpenAI
    from app.core.config import settings
except ImportError:
    OpenAI = None
    settings = None

logger = logging.getLogger(__name__)

class AIAnalyzerCore:
    """AIåˆ†æå™¨æ ¸å¿ƒç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–AIåˆ†ææœåŠ¡å®¢æˆ·ç«¯"""
        if not OpenAI or not settings or not settings.OPENAI_API_KEY:
            self.client = None
            logger.warning("âš ï¸ OpenAIæˆ–é…ç½®ä¸å¯ç”¨ï¼ŒAIåˆ†ææœåŠ¡å°†å¤„äºç¦ç”¨çŠ¶æ€ã€‚")
        else:
            self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
            logger.info("âœ… AI Analyzer Core initialized successfully with OpenAI client.")
        
        # ç®€åŒ–äº¤äº’è®°å½•å™¨åˆå§‹åŒ–
        self.interaction_logger = None

    def is_available(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.client is not None

    async def analyze_text_async(self, 
                               prompt: str, 
                               session_id: str = None,
                               context_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å¼‚æ­¥æ–‡æœ¬åˆ†ææ–¹æ³•ï¼Œæ”¯æŒAIäº¤äº’è®°å½•ä¿å­˜
        
        Args:
            prompt: åˆ†ææç¤ºè¯
            session_id: ä¼šè¯ID
            context_data: ä¸Šä¸‹æ–‡æ•°æ®
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if not self.is_available():
            return {"success": False, "error": "AI Analyzer Service is not available."}
        
        start_time = time.time()
        
        try:
            logger.info(f"ğŸ¤– å¼€å§‹AIæ–‡æœ¬åˆ†æ (ä¼šè¯: {session_id})")
            
            # è°ƒç”¨OpenAI API
            response = self.client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å»ºç­‘å·¥ç¨‹é€ ä»·å¸ˆï¼Œè¯·æ ¹æ®è¦æ±‚è¿›è¡Œç²¾ç¡®åˆ†æã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=settings.OPENAI_TEMPERATURE,
                max_tokens=settings.OPENAI_MAX_TOKENS
            )
            
            # è·å–å“åº”æ–‡æœ¬
            response_text = response.choices[0].message.content
            usage_info = {
                'prompt_tokens': response.usage.prompt_tokens,
                'completion_tokens': response.usage.completion_tokens,
                'total_tokens': response.usage.total_tokens
            }
            
            # æ„å»ºç»“æœ
            result = {
                "success": True,
                "response": response_text,
                "usage": usage_info,
                "model": settings.OPENAI_MODEL,
                "session_id": session_id,
                "processing_time": time.time() - start_time
            }
            
            # è®°å½•AIäº¤äº’ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
            if context_data and session_id:
                try:
                    drawing_id = context_data.get("drawing_id", "unknown")
                    logger.info(f"ğŸ¤– AIäº¤äº’è®°å½•: session={session_id}, drawing={drawing_id}, tokens={usage_info.get('total_tokens', 0)}")
                except Exception as log_exc:
                    logger.debug(f"äº¤äº’è®°å½•æ—¥å¿—å¼‚å¸¸: {log_exc}")
            
            logger.info(f"âœ… AIæ–‡æœ¬åˆ†æå®Œæˆ: {len(response_text)} ä¸ªå­—ç¬¦")
            return result
            
        except Exception as e:
            logger.error(f"âŒ AIæ–‡æœ¬åˆ†æå¼‚å¸¸: {e}", exc_info=True)
            return {
                "success": False, 
                "error": str(e),
                "session_id": session_id,
                "processing_time": time.time() - start_time
            }

    def generate_qto_from_data(self, extracted_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ¹æ®OCRæ–‡æœ¬å’Œè¡¨æ ¼æ•°æ®ï¼Œè°ƒç”¨LLMç”Ÿæˆç»“æ„åŒ–çš„å·¥ç¨‹é‡æ¸…å•ï¼ˆQTOï¼‰
        
        Args:
            extracted_data: ä»UnifiedOCREngineä¼ æ¥çš„ã€åŒ…å«æ–‡æœ¬å’Œè¡¨æ ¼çš„æ•°æ®
            
        Returns:
            Dict[str, Any]: å¤§æ¨¡å‹ç”Ÿæˆçš„ç»“æ„åŒ–QTOæ•°æ®
        """
        if not self.is_available():
            return {"error": "AI Analyzer Service is not available."}

        logger.info("ğŸ¤– Starting QTO generation with LLM...")

        # å¯¼å…¥æç¤ºè¯æ„å»ºå™¨
        from .ai_prompt_builder import PromptBuilder
        prompt_builder = PromptBuilder()

        # 1. æ„å»ºç³»ç»ŸPrompt
        system_prompt = prompt_builder.build_system_prompt()

        # 2. æ„å»ºç”¨æˆ·Prompt
        user_prompt = prompt_builder.build_user_prompt(extracted_data)
        
        if not user_prompt:
            logger.warning("No data available to build a prompt. Aborting LLM call.")
            return {"error": "No content to analyze."}

        # 3. è°ƒç”¨OpenAI API
        try:
            logger.info(f"Sending request to OpenAI model: {settings.OPENAI_MODEL}")
            
            response = self.client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=settings.OPENAI_TEMPERATURE,
                max_tokens=settings.OPENAI_MAX_TOKENS,
                response_format={"type": "json_object"}  # è¦æ±‚è¿”å›JSONå¯¹è±¡
            )
            
            # 4. è§£æç»“æœ
            qto_json_string = response.choices[0].message.content
            logger.info("âœ… Successfully received response from LLM.")
            
            if not qto_json_string:
                logger.error("LLM returned empty response")
                return {"error": "Empty response from LLM"}
            
            try:
                qto_data = json.loads(qto_json_string)
                return {"success": True, "qto_data": qto_data}
            except json.JSONDecodeError:
                logger.error("Failed to parse JSON from LLM response.")
                return {"error": "Invalid JSON response from LLM", "raw_response": qto_json_string}

        except Exception as e:
            logger.error(f"âŒ An error occurred while calling OpenAI API: {e}", exc_info=True)
            return {"error": str(e)}

    def _validate_response_authenticity(self, qto_data: Dict) -> List[str]:
        """éªŒè¯å“åº”å†…å®¹çš„çœŸä¼ª"""
        errors = []
        
        # æ£€æŸ¥é¡¹ç›®ä¿¡æ¯
        drawing_info = qto_data.get("drawing_info", {})
        project_name = drawing_info.get("project_name", "")
        
        # æ£€æŸ¥é¡¹ç›®åç§°
        if not project_name:
            errors.append("é¡¹ç›®åç§°ç¼ºå¤±")
        
        # æ£€æŸ¥å›¾çº¸æ¯”ä¾‹
        scale = drawing_info.get("scale", "")
        if not scale:
            errors.append("å›¾çº¸æ¯”ä¾‹ç¼ºå¤±")
        
        # æ£€æŸ¥æ„ä»¶æ•°é‡
        components = qto_data.get("components", [])
        if not components:
            errors.append("æ„ä»¶æ•°é‡ä¸ºé›¶")
        
        # æ£€æŸ¥æ„ä»¶ç¼–å·
        for comp in components:
            component_id = comp.get("component_id", "")
            if not component_id:
                errors.append(f"æ„ä»¶ç¼–å·ç¼ºå¤±: {comp}")
        
        return errors

    def _check_for_mock_data_patterns(self, qto_data: Dict) -> bool:
        """æ£€æŸ¥QTOæ•°æ®æ˜¯å¦åŒ…å«æ¨¡æ‹Ÿæ•°æ®çš„æ¨¡å¼"""
        try:
            mock_indicators_found = []
            
            # 1. æ£€æŸ¥é¡¹ç›®ä¿¡æ¯ä¸­çš„æ¨¡æ‹Ÿæ•°æ®æ ‡è¯†
            drawing_info = qto_data.get("drawing_info", {})
            project_name = drawing_info.get("project_name", "")
            title = drawing_info.get("title", "")
            
            project_mock_indicators = [
                "æŸå»ºç­‘å·¥ç¨‹é¡¹ç›®", "æŸå»ºç­‘ç»“æ„æ–½å·¥å›¾", "æŸä½å®…æ¥¼", "æŸåŠå…¬æ¥¼",
                "ç¤ºä¾‹é¡¹ç›®", "æµ‹è¯•é¡¹ç›®", "æ¼”ç¤ºé¡¹ç›®", "æ ·ä¾‹å·¥ç¨‹",
                "XXé¡¹ç›®", "XXXå·¥ç¨‹", "demo", "example", "test",
                "æŸå»ºç­‘", "æŸé¡¹ç›®", "æŸå·¥ç¨‹", "æŸç»“æ„"
            ]
            
            for indicator in project_mock_indicators:
                if indicator.lower() in project_name.lower() or indicator.lower() in title.lower():
                    mock_indicators_found.append(f"é¡¹ç›®åç§°åŒ…å«æ¨¡æ‹Ÿæ ‡è¯†: '{indicator}'")
                    logger.warning(f"ğŸš¨ å‘ç°æ¨¡æ‹Ÿæ•°æ®æ ‡è¯†: '{indicator}' in {project_name or title}")
            
            # 2. æ£€æŸ¥æ„ä»¶ç¼–å·çš„è§„å¾‹æ€§æ¨¡å¼
            components = qto_data.get("components", [])
            if len(components) >= 3:
                component_ids = [comp.get("component_id", "") for comp in components]
                
                # æ£€æŸ¥KZ-1, KZ-2, KZ-3ç±»å‹çš„è¿ç»­ç¼–å·
                kz_ids = [comp_id for comp_id in component_ids if comp_id.startswith("KZ-")]
                if len(kz_ids) >= 3:
                    kz_pattern = all(
                        comp_id == f"KZ-{i+1}" for i, comp_id in enumerate(kz_ids)
                    )
                    if kz_pattern:
                        mock_indicators_found.append("æ„ä»¶ç¼–å·å‘ˆç°è§„å¾‹æ€§è¿ç»­æ¨¡å¼(KZ-1,KZ-2,KZ-3...)")
                        logger.warning("ğŸš¨ å‘ç°è§„å¾‹æ€§æ„ä»¶ç¼–å·æ¨¡å¼")
            
            # ç»¼åˆè¯„ä¼°
            if mock_indicators_found:
                logger.warning(f"ğŸš¨ å‘ç° {len(mock_indicators_found)} ä¸ªæ¨¡æ‹Ÿæ•°æ®ç‰¹å¾:")
                for indicator in mock_indicators_found:
                    logger.warning(f"   - {indicator}")
                return True
            else:
                logger.info("âœ… æ•°æ®æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘ç°æ˜æ˜¾çš„æ¨¡æ‹Ÿæ•°æ®ç‰¹å¾")
                return False
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼æ—¶å‡ºé”™: {e}")
            return False 