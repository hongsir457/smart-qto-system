#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCRå¤„ç†å™¨æ¨¡å— - å¤„ç†OCRç›¸å…³çš„æ‰€æœ‰é€»è¾‘
"""

import os
import json
import logging
import time
import re
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__)

from ..enhanced_slice_models import OCRTextItem, EnhancedSliceInfo


class OCRHandler:
    """OCRå¤„ç†å™¨ - è´Ÿè´£OCRæå–ã€ç¼“å­˜ã€åˆ†ç±»ç­‰"""
    
    def __init__(self):
        """åˆå§‹åŒ–OCRå¤„ç†å™¨"""
        self.component_patterns = self._default_component_patterns()
        
    def extract_ocr_from_slices_optimized(self, analyzer_self, enhanced_slices: List[EnhancedSliceInfo]) -> Dict[str, Any]:
        """ä¼˜åŒ–çš„OCRæå–æ–¹æ³•ï¼Œé›†æˆç¼“å­˜ç®¡ç†å’Œåæ ‡è½¬æ¢"""
        try:
            from app.utils.analysis_optimizations import AnalysisLogger
            
            start_time = time.time()
            total_ocr_items = 0
            cached_slices = 0
            new_ocr_slices = 0
            
            AnalysisLogger.log_step("ocr_extraction_optimized", "å¼€å§‹ä¼˜åŒ–OCRæå–")
            
            for slice_info in enhanced_slices:
                try:
                    # ä½¿ç”¨ä¼˜åŒ–çš„OCRç¼“å­˜ç®¡ç†å™¨
                    cache_result = analyzer_self.ocr_cache.get_cached_ocr(
                        slice_info.slice_path, 
                        slice_info.filename
                    )
                    
                    if cache_result:
                        slice_info.ocr_results = cache_result
                        cached_slices += 1
                        AnalysisLogger.log_step("ocr_cache_hit", f"å¤ç”¨ç¼“å­˜: {slice_info.filename}")
                    else:
                        # æ‰§è¡Œæ–°çš„OCRåˆ†æ
                        if not os.path.exists(slice_info.slice_path):
                            AnalysisLogger.log_step("ocr_skip", f"æ–‡ä»¶ä¸å­˜åœ¨: {slice_info.slice_path}")
                            continue
                            
                        # è°ƒç”¨PaddleOCRè¿›è¡Œæ–‡æœ¬æå–
                        ocr_texts = analyzer_self.ocr_engine.extract_text_from_image(slice_info.slice_path)
                        slice_info.ocr_results = self.parse_ocr_results(ocr_texts)
                        
                        # ç¼“å­˜ç»“æœ
                        analyzer_self.ocr_cache.cache_ocr_result(
                            slice_info.slice_path, 
                            slice_info.filename, 
                            slice_info.ocr_results
                        )
                        new_ocr_slices += 1
                        AnalysisLogger.log_step("ocr_new", f"æ–°åˆ†æ: {slice_info.filename}")
                    
                    total_ocr_items += len(slice_info.ocr_results) if slice_info.ocr_results else 0
                    
                except Exception as e:
                    AnalysisLogger.log_step("ocr_error", f"OCRå¤±è´¥: {slice_info.filename} - {e}")
                    slice_info.ocr_results = []
                    continue
            
            processing_time = time.time() - start_time
            
            # ç»Ÿè®¡ä¿¡æ¯
            statistics = {
                "total_slices": len(enhanced_slices),
                "cached_slices": cached_slices,
                "new_ocr_slices": new_ocr_slices,
                "total_ocr_items": total_ocr_items,
                "cache_hit_rate": cached_slices / len(enhanced_slices) if enhanced_slices else 0,
                "processing_time": processing_time
            }
            
            AnalysisLogger.log_step("ocr_extraction_completed", 
                                  f"OCRæå–å®Œæˆ: {statistics}")
            
            logger.info(f"ğŸ” ä¼˜åŒ–OCRæå–å®Œæˆ: æ€»è®¡{total_ocr_items}ä¸ªæ–‡æœ¬é¡¹ï¼Œ"
                       f"ç¼“å­˜å‘½ä¸­ç‡{statistics['cache_hit_rate']:.1%}ï¼Œè€—æ—¶{processing_time:.2f}s")
            
            return {
                "success": True,
                "statistics": statistics
            }
            
        except Exception as e:
            logger.error(f"âŒ ä¼˜åŒ–OCRæå–å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    def extract_global_ocr_overview_optimized(self, analyzer_self, enhanced_slices: List[EnhancedSliceInfo], 
                                             drawing_info: Dict[str, Any], task_id: str) -> Dict[str, Any]:
        """ä¼˜åŒ–çš„å…¨å›¾OCRæ¦‚è§ˆåˆ†æï¼Œä½¿ç”¨ç»Ÿä¸€çš„GPTå“åº”è§£æå™¨"""
        try:
            from app.utils.analysis_optimizations import GPTResponseParser, AnalysisLogger
            from app.services.ocr_result_corrector import OCRResultCorrector
            import json
            start_time = time.time()
            AnalysisLogger.log_step("global_ocr_overview", "å¼€å§‹å…¨å›¾OCRæ¦‚è§ˆåˆ†æ")

            # æ±‡æ€»æ‰€æœ‰OCRæ–‡æœ¬åŒºåŸŸï¼ˆå«åæ ‡ï¼‰
            text_regions = []
            for slice_info in enhanced_slices:
                if slice_info.ocr_results:
                    for item in slice_info.ocr_results:
                        text_regions.append({
                            "text": item.text,
                            "bbox": getattr(item, "bbox", None) or getattr(item, "position", None)
                        })

            if not text_regions:
                return {"success": False, "error": "æ²¡æœ‰OCRæ–‡æœ¬å¯åˆ†æ"}

            # ç”¨OCRResultCorrectoræ‹¼æ¥çº¯æ–‡æœ¬ï¼ˆæ’åºã€åˆå¹¶ã€èšç±»ï¼‰
            try:
                corrector = OCRResultCorrector()
                ocr_plain_text = corrector.build_plain_text_from_regions(text_regions)
            except Exception as e:
                logger.warning(f"âš ï¸ OCRResultCorrectorä¸å¯ç”¨ï¼Œé™çº§ä¸ºç®€å•æ‹¼æ¥: {e}")
                ocr_plain_text = '\n'.join([r["text"] for r in text_regions])

            # æ—¥å¿—è¾“å‡ºå…¨å›¾çº¯æ–‡æœ¬æ¦‚è§ˆ
            lines = ocr_plain_text.splitlines()
            logger.info(f"ğŸ“‹ å…¨å›¾æ–‡æœ¬æ¦‚è§ˆï¼ˆå‰5è¡Œï¼‰: {' | '.join(lines[:5])}")
            logger.info(f"ğŸ“‹ å…¨å›¾æ–‡æœ¬æ¦‚è§ˆï¼ˆå5è¡Œï¼‰: {' | '.join(lines[-5:])}")

            # æ„å»ºåˆ†ææç¤ºè¯
            analysis_prompt = self.build_global_overview_prompt(ocr_plain_text, drawing_info)

            # è°ƒç”¨AIåˆ†æ
            if not analyzer_self.ai_analyzer:
                return {"success": False, "error": "AIåˆ†æå™¨æœªåˆå§‹åŒ–"}

            parser = GPTResponseParser()
            response = analyzer_self.ai_analyzer.analyze_with_context(
                prompt=analysis_prompt,
                context_type="global_overview",
                task_id=task_id
            )

            if not response.get("success"):
                return {"success": False, "error": response.get("error", "AIåˆ†æå¤±è´¥")}

            parsed_result = parser.parse_response(
                response.get("analysis", ""),
                expected_format="json",
                error_enabled=True
            )

            if not parsed_result.get("success"):
                return {"success": False, "error": "å“åº”è§£æå¤±è´¥"}

            overview_data = parsed_result.get("data", {})
            processing_time = time.time() - start_time
            AnalysisLogger.log_step("global_overview_completed", f"å…¨å›¾æ¦‚è§ˆå®Œæˆï¼Œè€—æ—¶{processing_time:.2f}s")

            return {
                "success": True,
                "overview": overview_data,
                "ocr_text_count": len(lines),
                "processing_time": processing_time
            }
        except Exception as e:
            logger.error(f"âŒ å…¨å›¾OCRæ¦‚è§ˆåˆ†æå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    def build_global_overview_prompt(self, ocr_plain_text: str, drawing_info: Dict[str, Any]) -> str:
        """ä¸ºå…¨å›¾OCRæ¦‚è§ˆæ„å»ºPromptï¼ˆåªç”¨çº¯æ–‡æœ¬ï¼‰"""
        truncation_note = "\n...(æ–‡æœ¬è¿‡é•¿ï¼Œå·²æˆªæ–­)" if len(ocr_plain_text) > 4000 else ""
        drawing_name = drawing_info.get('drawing_name', 'æœªçŸ¥')
        drawing_type = drawing_info.get('drawing_type', 'å»ºç­‘å›¾çº¸')
        
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å»ºç­‘å·¥ç¨‹é‡è®¡ç®—ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ä»å»ºç­‘å›¾çº¸ä¸­æå–çš„OCRæ–‡æœ¬ï¼ˆå·²æŒ‰é¡ºåºæ’åºã€ç›¸é‚»åˆå¹¶ï¼‰ï¼Œå¹¶æä¾›ç»“æ„åŒ–çš„å…¨å›¾æ¦‚è§ˆä¿¡æ¯ã€‚

å›¾çº¸ä¿¡æ¯ï¼š
- æ–‡ä»¶åï¼š{drawing_name}
- å›¾çº¸ç±»å‹ï¼š{drawing_type}

OCRæå–çš„çº¯æ–‡æœ¬å†…å®¹ï¼š
{ocr_plain_text[:4000]}{truncation_note}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "drawing_info": {{
        "project_name": "å·¥ç¨‹åç§°",
        "drawing_type": "å›¾çº¸ç±»å‹",
        "scale": "å›¾çº¸æ¯”ä¾‹",
        "drawing_number": "å›¾çº¸ç¼–å·"
    }},
    "component_ids": ["æ„ä»¶ç¼–å·åˆ—è¡¨"],
    "component_types": ["æ„ä»¶ç±»å‹åˆ—è¡¨"],
    "material_grades": ["ææ–™ç­‰çº§åˆ—è¡¨"],
    "axis_lines": ["è½´çº¿æ ‡è¯†åˆ—è¡¨"],
    "summary": {{
        "total_components": 0,
        "main_structure_type": "ä¸»è¦ç»“æ„ç±»å‹",
        "drawing_complexity": "å›¾çº¸å¤æ‚ç¨‹åº¦"
    }}
}}

è¦æ±‚ï¼š
1. å‡†ç¡®è¯†åˆ«å›¾çº¸ä¸­çš„æ„ä»¶ç¼–å·ï¼ˆå¦‚ï¼šKL1ã€Z1ã€B1ç­‰ï¼‰
2. è¯†åˆ«æ„ä»¶ç±»å‹ï¼ˆå¦‚ï¼šæ¡†æ¶æ¢ã€æŸ±ã€æ¿ç­‰ï¼‰
3. æå–ææ–™ç­‰çº§ä¿¡æ¯ï¼ˆå¦‚ï¼šC30ã€HRB400ç­‰ï¼‰
4. è¯†åˆ«è½´çº¿æ ‡è¯†ï¼ˆå¦‚ï¼šAã€Bã€Cã€1ã€2ã€3ç­‰ï¼‰
5. è¿”å›æ ‡å‡†JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜æ–‡å­—
"""
        return prompt

    def parse_ocr_results(self, ocr_texts: List[Dict]) -> List[OCRTextItem]:
        """è§£æOCRç»“æœä¸ºæ ‡å‡†æ ¼å¼"""
        ocr_items = []
        
        for item in ocr_texts:
            try:
                text = item.get("text", "").strip()
                confidence = item.get("confidence", 0.0)
                
                # ä»PaddleOCRçš„bbox_xyxyæ ¼å¼è½¬æ¢ä¸ºpositionæ ¼å¼
                bbox_xyxy = item.get("bbox_xyxy", {})
                if bbox_xyxy:
                    # è½¬æ¢bboxä¸ºå››ä¸ªè§’ç‚¹åæ ‡
                    x_min = bbox_xyxy.get("x_min", 0)
                    y_min = bbox_xyxy.get("y_min", 0)
                    x_max = bbox_xyxy.get("x_max", 0)
                    y_max = bbox_xyxy.get("y_max", 0)
                    
                    position = [
                        [x_min, y_min],  # å·¦ä¸Š
                        [x_max, y_min],  # å³ä¸Š
                        [x_max, y_max],  # å³ä¸‹
                        [x_min, y_max]   # å·¦ä¸‹
                    ]
                else:
                    position = []
                
                if text and position:
                    # è®¡ç®—æ ‡å‡†åŒ–è¾¹ç•Œæ¡†
                    bbox = self.calculate_bbox_from_position(position)
                    
                    ocr_item = OCRTextItem(
                        text=text,
                        position=position,
                        confidence=confidence,
                        category="unknown",
                        bbox=bbox
                    )
                    
                    ocr_items.append(ocr_item)
                    
            except Exception as e:
                logger.warning(f"âš ï¸ è§£æOCRé¡¹å¤±è´¥: {e}")
                continue
        
        return ocr_items

    def calculate_bbox_from_position(self, position: List[List[int]]) -> Dict[str, int]:
        """ä»ä½ç½®ç‚¹è®¡ç®—è¾¹ç•Œæ¡†"""
        if len(position) < 4:
            return {"x": 0, "y": 0, "width": 0, "height": 0}
        
        xs = [p[0] for p in position]
        ys = [p[1] for p in position]
        
        x_min, x_max = min(xs), max(xs)
        y_min, y_max = min(ys), max(ys)
        
        return {
            "x": x_min,
            "y": y_min,
            "width": x_max - x_min,
            "height": y_max - y_min
        }

    def _default_component_patterns(self):
        """é»˜è®¤æ„ä»¶æ¨¡å¼"""
        return {
            'component_id': [r'^[A-Z]{1,2}\d{2,4}$', r'^[A-Z]{1,2}-\d{1,3}$', r'^\d{1,3}[A-Z]{1,2}$'],
            'dimension': [r'^\d{2,4}[xXÃ—]\d{2,4}$', r'^\d{2,4}[xXÃ—]\d{2,4}[xXÃ—]\d{2,4}$', r'^[bBhH]?\d{2,4}$'],
            'material': [r'^C\d{2}$', r'^HRB\d{3}$', r'^MU\d{1,2}$', r'^Q\d{3}$'],
            'axis': [r'^[A-Z]-[A-Z]$', r'^\d+-\d+$', r'^è½´çº¿\s*[A-Z0-9\-/]+$', r'^[A-Z]\d*/[A-Z]\d*$']
        }
