import logging
from typing import Dict, Any, List, Optional
import os
import math
import base64
import tempfile

from ..enhanced_slice_models import OCRTextItem, EnhancedSliceInfo

logger = logging.getLogger(__name__)


class ReuseHandler:
    """å¤„ç†ä¸ç¼“å­˜å¤ç”¨ç›¸å…³çš„é€»è¾‘"""

    def can_reuse_slice_ocr(self, analyzer, slice_info: EnhancedSliceInfo) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤ç”¨åˆ‡ç‰‡çš„OCRç»“æœ"""
        try:
            # æ£€æŸ¥å…±äº«åˆ‡ç‰‡ç»“æœä¸­æ˜¯å¦æœ‰OCRæ•°æ®
            if hasattr(analyzer, 'shared_slice_results') and analyzer.shared_slice_results:
                for original_path, slice_result in analyzer.shared_slice_results.items():
                    slice_infos = slice_result.get('slice_infos', [])
                    for info in slice_infos:
                        if (info.get('row') == slice_info.row and
                            info.get('col') == slice_info.col and
                            info.get('ocr_results')):
                            return True
            
            # æ£€æŸ¥å†…å­˜ç¼“å­˜
            if hasattr(analyzer, '_slice_ocr_cache'):
                slice_key = f"{slice_info.row}_{slice_info.col}_{slice_info.slice_path}"
                return slice_key in analyzer._slice_ocr_cache
            
            return False
            
        except Exception as e:
            error_message = str(e).replace('\\', '/')
            logger.debug(f"âš ï¸ æ£€æŸ¥OCRå¤ç”¨å¤±è´¥: {error_message}")
            return False

    def load_cached_ocr_results(self, analyzer, slice_info: EnhancedSliceInfo) -> List[OCRTextItem]:
        """åŠ è½½ç¼“å­˜çš„OCRç»“æœ"""
        try:
            # ä¼˜å…ˆä»å…±äº«åˆ‡ç‰‡ç»“æœåŠ è½½
            if hasattr(analyzer, 'shared_slice_results') and analyzer.shared_slice_results:
                for original_path, slice_result in analyzer.shared_slice_results.items():
                    slice_infos = slice_result.get('slice_infos', [])
                    for info in slice_infos:
                        if (info.get('row') == slice_info.row and
                            info.get('col') == slice_info.col):
                            ocr_data = info.get('ocr_results', [])
                            if ocr_data:
                                # è½¬æ¢ä¸ºOCRTextItemå¯¹è±¡
                                return self.convert_to_ocr_text_items(ocr_data)
            
            # ä»å†…å­˜ç¼“å­˜åŠ è½½
            if hasattr(analyzer, '_slice_ocr_cache'):
                slice_key = f"{slice_info.row}_{slice_info.col}_{slice_info.slice_path}"
                cached_data = analyzer._slice_ocr_cache.get(slice_key)
                if cached_data:
                    return self.convert_to_ocr_text_items(cached_data)
            
            return []
            
        except Exception as e:
            error_message = str(e).replace('\\', '/')
            logger.debug(f"âš ï¸ åŠ è½½ç¼“å­˜OCRç»“æœå¤±è´¥: {error_message}")
            return []

    def convert_to_ocr_text_items(self, ocr_data: List[Dict]) -> List[OCRTextItem]:
        """å°†å­—å…¸æ ¼å¼çš„OCRæ•°æ®è½¬æ¢ä¸ºOCRTextItemå¯¹è±¡"""
        ocr_items = []
        
        for item in ocr_data:
            try:
                if isinstance(item, dict):
                    ocr_item = OCRTextItem(
                        text=item.get('text', ''),
                        position=item.get('position', []),
                        confidence=item.get('confidence', 0.0),
                        category=item.get('category', 'unknown'),
                        bbox=item.get('bbox', {})
                    )
                    ocr_items.append(ocr_item)
                elif hasattr(item, 'text'):  # å·²ç»æ˜¯OCRTextItemå¯¹è±¡
                    ocr_items.append(item)
                    
            except Exception as e:
                error_message = str(e).replace('\\', '/')
                logger.debug(f"âš ï¸ è½¬æ¢OCRé¡¹å¤±è´¥: {error_message}")
                continue
        
        return ocr_items

    def cache_slice_ocr_results(self, analyzer, slice_info: EnhancedSliceInfo):
        """ç¼“å­˜åˆ‡ç‰‡çš„OCRç»“æœ"""
        try:
            if not hasattr(analyzer, '_slice_ocr_cache'):
                analyzer._slice_ocr_cache = {}
            
            slice_key = f"{slice_info.row}_{slice_info.col}_{slice_info.slice_path}"
            
            # è½¬æ¢OCRTextItemä¸ºå­—å…¸æ ¼å¼
            ocr_data = []
            for ocr_item in slice_info.ocr_results or []:
                ocr_data.append({
                    'text': ocr_item.text,
                    'position': ocr_item.position,
                    'confidence': ocr_item.confidence,
                    'category': ocr_item.category,
                    'bbox': ocr_item.bbox
                })
            
            analyzer._slice_ocr_cache[slice_key] = ocr_data
            
        except Exception as e:
            error_message = str(e).replace('\\', '/')
            logger.debug(f"âš ï¸ ç¼“å­˜OCRç»“æœå¤±è´¥: {error_message}")

    def save_global_ocr_cache(self, analyzer):
        """ä¿å­˜å…¨å±€OCRç¼“å­˜"""
        try:
            if not hasattr(analyzer, '_global_ocr_cache'):
                analyzer._global_ocr_cache = {}
            
            # ä¿å­˜æ‰€æœ‰åˆ‡ç‰‡çš„OCRç»“æœ
            for slice_info in analyzer.enhanced_slices:
                if slice_info.ocr_results:
                    slice_key = f"{slice_info.row}_{slice_info.col}"
                    ocr_data = []
                    for ocr_item in slice_info.ocr_results:
                        ocr_data.append({
                            'text': ocr_item.text,
                            'position': ocr_item.position,
                            'confidence': ocr_item.confidence,
                            'category': ocr_item.category,
                            'bbox': ocr_item.bbox
                        })
                    analyzer._global_ocr_cache[slice_key] = ocr_data
            
            logger.debug(f"ğŸ’¾ å…¨å±€OCRç¼“å­˜å·²ä¿å­˜: {len(analyzer._global_ocr_cache)} ä¸ªåˆ‡ç‰‡")
            
        except Exception as e:
            error_message = str(e).replace('\\', '/')
            logger.debug(f"âš ï¸ ä¿å­˜å…¨å±€OCRç¼“å­˜å¤±è´¥: {error_message}")

    def reuse_global_ocr_cache(self, analyzer) -> Dict[str, Any]:
        """å¤ç”¨å…¨å±€OCRç¼“å­˜"""
        try:
            total_text_items = 0
            reused_slices = 0
            
            for slice_info in analyzer.enhanced_slices:
                slice_key = f"{slice_info.row}_{slice_info.col}"
                
                if slice_key in analyzer._global_ocr_cache:
                    ocr_data = analyzer._global_ocr_cache[slice_key]
                    slice_info.ocr_results = self.convert_to_ocr_text_items(ocr_data)
                    total_text_items += len(slice_info.ocr_results)
                    reused_slices += 1
                    logger.debug(f"â™»ï¸ åˆ‡ç‰‡ {slice_key} å¤ç”¨å…¨å±€ç¼“å­˜: {len(slice_info.ocr_results)} ä¸ªæ–‡æœ¬é¡¹")
                else:
                    slice_info.ocr_results = []
            
            logger.info(f"â™»ï¸ å…¨å±€OCRç¼“å­˜å¤ç”¨å®Œæˆ: {reused_slices}/{len(analyzer.enhanced_slices)} ä¸ªåˆ‡ç‰‡, å…± {total_text_items} ä¸ªæ–‡æœ¬é¡¹")
            
            return {
                "success": True,
                "statistics": {
                    "processed_slices": 0,
                    "reused_slices": reused_slices,
                    "total_slices": len(analyzer.enhanced_slices),
                    "total_text_items": total_text_items,
                    "success_rate": reused_slices / len(analyzer.enhanced_slices) if analyzer.enhanced_slices else 0,
                    "reuse_rate": 1.0
                }
            }
            
        except Exception as e:
            error_message = str(e).replace('\\', '/')
            logger.error(f"âŒ å¤ç”¨å…¨å±€OCRç¼“å­˜å¤±è´¥: {error_message}")
            return {"success": False, "error": str(e)}

    def can_reuse_shared_slices(self, shared_slice_results: Dict[str, Any], image_path: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤ç”¨å…±äº«åˆ‡ç‰‡ç»“æœ"""
        if not shared_slice_results:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”å›¾åƒçš„åˆ‡ç‰‡ç»“æœ
        slice_info = shared_slice_results.get(image_path)
        if not slice_info:
            # å°è¯•ç”¨æ–‡ä»¶ååŒ¹é…
            image_name = os.path.basename(image_path)
            for path, info in shared_slice_results.items():
                if os.path.basename(path) == image_name:
                    slice_info = info
                    break
        
        if not slice_info:
            return False
        
        # æ£€æŸ¥åˆ‡ç‰‡ç»“æœæ˜¯å¦æœ‰æ•ˆ
        if not slice_info.get('sliced', False):
            return False
        
        slice_infos = slice_info.get('slice_infos', [])
        if not slice_infos:
            return False
        
        logger.info(f"âœ… å‘ç°å¯å¤ç”¨çš„æ™ºèƒ½åˆ‡ç‰‡: {len(slice_infos)} ä¸ªåˆ‡ç‰‡")
        return True

    def reuse_shared_slices(self, analyzer, shared_slice_results: Dict[str, Any], image_path: str, drawing_info: Dict[str, Any]) -> Dict[str, Any]:
        """å¤ç”¨å…±äº«åˆ‡ç‰‡ç»“æœ"""
        try:
            # è·å–åˆ‡ç‰‡ä¿¡æ¯
            slice_info_data = shared_slice_results.get(image_path)
            if not slice_info_data:
                # å°è¯•ç”¨æ–‡ä»¶ååŒ¹é…
                image_name = os.path.basename(image_path)
                for path, info in shared_slice_results.items():
                    if os.path.basename(path) == image_name:
                        slice_info_data = info
                        break
            
            if not slice_info_data:
                return {"success": False, "error": "æœªæ‰¾åˆ°å¯¹åº”çš„åˆ‡ç‰‡ä¿¡æ¯"}
            
            slice_infos = slice_info_data.get('slice_infos', [])
            original_width = slice_info_data.get('original_width', 0)
            original_height = slice_info_data.get('original_height', 0)
            
            logger.info(f"â™»ï¸ å¤ç”¨æ™ºèƒ½åˆ‡ç‰‡: {len(slice_infos)} ä¸ªåˆ‡ç‰‡ï¼ŒåŸå›¾å°ºå¯¸: {original_width}x{original_height}")
            
            # è½¬æ¢ä¸ºEnhancedSliceInfoæ ¼å¼
            analyzer.enhanced_slices = []
            ocr_text_count = 0
            used_coordinates = set()  # é˜²é‡å¤åæ ‡é›†åˆ
            
            for i, slice_data in enumerate(slice_infos):
                try:
                    slice_image_data = base64.b64decode(slice_data.base64_data)
                    temp_slice_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
                    temp_slice_file.write(slice_image_data)
                    temp_slice_file.close()
                    
                    if original_width > 0 and original_height > 0:
                        total_slices = len(slice_infos)
                        estimated_rows = math.ceil(math.sqrt(total_slices * original_height / original_width))
                        estimated_cols = math.ceil(total_slices / estimated_rows)
                        
                        if estimated_rows > 0 and estimated_cols > 0:
                            row_height = max(1, original_height // estimated_rows)
                            col_width = max(1, original_width // estimated_cols)
                            row = min(slice_data.y // row_height, estimated_rows - 1)
                            col = min(slice_data.x // col_width, estimated_cols - 1)
                        else:
                            estimated_cols = max(1, math.ceil(math.sqrt(len(slice_infos))))
                            row = i // estimated_cols
                            col = i % estimated_cols
                    else:
                        estimated_cols = max(1, math.ceil(math.sqrt(len(slice_infos))))
                        row = i // estimated_cols
                        col = i % estimated_cols
                    
                    row = max(0, row)
                    col = max(0, col)
                    
                    original_coord = (row, col)
                    if original_coord in used_coordinates:
                        estimated_cols = max(1, math.ceil(math.sqrt(len(slice_infos))))
                        row = i // estimated_cols
                        col = i % estimated_cols
                        
                        retry_count = 0
                        while (row, col) in used_coordinates and retry_count < 100:
                            row = i // estimated_cols + retry_count // estimated_cols
                            col = (i + retry_count) % estimated_cols
                            retry_count += 1
                    
                    used_coordinates.add((row, col))
                    
                    enhanced_slice_info = EnhancedSliceInfo(
                        filename=f"reused_slice_{row}_{col}.png",
                        row=row,
                        col=col,
                        x_offset=slice_data.x,
                        y_offset=slice_data.y,
                        source_page=drawing_info.get("page_number", 1),
                        width=slice_data.width,
                        height=slice_data.height,
                        slice_path=temp_slice_file.name,
                        ocr_results=[],
                        enhanced_prompt=""
                    )
                    
                    analyzer.enhanced_slices.append(enhanced_slice_info)
                    
                except Exception as e:
                    error_message = str(e).replace('\\', '/')
                    logger.warning(f"âš ï¸ å¤ç”¨åˆ‡ç‰‡ {i} å¤±è´¥: {error_message}")
                    continue
            
            self.fix_duplicate_slice_ids(analyzer)
            
            ocr_reused = False
            if hasattr(slice_info_data, 'ocr_results') or 'ocr_results' in slice_info_data:
                logger.info("â™»ï¸ å‘ç°å¯å¤ç”¨çš„OCRç»“æœ")
                ocr_reused = True
                ocr_text_count = len(slice_info_data.get('ocr_results', []))
            
            if analyzer.enhanced_slices:
                rows = [s.row for s in analyzer.enhanced_slices]
                cols = [s.col for s in analyzer.enhanced_slices]
                logger.info(f"âœ… æ™ºèƒ½åˆ‡ç‰‡å¤ç”¨å®Œæˆ: {len(analyzer.enhanced_slices)} ä¸ªåˆ‡ç‰‡")
                logger.info(f"ğŸ“ åˆ‡ç‰‡èŒƒå›´: è¡Œ {min(rows)}-{max(rows)}, åˆ— {min(cols)}-{max(cols)}")
                logger.info(f"ğŸ“ åˆ‡ç‰‡æ ‡è¯†: {[f'{s.row}_{s.col}' for s in analyzer.enhanced_slices[:5]]}{'...' if len(analyzer.enhanced_slices) > 5 else ''}")
            else:
                logger.info(f"âœ… æ™ºèƒ½åˆ‡ç‰‡å¤ç”¨å®Œæˆ: {len(analyzer.enhanced_slices)} ä¸ªåˆ‡ç‰‡")
            
            slice_coordinate_map = {}
            for s_info in analyzer.enhanced_slices:
                slice_key = f"{s_info.row}_{s_info.col}"
                slice_coordinate_map[slice_key] = {
                    'x_offset': s_info.x_offset,
                    'y_offset': s_info.y_offset,
                    'width': s_info.width,
                    'height': s_info.height,
                    'slice_id': slice_key,
                    'row': s_info.row,
                    'col': s_info.col
                }
            
            original_image_info = {
                'width': original_width,
                'height': original_height,
                'total_slices': len(analyzer.enhanced_slices),
                'slice_source': 'intelligent_slicer'
            }
            
            logger.info(f"âœ… åæ ‡æ˜ å°„æ„å»ºå®Œæˆ: {len(slice_coordinate_map)} ä¸ªåˆ‡ç‰‡æ˜ å°„")
            
            return {
                "success": True,
                "slice_count": len(analyzer.enhanced_slices),
                "grid_size": f"æ™ºèƒ½åˆ‡ç‰‡å¤ç”¨",
                "slice_reused": True,
                "ocr_reused": ocr_reused,
                "original_slice_count": len(slice_infos),
                "slice_source": "intelligent_slicer",
                "ocr_statistics": {
                    "reused_ocr_count": ocr_text_count,
                    "reused_from": "shared_slice_results"
                },
                "slice_coordinate_map": slice_coordinate_map,
                "original_image_info": original_image_info
            }
            
        except Exception as e:
            error_message = str(e).replace('\\', '/')
            logger.error(f"âŒ æ™ºèƒ½åˆ‡ç‰‡å¤ç”¨å¤±è´¥: {error_message}")
            return {"success": False, "error": str(e)}

    def load_shared_ocr_results(self, analyzer, shared_slice_results: Dict[str, Any], image_path: str) -> Dict[str, Any]:
        """ä»å…±äº«åˆ‡ç‰‡ç»“æœä¸­åŠ è½½OCRæ•°æ®"""
        slice_info_data = shared_slice_results.get(image_path)
        if not slice_info_data or not slice_info_data.get('sliced'):
            return {"success": False, "error": "åœ¨å…±äº«ç»“æœä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ‡ç‰‡ä¿¡æ¯"}

        total_loaded_texts = 0
        total_slices_with_ocr = 0

        for slice_data in analyzer.enhanced_slices:
            original_slice = next((s for s in slice_info_data.get('slice_infos', []) if s.slice_id == slice_data.filename), None)
            
            if original_slice and hasattr(original_slice, 'ocr_results') and original_slice.ocr_results:
                ocr_items = self.convert_to_ocr_text_items(original_slice.ocr_results)
                slice_data.ocr_results = ocr_items
                total_loaded_texts += len(ocr_items)
                total_slices_with_ocr += 1

        logger.info(f"âœ… ä»å…±äº«ç»“æœåŠ è½½OCRæ•°æ®: {total_slices_with_ocr}/{len(analyzer.enhanced_slices)} ä¸ªåˆ‡ç‰‡ï¼Œ{total_loaded_texts} ä¸ªæ–‡æœ¬é¡¹")
        
        return {"success": True, "loaded_text_count": total_loaded_texts}

    def fix_duplicate_slice_ids(self, analyzer):
        """ä¿®å¤é‡å¤çš„åˆ‡ç‰‡æ ‡è¯†"""
        try:
            slice_ids = [f"{s.row}_{s.col}" for s in analyzer.enhanced_slices]
            if len(slice_ids) == len(set(slice_ids)):
                return
                
            logger.info("ğŸ”§ å¼€å§‹ä¿®å¤é‡å¤çš„åˆ‡ç‰‡æ ‡è¯†...")
            
            used_coordinates = set()
            fixed_count = 0
            
            for i, slice_info in enumerate(analyzer.enhanced_slices):
                original_coord = (slice_info.row, slice_info.col)
                
                if original_coord in used_coordinates:
                    estimated_cols = max(1, math.ceil(math.sqrt(len(analyzer.enhanced_slices))))
                    new_row = i // estimated_cols
                    new_col = i % estimated_cols
                    
                    retry_count = 0
                    while (new_row, new_col) in used_coordinates and retry_count < 100:
                        new_row = (i + retry_count) // estimated_cols
                        new_col = (i + retry_count) % estimated_cols
                        retry_count += 1
                    
                    slice_info.row = new_row
                    slice_info.col = new_col
                    slice_info.filename = f"reused_slice_{new_row}_{new_col}.png"
                    fixed_count += 1
                    
                    logger.debug(f"ä¿®å¤åˆ‡ç‰‡ {i}: {original_coord} -> ({new_row}, {new_col})")
                
                used_coordinates.add((slice_info.row, slice_info.col))
            
            logger.info(f"âœ… åˆ‡ç‰‡æ ‡è¯†ä¿®å¤å®Œæˆ: ä¿®å¤äº† {fixed_count} ä¸ªé‡å¤æ ‡è¯†")
            
        except Exception as e:
            error_message = str(e).replace('\\', '/')
            logger.error(f"âŒ ä¿®å¤åˆ‡ç‰‡æ ‡è¯†å¤±è´¥: {error_message}") 