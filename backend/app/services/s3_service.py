#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
S3äº‘å­˜å‚¨æœåŠ¡ - æ”¯æŒæœ¬åœ°å­˜å‚¨fallback
"""

import boto3
import logging
import os
import uuid
import shutil
from typing import Optional, BinaryIO
from botocore.exceptions import ClientError, NoCredentialsError
from pathlib import Path
import aiofiles
import asyncio
from botocore.config import Config
from concurrent.futures import ThreadPoolExecutor

# S3é…ç½®é€šè¿‡å»¶è¿Ÿå¯¼å…¥è·å–
logger = logging.getLogger(__name__)

class S3Service:
    _instance = None
    _initialized = False

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(S3Service, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        # åªåœ¨ç¬¬ä¸€æ¬¡å®ä¾‹åŒ–æ—¶è¿›è¡Œåˆå§‹åŒ–
        if S3Service._initialized:
            return
            
        S3Service._initialized = True
        
        self.use_local_storage = False
        self.local_storage_path = Path("uploads")
        
        try:
            # å»¶è¿Ÿå¯¼å…¥é…ç½®ä»¥é¿å…å¾ªç¯å¯¼å…¥
            from ..core.config import settings
            
            self.endpoint_url = settings.S3_ENDPOINT
            self.access_key = settings.S3_ACCESS_KEY
            self.secret_key = settings.S3_SECRET_KEY
            self.bucket_name = settings.S3_BUCKET_NAME
            self.region = settings.S3_REGION
            self.use_local_storage = False  # é»˜è®¤ä½¿ç”¨S3

            # æ£€æŸ¥S3é…ç½®æ˜¯å¦å®Œæ•´
            if not all([self.endpoint_url, self.access_key, self.secret_key, self.bucket_name]):
                logger.warning("S3é…ç½®ä¸å®Œæ•´ï¼Œå°†å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°å­˜å‚¨ã€‚")
                self.use_local_storage = True
                self._setup_local_storage()
                return
            
            # åˆå§‹åŒ–boto3å®¢æˆ·ç«¯
            try:
                self.s3_client = boto3.client(
                    's3',
                    endpoint_url=self.endpoint_url,
                    aws_access_key_id=self.access_key,
                    aws_secret_access_key=self.secret_key,
                    region_name=self.region,
                    config=Config(signature_version='s3v4')
                )
                # logger.info("âœ… S3å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸã€‚")
                
                # # ç§»é™¤æœ‰å®³çš„è¿æ¥æµ‹è¯•ï¼Œå› ä¸ºå®ƒå¯èƒ½å› æƒé™é—®é¢˜ï¼ˆè€Œéè¿æ¥é—®é¢˜ï¼‰å¤±è´¥
                # # self.test_s3_connection()

            except Exception as e:
                logger.error(f"âŒ S3å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†åˆ‡æ¢åˆ°æœ¬åœ°å­˜å‚¨ã€‚")
                self.use_local_storage = True
            
            if self.use_local_storage:
                self._setup_local_storage()
            else:
                logger.info(f"âœ… S3æœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼Œbucket: {self.bucket_name}")
                
            # è®°å½•å°†è¦ä½¿ç”¨çš„S3é…ç½®
            logger.info(f"S3_ENDPOINT_URL: {self.endpoint_url}")
            logger.info(f"S3_ACCESS_KEY: {'*' * 5 if self.access_key else 'Not set'}")
            logger.info(f"S3_BUCKET_NAME (overridden): {self.bucket_name}")
            logger.info(f"S3_REGION: {self.region}")
                
        except Exception as e:
            logger.warning(f"âš ï¸ S3æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨æœ¬åœ°å­˜å‚¨")
            self.use_local_storage = True
            self._setup_local_storage()
    
    def _setup_local_storage(self):
        """è®¾ç½®æœ¬åœ°å­˜å‚¨"""
        self.use_local_storage = True
        self.local_storage_path.mkdir(exist_ok=True)
        (self.local_storage_path / "drawings").mkdir(exist_ok=True)
        logger.info(f"ğŸ“ æœ¬åœ°å­˜å‚¨å·²è®¾ç½®: {self.local_storage_path.absolute()}")
    
    def upload_file(
        self, 
        file_obj: BinaryIO, 
        file_name: str, 
        content_type: str = "application/octet-stream",
        folder: str = "drawings"
    ) -> dict:
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°S3æˆ–æœ¬åœ°å­˜å‚¨
        """
        if self.use_local_storage:
            return self._upload_to_local(file_obj, file_name, folder)
        else:
            return self._upload_to_s3(file_obj, file_name, content_type, folder)
    
    def _upload_to_local(self, file_obj: BinaryIO, file_name: str, folder: str) -> dict:
        """ä¸Šä¼ æ–‡ä»¶åˆ°æœ¬åœ°å­˜å‚¨"""
        try:
            # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶ID
            file_id = str(uuid.uuid4())
            file_ext = os.path.splitext(file_name)[1]
            local_filename = f"{file_id}{file_ext}"
            
            # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
            folder_path = self.local_storage_path / folder
            folder_path.mkdir(exist_ok=True)
            
            # ä¿å­˜æ–‡ä»¶
            file_path = folder_path / local_filename
            with open(file_path, 'wb') as f:
                shutil.copyfileobj(file_obj, f)
            
            # ç”Ÿæˆç›¸å¯¹è·¯å¾„ä½œä¸º"s3_key"
            s3_key = f"{folder}/{local_filename}"
            file_url = f"file://{file_path.absolute()}"
            
            logger.info(f"âœ… æ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°: {file_path}")
            
            return {
                "s3_key": s3_key,
                "s3_url": file_url,
                "bucket": "local",
                "file_id": file_id,
                "original_filename": file_name,
                "local_path": str(file_path)
            }
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")
            raise Exception(f"æœ¬åœ°æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")
    
    def _upload_to_s3(self, file_obj: BinaryIO, file_name: str, content_type: str, folder: str) -> dict:
        """ä¸Šä¼ æ–‡ä»¶åˆ°S3"""
        try:
            # ç”Ÿæˆå”¯ä¸€çš„S3é”®å
            file_id = str(uuid.uuid4())
            file_ext = os.path.splitext(file_name)[1]
            s3_key = f"{folder}/{file_id}{file_ext}"
            
            logger.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ æ–‡ä»¶åˆ°S3: {s3_key}")
            
            # å¯¹ä¸­æ–‡æ–‡ä»¶åè¿›è¡ŒBase64ç¼–ç ä»¥æ”¯æŒS3 metadata
            import base64
            encoded_filename = base64.b64encode(file_name.encode('utf-8')).decode('ascii')
            
            self.s3_client.upload_fileobj(
                file_obj,
                self.bucket_name,
                s3_key,
                ExtraArgs={
                    'ContentType': content_type,
                    'Metadata': {
                        'original_filename_encoded': encoded_filename,
                        'uploaded_by': 'smart_qto_system',
                        'encoding': 'base64_utf8'
                    }
                }
            )
            
            # ç”ŸæˆS3æ–‡ä»¶URL
            file_url = f"{self.endpoint_url}/{self.bucket_name}/{s3_key}"
            
            logger.info(f"âœ… æ–‡ä»¶ä¸Šä¼ S3æˆåŠŸ: {s3_key}")
            
            return {
                "s3_key": s3_key,
                "s3_url": file_url,
                "bucket": self.bucket_name,
                "file_id": file_id,
                "original_filename": file_name
            }
            
        except ClientError as e:
            logger.error(f"âŒ S3ä¸Šä¼ å¤±è´¥: {str(e)}")
            raise Exception(f"S3ä¸Šä¼ å¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶ä¸Šä¼ å¼‚å¸¸: {str(e)}")
            raise
    
    def download_file(self, s3_key: str, local_path: str) -> bool:
        """
        ä»S3æˆ–æœ¬åœ°å­˜å‚¨ä¸‹è½½æ–‡ä»¶
        """
        if self.use_local_storage:
            return self._download_from_local(s3_key, local_path)
        else:
            return self._download_from_s3(s3_key, local_path)
    
    def _download_from_local(self, s3_key: str, local_path: str) -> bool:
        """ä»æœ¬åœ°å­˜å‚¨"ä¸‹è½½"æ–‡ä»¶ï¼ˆå®é™…æ˜¯å¤åˆ¶ï¼‰"""
        try:
            # s3_keyæ ¼å¼ï¼šfolder/filename
            source_path = self.local_storage_path / s3_key
            
            if not source_path.exists():
                logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
                return False
            
            logger.info(f"ğŸ“ ä»æœ¬åœ°å¤åˆ¶æ–‡ä»¶: {source_path} â†’ {local_path}")
            shutil.copy2(source_path, local_path)
            
            logger.info(f"âœ… æ–‡ä»¶å¤åˆ¶æˆåŠŸ: {local_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶å¤åˆ¶å¤±è´¥: {str(e)}")
            return False
    
    def _download_from_s3(self, s3_key: str, local_path: str) -> bool:
        """ä»S3ä¸‹è½½æ–‡ä»¶"""
        try:
            logger.info(f"ğŸ“¥ å¼€å§‹ä»S3ä¸‹è½½æ–‡ä»¶: {s3_key} â†’ {local_path}")
            
            self.s3_client.download_file(
                self.bucket_name,
                s3_key,
                local_path
            )
            
            logger.info(f"âœ… æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {local_path}")
            return True
            
        except ClientError as e:
            logger.error(f"âŒ S3ä¸‹è½½å¤±è´¥: {str(e)}")
            return False
        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶ä¸‹è½½å¼‚å¸¸: {str(e)}")
            return False
    
    def delete_file(self, s3_key: str) -> bool:
        """
        åˆ é™¤S3æˆ–æœ¬åœ°å­˜å‚¨æ–‡ä»¶
        """
        if self.use_local_storage:
            return self._delete_from_local(s3_key)
        else:
            return self._delete_from_s3(s3_key)
    
    def _delete_from_local(self, s3_key: str) -> bool:
        """åˆ é™¤æœ¬åœ°å­˜å‚¨æ–‡ä»¶"""
        try:
            file_path = self.local_storage_path / s3_key
            
            if file_path.exists():
                file_path.unlink()
                logger.info(f"âœ… æœ¬åœ°æ–‡ä»¶åˆ é™¤æˆåŠŸ: {file_path}")
            else:
                logger.warning(f"âš ï¸ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶åˆ é™¤å¤±è´¥: {str(e)}")
            return False
    
    def _delete_from_s3(self, s3_key: str) -> bool:
        """åˆ é™¤S3æ–‡ä»¶"""
        try:
            logger.info(f"ğŸ—‘ï¸ åˆ é™¤S3æ–‡ä»¶: {s3_key}")
            
            self.s3_client.delete_object(
                Bucket=self.bucket_name,
                Key=s3_key
            )
            
            logger.info(f"âœ… S3æ–‡ä»¶åˆ é™¤æˆåŠŸ: {s3_key}")
            return True
            
        except ClientError as e:
            logger.error(f"âŒ S3åˆ é™¤å¤±è´¥: {str(e)}")
            return False
        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶åˆ é™¤å¼‚å¸¸: {str(e)}")
            return False
    
    def decode_filename(self, encoded_filename: str) -> str:
        """
        è§£ç Base64ç¼–ç çš„æ–‡ä»¶å
        """
        try:
            import base64
            return base64.b64decode(encoded_filename.encode('ascii')).decode('utf-8')
        except Exception as e:
            logger.warning(f"æ–‡ä»¶åè§£ç å¤±è´¥: {e}")
            return encoded_filename
    
    def get_file_info(self, s3_key: str) -> Optional[dict]:
        """
        è·å–æ–‡ä»¶ä¿¡æ¯
        """
        if self.use_local_storage:
            return self._get_local_file_info(s3_key)
        else:
            return self._get_s3_file_info(s3_key)
    
    def _get_local_file_info(self, s3_key: str) -> Optional[dict]:
        """è·å–æœ¬åœ°æ–‡ä»¶ä¿¡æ¯"""
        try:
            file_path = self.local_storage_path / s3_key
            
            if not file_path.exists():
                return None
            
            stat = file_path.stat()
            return {
                "size": stat.st_size,
                "last_modified": stat.st_mtime,
                "content_type": "application/octet-stream",
                "metadata": {}
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–æœ¬åœ°æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def _get_s3_file_info(self, s3_key: str) -> Optional[dict]:
        """è·å–S3æ–‡ä»¶ä¿¡æ¯"""
        try:
            response = self.s3_client.head_object(
                Bucket=self.bucket_name,
                Key=s3_key
            )
            
            return {
                "size": response.get('ContentLength'),
                "last_modified": response.get('LastModified'),
                "content_type": response.get('ContentType'),
                "metadata": response.get('Metadata', {})
            }
            
        except ClientError as e:
            logger.error(f"âŒ è·å–S3æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"âŒ è·å–æ–‡ä»¶ä¿¡æ¯å¼‚å¸¸: {str(e)}")
            return None

    def generate_presigned_url(self, s3_key: str, expires_in: int = 3600) -> str:
        """ç”ŸæˆæŒ‡å®šæ–‡ä»¶çš„ä¸´æ—¶è®¿é—® URLï¼Œç”¨äºç»™å¤§æ¨¡å‹è¯»å–å›¾ç‰‡ç­‰èµ„æºã€‚"""
        try:
            if self.use_local_storage:
                # æœ¬åœ°å­˜å‚¨ç›´æ¥è¿”å› file:// è·¯å¾„
                local_path = self.local_storage_path / s3_key
                return f"file://{local_path.absolute()}"
            else:
                url = self.s3_client.generate_presigned_url(
                    ClientMethod="get_object",
                    Params={"Bucket": self.bucket_name, "Key": s3_key},
                    ExpiresIn=expires_in
                )
                return url
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆ presigned URL å¤±è´¥: {e}")
            raise

    def upload_content(self, content: str, s3_key: str, content_type: str = "application/json") -> bool:
        """ä¸Šä¼ å­—ç¬¦ä¸²å†…å®¹åˆ°S3æˆ–æœ¬åœ°å­˜å‚¨"""
        try:
            if self.use_local_storage:
                return self._upload_content_to_local(content, s3_key)
            else:
                return self._upload_content_to_s3(content, s3_key, content_type)
        except Exception as e:
            logger.error(f"ä¸Šä¼ å†…å®¹å¤±è´¥: {e}")
            return False
    
    def _upload_content_to_local(self, content: str, s3_key: str) -> bool:
        """ä¸Šä¼ å†…å®¹åˆ°æœ¬åœ°å­˜å‚¨"""
        try:
            file_path = self.local_storage_path / s3_key
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"âœ… å†…å®¹å·²ä¿å­˜åˆ°æœ¬åœ°: {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°å†…å®¹ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def _upload_content_to_s3(self, content: str, s3_key: str, content_type: str) -> bool:
        """ä¸Šä¼ å†…å®¹åˆ°S3"""
        try:
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=s3_key,
                Body=content.encode('utf-8'),
                ContentType=content_type
            )
            
            logger.info(f"âœ… å†…å®¹ä¸Šä¼ S3æˆåŠŸ: {s3_key}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ S3å†…å®¹ä¸Šä¼ å¤±è´¥: {e}")
            return False
    
    def get_file_url(self, s3_key: str) -> str:
        """è·å–æ–‡ä»¶è®¿é—®URL"""
        try:
            if self.use_local_storage:
                file_path = self.local_storage_path / s3_key
                return f"file://{file_path.absolute()}"
            else:
                return f"{self.endpoint_url}/{self.bucket_name}/{s3_key}"
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶URLå¤±è´¥: {e}")
            return ""
    
    def upload_txt_content(self, content: str, file_name: str, folder: str = "ocr_results/txt") -> dict:
        """
        ä¸Šä¼ æ–‡æœ¬å†…å®¹ï¼ˆTXTæ ¼å¼ï¼‰åˆ°S3æˆ–æœ¬åœ°å­˜å‚¨
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            file_name: æ–‡ä»¶å
            folder: å­˜å‚¨æ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            åŒ…å«ä¸Šä¼ ç»“æœä¿¡æ¯çš„å­—å…¸
        """
        if self.use_local_storage:
            return self._upload_txt_to_local(content, file_name, folder)
        else:
            return self._upload_txt_to_s3(content, file_name, folder)
    
    def _upload_txt_to_local(self, content: str, filename: str, folder: str) -> dict:
        """ä¸Šä¼ TXTåˆ°æœ¬åœ°å­˜å‚¨"""
        try:
            # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
            folder_path = self.local_storage_path / folder
            folder_path.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜æ–‡ä»¶
            file_path = folder_path / filename
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # ç”Ÿæˆç›¸å¯¹è·¯å¾„ä½œä¸º"s3_key"
            s3_key = f"{folder}/{filename}"
            file_url = f"file://{file_path.absolute()}"
            
            logger.info(f"âœ… TXTæ–‡ä»¶å·²ä¿å­˜åˆ°æœ¬åœ°: {file_path}")
            
            return {
                "success": True,
                "s3_key": s3_key,
                "s3_url": file_url,
                "bucket": "local",
                "filename": filename,
                "local_path": str(file_path),
                "file_size": len(content.encode('utf-8'))
            }
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°TXTæ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")
            raise Exception(f"æœ¬åœ°TXTæ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")
    
    def _upload_txt_to_s3(self, content: str, filename: str, folder: str) -> dict:
        """ä¸Šä¼ TXTåˆ°S3"""
        try:
            s3_key = f"{folder}/{filename}"
            
            logger.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ TXTæ–‡ä»¶åˆ°S3: {s3_key}")
            
            # å°†å†…å®¹ç¼–ç ä¸ºå­—èŠ‚
            content_bytes = content.encode('utf-8')
            
            # å¯¹ä¸­æ–‡æ–‡ä»¶åè¿›è¡ŒBase64ç¼–ç 
            import base64
            encoded_filename = base64.b64encode(filename.encode('utf-8')).decode('ascii')
            
            self.s3_client.put_object(
                Bucket=self.bucket_name,
                Key=s3_key,
                Body=content_bytes,
                ContentType='text/plain; charset=utf-8',
                Metadata={
                    'original_filename_encoded': encoded_filename,
                    'uploaded_by': 'smart_qto_system',
                    'encoding': 'utf8',
                    'content_type': 'paddleocr_txt_result'
                }
            )
            
            # ç”ŸæˆS3æ–‡ä»¶URL
            file_url = f"{self.endpoint_url}/{self.bucket_name}/{s3_key}"
            
            logger.info(f"âœ… TXTæ–‡ä»¶ä¸Šä¼ S3æˆåŠŸ: {s3_key}")
            
            return {
                "success": True,
                "s3_key": s3_key,
                "s3_url": file_url,
                "bucket": self.bucket_name,
                "filename": filename,
                "file_size": len(content_bytes)
            }
            
        except ClientError as e:
            logger.error(f"âŒ S3 TXTä¸Šä¼ å¤±è´¥: {str(e)}")
            raise Exception(f"S3 TXTä¸Šä¼ å¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"âŒ TXTæ–‡ä»¶ä¸Šä¼ å¼‚å¸¸: {str(e)}")
            raise

    async def download_content_async(self, s3_key: str) -> Optional[str]:
        """å¼‚æ­¥ä¸‹è½½æ–‡ä»¶å†…å®¹"""
        try:
            if self.use_local_storage:
                return await self._download_content_from_local_async(s3_key)
            else:
                return await self._download_content_from_s3_async(s3_key)
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥ä¸‹è½½å†…å®¹å¤±è´¥ {s3_key}: {e}")
            return None

    def download_content_sync(self, s3_key: str) -> Optional[str]:
        """åŒæ­¥ä¸‹è½½æ–‡ä»¶å†…å®¹"""
        try:
            if self.use_local_storage:
                return self._download_content_from_local_sync(s3_key)
            else:
                return self._download_content_from_s3_sync(s3_key)
        except Exception as e:
            logger.error(f"âŒ åŒæ­¥ä¸‹è½½å†…å®¹å¤±è´¥ {s3_key}: {e}")
            return None

    async def _download_content_from_local_async(self, s3_key: str) -> Optional[str]:
        """ä»æœ¬åœ°å­˜å‚¨å¼‚æ­¥ä¸‹è½½å†…å®¹"""
        try:
            file_path = self.local_storage_path / s3_key
            
            if not file_path.exists():
                logger.warning(f"âš ï¸ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            
            async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                content = await f.read()
            
            logger.info(f"âœ… æœ¬åœ°å†…å®¹ä¸‹è½½æˆåŠŸ: {file_path}")
            return content
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°å¼‚æ­¥ä¸‹è½½å¤±è´¥: {e}")
            return None

    def _download_content_from_local_sync(self, s3_key: str) -> Optional[str]:
        """ä»æœ¬åœ°å­˜å‚¨åŒæ­¥ä¸‹è½½å†…å®¹"""
        try:
            file_path = self.local_storage_path / s3_key
            
            if not file_path.exists():
                logger.warning(f"âš ï¸ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            logger.info(f"âœ… æœ¬åœ°å†…å®¹ä¸‹è½½æˆåŠŸ: {file_path}")
            return content
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°åŒæ­¥ä¸‹è½½å¤±è´¥: {e}")
            return None

    async def _download_content_from_s3_async(self, s3_key: str) -> Optional[str]:
        """ä»S3å¼‚æ­¥ä¸‹è½½å†…å®¹"""
        try:
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„S3æ“ä½œ
            def download_sync():
                response = self.s3_client.get_object(Bucket=self.bucket_name, Key=s3_key)
                content = response['Body'].read().decode('utf-8')
                return content
            
            content = await asyncio.get_event_loop().run_in_executor(None, download_sync)
            
            logger.info(f"âœ… S3å¼‚æ­¥å†…å®¹ä¸‹è½½æˆåŠŸ: {s3_key}")
            return content
            
        except Exception as e:
            logger.error(f"âŒ S3å¼‚æ­¥ä¸‹è½½å¤±è´¥: {e}")
            return None

    def _download_content_from_s3_sync(self, s3_key: str) -> Optional[str]:
        """ä»S3åŒæ­¥ä¸‹è½½å†…å®¹"""
        try:
            response = self.s3_client.get_object(Bucket=self.bucket_name, Key=s3_key)
            content = response['Body'].read().decode('utf-8')
            
            logger.info(f"âœ… S3åŒæ­¥å†…å®¹ä¸‹è½½æˆåŠŸ: {s3_key}")
            return content
            
        except ClientError as e:
            logger.error(f"âŒ S3åŒæ­¥ä¸‹è½½å¤±è´¥: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"âŒ S3å†…å®¹ä¸‹è½½å¼‚å¸¸: {str(e)}")
            return None

    async def download_file_async(self, s3_key: str, local_path: str) -> bool:
        """å¼‚æ­¥ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°è·¯å¾„"""
        try:
            if self.use_local_storage:
                return await self._download_file_from_local_async(s3_key, local_path)
            else:
                return await self._download_file_from_s3_async(s3_key, local_path)
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥ä¸‹è½½æ–‡ä»¶å¤±è´¥ {s3_key}: {e}")
            return False

    def download_file_sync(self, s3_key: str, local_path: str) -> bool:
        """åŒæ­¥ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°è·¯å¾„"""
        return self.download_file(s3_key, local_path)

    async def _download_file_from_local_async(self, s3_key: str, local_path: str) -> bool:
        """ä»æœ¬åœ°å­˜å‚¨å¼‚æ­¥ä¸‹è½½æ–‡ä»¶"""
        try:
            source_path = self.local_storage_path / s3_key
            
            if not source_path.exists():
                logger.warning(f"âš ï¸ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {source_path}")
                return False
            
            # åˆ›å»ºç›®æ ‡ç›®å½•
            os.makedirs(os.path.dirname(local_path), exist_ok=True)
            
            # å¼‚æ­¥å¤åˆ¶æ–‡ä»¶
            await asyncio.get_event_loop().run_in_executor(
                None, shutil.copy2, str(source_path), local_path
            )
            
            logger.info(f"âœ… æœ¬åœ°æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {local_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æœ¬åœ°å¼‚æ­¥æ–‡ä»¶ä¸‹è½½å¤±è´¥: {e}")
            return False

    async def _download_file_from_s3_async(self, s3_key: str, local_path: str) -> bool:
        """ä»S3å¼‚æ­¥ä¸‹è½½æ–‡ä»¶"""
        try:
            # åˆ›å»ºç›®æ ‡ç›®å½•
            os.makedirs(os.path.dirname(local_path), exist_ok=True)
            
            await self.s3_client.download_file(self.bucket_name, s3_key, local_path)
            
            logger.info(f"âœ… S3å¼‚æ­¥æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {local_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ S3å¼‚æ­¥æ–‡ä»¶ä¸‹è½½å¤±è´¥: {e}")
            return False

    def test_s3_connection(self):
        """
        æµ‹è¯•ä¸S3çš„è¿æ¥ã€‚å¦‚æœå¤±è´¥ï¼Œåˆ™åˆ‡æ¢åˆ°æœ¬åœ°å­˜å‚¨ã€‚
        """
        # æ­¤åŠŸèƒ½å·²ç¦ç”¨ï¼Œå› ä¸ºå®ƒä¼šå¯¼è‡´æƒé™é—®é¢˜
        pass
        # try:
        #     self.s3_client.head_bucket(Bucket=self.bucket_name)
        #     logger.info(f"âœ… S3è¿æ¥æµ‹è¯•æˆåŠŸï¼Œå¯ä»¥ä½¿ç”¨Bucket: '{self.bucket_name}'")
        # except (ClientError, NoCredentialsError) as e:
        #     logger.warning(f"âš ï¸ S3è¿æ¥æµ‹è¯•å¤±è´¥: {e}ï¼Œå°†åˆ‡æ¢åˆ°æœ¬åœ°å­˜å‚¨")
        #     self.use_local_storage = True

    def upload_file_sync(
        self, 
        file_obj: BinaryIO, 
        s3_key: str, 
        content_type: str = "application/octet-stream",
        original_filename: str = None
    ) -> dict:
        """
        ã€æ–°ã€‘åŒæ­¥ä¸Šä¼ æ–‡ä»¶åˆ°S3æˆ–æœ¬åœ°å­˜å‚¨ï¼Œä½¿ç”¨å®Œæ•´çš„s3_keyã€‚
        
        Args:
            file_obj: æ–‡ä»¶å¯¹è±¡
            s3_key: å®Œæ•´çš„S3é”® (åŒ…æ‹¬è·¯å¾„)
            content_type: å†…å®¹ç±»å‹
            original_filename: åŸå§‹æ–‡ä»¶åï¼Œç”¨äºå…ƒæ•°æ®
            
        Returns:
            ä¸Šä¼ ç»“æœ
        """
        if self.use_local_storage:
            # æœ¬åœ°å­˜å‚¨ä»ç„¶éœ€è¦æ‹†åˆ†è·¯å¾„
            parts = s3_key.split('/')
            file_name_for_local = parts[-1]
            folder_for_local = '/'.join(parts[:-1]) if len(parts) > 1 else ""
            return self._upload_to_local(file_obj, file_name_for_local, folder_for_local)
        else:
            return self._upload_to_s3_sync(file_obj, s3_key, content_type, original_filename)

    def _upload_to_s3_sync(self, file_obj: BinaryIO, s3_key: str, content_type: str, original_filename: str = None) -> dict:
        """ã€æ–°ã€‘ä½¿ç”¨å®Œæ•´çš„ s3_key ä¸Šä¼ æ–‡ä»¶åˆ°S3"""
        try:
            # å¦‚æœæ²¡æœ‰æä¾›åŸå§‹æ–‡ä»¶åï¼Œä»s3_keyä¸­æå–
            if not original_filename:
                original_filename = os.path.basename(s3_key)

            logger.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ æ–‡ä»¶åˆ°S3 (ä½¿ç”¨å®Œæ•´key): {s3_key}")
            
            # å¯¹ä¸­æ–‡æ–‡ä»¶åè¿›è¡ŒBase64ç¼–ç ä»¥æ”¯æŒS3 metadata
            import base64
            encoded_filename = base64.b64encode(original_filename.encode('utf-8')).decode('ascii')
            
            self.s3_client.upload_fileobj(
                file_obj,
                self.bucket_name,
                s3_key, # ç›´æ¥ä½¿ç”¨å®Œæ•´çš„s3_key
                ExtraArgs={
                    'ContentType': content_type,
                    'Metadata': {
                        'original_filename_encoded': encoded_filename,
                        'uploaded_by': 'smart_qto_system',
                        'encoding': 'base64_utf8'
                    }
                }
            )
            
            # ç”ŸæˆS3æ–‡ä»¶URL
            file_url = f"{self.endpoint_url}/{self.bucket_name}/{s3_key}"
            
            logger.info(f"âœ… æ–‡ä»¶ä¸Šä¼ S3æˆåŠŸ (ä½¿ç”¨å®Œæ•´key): {s3_key}")
            
            return {
                "s3_key": s3_key,
                "s3_url": file_url,
                "bucket": self.bucket_name,
                "file_id": os.path.basename(s3_key), # ä½¿ç”¨æ–‡ä»¶åä½œä¸ºè¿‘ä¼¼ID
                "original_filename": original_filename
            }
            
        except ClientError as e:
            logger.error(f"âŒ S3ä¸Šä¼ å¤±è´¥ (ä½¿ç”¨å®Œæ•´key): {s3_key}, é”™è¯¯: {str(e)}")
            raise Exception(f"S3ä¸Šä¼ å¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶ä¸Šä¼ å¼‚å¸¸ (ä½¿ç”¨å®Œæ•´key): {s3_key}, é”™è¯¯: {str(e)}")
            raise

# åˆ›å»ºå…¨å±€S3æœåŠ¡å®ä¾‹
s3_service = S3Service() 