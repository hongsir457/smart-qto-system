"""
å¢å¼ºç‰ˆVisionåˆ†æç»“æœåˆå¹¶å™¨
å®ç°ç²¾ç¡®ä½ç½®åŒ¹é…ã€ç©ºé—´é‡å åˆ¤å®šã€OCRæ–‡æœ¬è”åŠ¨ç­‰é«˜çº§åŠŸèƒ½
"""

import json
import time
import math
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import logging
import numpy as np

logger = logging.getLogger(__name__)

@dataclass
class TextRegion:
    """OCRæ–‡æœ¬åŒºåŸŸ"""
    text: str
    bbox: List[float]  # [x1, y1, x2, y2]
    confidence: float
    slice_id: str
    global_bbox: Optional[List[float]] = None

@dataclass
class ComponentMatch:
    """æ„ä»¶åŒ¹é…ç»“æœ"""
    component: Dict[str, Any]
    source_slice_id: str
    confidence: float
    matched_texts: List[TextRegion]
    spatial_relation: Dict[str, Any]

class OCRResultMerger:
    """ç‹¬ç«‹çš„OCRç»“æœåˆå¹¶å™¨"""
    
    def __init__(self, iou_threshold: float = 0.7):
        self.iou_threshold = iou_threshold
    
    def merge_all(self, slice_results: List[Dict], overlap_strategy: str = "IOU") -> List[TextRegion]:
        """
        åˆå¹¶æ‰€æœ‰åˆ‡ç‰‡çš„OCRç»“æœ
        
        Args:
            slice_results: åˆ‡ç‰‡OCRç»“æœåˆ—è¡¨
            overlap_strategy: é‡å å¤„ç†ç­–ç•¥ ("IOU", "distance", "hybrid")
            
        Returns:
            åˆå¹¶åçš„æ–‡æœ¬åŒºåŸŸåˆ—è¡¨
        """
        logger.info(f"ğŸ” å¼€å§‹OCRç»“æœåˆå¹¶: {len(slice_results)} ä¸ªåˆ‡ç‰‡ï¼Œç­–ç•¥={overlap_strategy}")
        
        all_regions = []
        
        # æ­¥éª¤1: æ”¶é›†æ‰€æœ‰æ–‡æœ¬åŒºåŸŸå¹¶è½¬æ¢ä¸ºå…¨å›¾åæ ‡
        for slice_result in slice_results:
            if not slice_result.get('success', False):
                continue
                
            slice_id = slice_result.get('slice_id', '')
            text_regions = slice_result.get('text_regions', [])
            
            for region in text_regions:
                text_region = TextRegion(
                    text=region.get('text', ''),
                    bbox=region.get('bbox', [0, 0, 0, 0]),
                    confidence=region.get('confidence', 0.0),
                    slice_id=slice_id,
                    global_bbox=self._convert_to_global_bbox(region.get('bbox', []), slice_result)
                )
                all_regions.append(text_region)
        
        logger.info(f"ğŸ“Š æ”¶é›†åˆ° {len(all_regions)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
        
        # æ­¥éª¤2: æ ¹æ®ç­–ç•¥åˆå¹¶é‡å åŒºåŸŸ
        if overlap_strategy == "IOU":
            merged_regions = self._merge_by_iou(all_regions)
        elif overlap_strategy == "distance":
            merged_regions = self._merge_by_distance(all_regions)
        elif overlap_strategy == "hybrid":
            merged_regions = self._merge_by_hybrid(all_regions)
        else:
            merged_regions = all_regions
        
        logger.info(f"âœ… OCRåˆå¹¶å®Œæˆ: {len(all_regions)} -> {len(merged_regions)} ä¸ªåŒºåŸŸ")
        return merged_regions
    
    def _convert_to_global_bbox(self, local_bbox: List[float], slice_result: Dict) -> List[float]:
        """å°†åˆ‡ç‰‡åæ ‡è½¬æ¢ä¸ºå…¨å›¾åæ ‡"""
        if len(local_bbox) != 4:
            return [0, 0, 0, 0]
        
        offset_x = slice_result.get('offset_x', 0)
        offset_y = slice_result.get('offset_y', 0)
        
        return [
            local_bbox[0] + offset_x,
            local_bbox[1] + offset_y,
            local_bbox[2] + offset_x,
            local_bbox[3] + offset_y
        ]
    
    def _merge_by_iou(self, regions: List[TextRegion]) -> List[TextRegion]:
        """åŸºäºIOUåˆå¹¶é‡å æ–‡æœ¬åŒºåŸŸ"""
        merged = []
        used_indices = set()
        
        for i, region in enumerate(regions):
            if i in used_indices:
                continue
            
            # æŸ¥æ‰¾æ‰€æœ‰ä¸å½“å‰åŒºåŸŸé‡å çš„åŒºåŸŸ
            overlapping_indices = [i]
            for j, other_region in enumerate(regions[i+1:], i+1):
                if j in used_indices:
                    continue
                
                iou = self._calculate_iou(region.global_bbox or region.bbox, 
                                        other_region.global_bbox or other_region.bbox)
                
                if iou > self.iou_threshold:
                    overlapping_indices.append(j)
            
            # åˆå¹¶é‡å åŒºåŸŸ
            if len(overlapping_indices) > 1:
                merged_region = self._merge_overlapping_regions([regions[idx] for idx in overlapping_indices])
                merged.append(merged_region)
                used_indices.update(overlapping_indices)
            else:
                merged.append(region)
                used_indices.add(i)
        
        return merged
    
    def _merge_by_distance(self, regions: List[TextRegion]) -> List[TextRegion]:
        """åŸºäºè·ç¦»åˆå¹¶é‚»è¿‘æ–‡æœ¬åŒºåŸŸ"""
        # è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
        distance_threshold = 50
        
        merged = []
        used_indices = set()
        
        for i, region in enumerate(regions):
            if i in used_indices:
                continue
            
            # æŸ¥æ‰¾é‚»è¿‘åŒºåŸŸ
            nearby_indices = [i]
            region_center = self._get_bbox_center(region.global_bbox or region.bbox)
            
            for j, other_region in enumerate(regions[i+1:], i+1):
                if j in used_indices:
                    continue
                
                other_center = self._get_bbox_center(other_region.global_bbox or other_region.bbox)
                distance = math.sqrt((region_center[0] - other_center[0])**2 + 
                                   (region_center[1] - other_center[1])**2)
                
                if distance < distance_threshold:
                    nearby_indices.append(j)
            
            # åˆå¹¶é‚»è¿‘åŒºåŸŸ
            if len(nearby_indices) > 1:
                merged_region = self._merge_overlapping_regions([regions[idx] for idx in nearby_indices])
                merged.append(merged_region)
                used_indices.update(nearby_indices)
            else:
                merged.append(region)
                used_indices.add(i)
        
        return merged
    
    def _merge_by_hybrid(self, regions: List[TextRegion]) -> List[TextRegion]:
        """æ··åˆç­–ç•¥ï¼šå…ˆIOUå†è·ç¦»"""
        # å…ˆåŸºäºIOUåˆå¹¶
        iou_merged = self._merge_by_iou(regions)
        
        # å†åŸºäºè·ç¦»åˆå¹¶
        final_merged = self._merge_by_distance(iou_merged)
        
        return final_merged
    
    def _calculate_iou(self, bbox1: List[float], bbox2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IOU"""
        if len(bbox1) != 4 or len(bbox2) != 4:
            return 0.0
        
        # è®¡ç®—äº¤é›†
        x1 = max(bbox1[0], bbox2[0])
        y1 = max(bbox1[1], bbox2[1])
        x2 = min(bbox1[2], bbox2[2])
        y2 = min(bbox1[3], bbox2[3])
        
        if x2 <= x1 or y2 <= y1:
            return 0.0
        
        intersection = (x2 - x1) * (y2 - y1)
        
        # è®¡ç®—å¹¶é›†
        area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
        area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _get_bbox_center(self, bbox: List[float]) -> Tuple[float, float]:
        """è·å–è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹"""
        if len(bbox) != 4:
            return (0.0, 0.0)
        return ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)
    
    def _merge_overlapping_regions(self, regions: List[TextRegion]) -> TextRegion:
        """åˆå¹¶å¤šä¸ªé‡å çš„æ–‡æœ¬åŒºåŸŸ"""
        if not regions:
            return None
        
        if len(regions) == 1:
            return regions[0]
        
        # åˆå¹¶æ–‡æœ¬å†…å®¹
        merged_text = " ".join([r.text for r in regions if r.text.strip()])
        
        # è®¡ç®—åˆå¹¶åçš„è¾¹ç•Œæ¡†
        all_bboxes = [r.global_bbox or r.bbox for r in regions if (r.global_bbox or r.bbox)]
        if all_bboxes:
            merged_bbox = [
                min(bbox[0] for bbox in all_bboxes),  # min x1
                min(bbox[1] for bbox in all_bboxes),  # min y1
                max(bbox[2] for bbox in all_bboxes),  # max x2
                max(bbox[3] for bbox in all_bboxes)   # max y2
            ]
        else:
            merged_bbox = [0, 0, 0, 0]
        
        # ä½¿ç”¨æœ€é«˜ç½®ä¿¡åº¦
        merged_confidence = max(r.confidence for r in regions)
        
        # åˆå¹¶åˆ‡ç‰‡ID
        slice_ids = list(set(r.slice_id for r in regions if r.slice_id))
        merged_slice_id = ",".join(slice_ids)
        
        return TextRegion(
            text=merged_text,
            bbox=merged_bbox,
            confidence=merged_confidence,
            slice_id=merged_slice_id,
            global_bbox=merged_bbox
        )

class EnhancedVisionResultMerger:
    """å¢å¼ºç‰ˆVisionåˆ†æç»“æœåˆå¹¶å™¨"""
    
    def __init__(self):
        self.ocr_merger = OCRResultMerger(iou_threshold=0.7)
        self.spatial_iou_threshold = 0.5
        self.text_association_distance = 100  # åƒç´ 
    
    def merge_vision_results_enhanced(self, 
                                    vision_results: List[Dict[str, Any]], 
                                    slice_coordinate_map: Dict[str, Any],
                                    original_image_info: Dict[str, Any],
                                    ocr_results: List[Dict] = None,
                                    task_id: str = "") -> Dict[str, Any]:
        """
        å¢å¼ºç‰ˆVisionç»“æœåˆå¹¶
        
        Args:
            vision_results: Visionåˆ†æç»“æœåˆ—è¡¨
            slice_coordinate_map: åˆ‡ç‰‡åæ ‡æ˜ å°„
            original_image_info: åŸå›¾ä¿¡æ¯
            ocr_results: OCRç»“æœï¼ˆå¯é€‰ï¼‰
            task_id: ä»»åŠ¡ID
            
        Returns:
            å¢å¼ºåˆå¹¶ç»“æœ
        """
        logger.info(f"ğŸš€ å¼€å§‹å¢å¼ºç‰ˆVisionç»“æœåˆå¹¶: {len(vision_results)} ä¸ªç»“æœ")
        start_time = time.time()
        
        # æ­¥éª¤1: ç²¾ç¡®ä½ç½®åŒ¹é… - åŸºäºbboxä¸­å¿ƒè€Œéç´¢å¼•åŒ¹é…
        matched_components = self._match_components_by_position(vision_results, slice_coordinate_map)
        logger.info(f"ğŸ“ ä½ç½®åŒ¹é…å®Œæˆ: {len(matched_components)} ä¸ªæ„ä»¶")
        
        # æ­¥éª¤2: åˆå¹¶OCRç»“æœï¼ˆå¦‚æœæä¾›ï¼‰
        merged_texts = []
        if ocr_results:
            merged_texts = self.ocr_merger.merge_all(ocr_results, overlap_strategy="hybrid")
            logger.info(f"ğŸ“ OCRåˆå¹¶å®Œæˆ: {len(merged_texts)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
        
        # æ­¥éª¤3: æ–‡æœ¬ä¸æ„ä»¶è”åŠ¨ - å°†OCRæ–‡æœ¬å…³è”åˆ°æ„ä»¶
        components_with_texts = self._associate_texts_with_components(matched_components, merged_texts)
        logger.info(f"ğŸ”— æ–‡æœ¬æ„ä»¶è”åŠ¨å®Œæˆ: {len(components_with_texts)} ä¸ªæ„ä»¶")
        
        # æ­¥éª¤4: ç©ºé—´é‡å +ç±»å‹ç›¸ä¼¼åˆ¤å®šåˆå¹¶
        final_components = self._merge_by_spatial_and_type_similarity(components_with_texts)
        logger.info(f"ğŸ”„ ç©ºé—´ç±»å‹åˆå¹¶å®Œæˆ: {len(final_components)} ä¸ªæ„ä»¶")
        
        # æ­¥éª¤5: ç”Ÿæˆå¢å¼ºç»“æœ
        enhanced_result = self._generate_enhanced_result(
            final_components, original_image_info, task_id, 
            start_time, len(vision_results), merged_texts
        )
        
        processing_time = time.time() - start_time
        logger.info(f"âœ… å¢å¼ºç‰ˆVisionåˆå¹¶å®Œæˆ: è€—æ—¶ {processing_time:.2f}s")
        
        return enhanced_result
    
    def _match_components_by_position(self, vision_results: List[Dict], 
                                    slice_coordinate_map: Dict[str, Any]) -> List[ComponentMatch]:
        """åŸºäºbboxä¸­å¿ƒç²¾ç¡®åŒ¹é…æ„ä»¶ä½ç½®"""
        logger.info("ğŸ¯ å¼€å§‹ç²¾ç¡®ä½ç½®åŒ¹é…...")
        
        matched_components = []
        
        for result in vision_results:
            if not result.get('success', False):
                continue
            
            qto_data = result.get('qto_data', {})
            components = qto_data.get('components', [])
            
            for component in components:
                # è·å–æ„ä»¶çš„è¾¹ç•Œæ¡†
                bbox = component.get('bbox')
                position = component.get('position')
                
                if not bbox and not position:
                    logger.warning(f"âš ï¸ æ„ä»¶ç¼ºå°‘ä½ç½®ä¿¡æ¯: {component.get('component_id', 'unknown')}")
                    continue
                
                # è®¡ç®—æ„ä»¶ä¸­å¿ƒç‚¹
                if bbox and len(bbox) >= 4:
                    center_x = (bbox[0] + bbox[2]) / 2
                    center_y = (bbox[1] + bbox[3]) / 2
                elif position:
                    if isinstance(position, dict):
                        center_x = position.get('x', 0)
                        center_y = position.get('y', 0)
                    elif isinstance(position, list) and len(position) >= 2:
                        center_x = position[0]
                        center_y = position[1]
                    else:
                        continue
                else:
                    continue
                
                # æŸ¥æ‰¾åŒ¹é…çš„åˆ‡ç‰‡
                matched_slice_id = self._find_slice_by_center(center_x, center_y, slice_coordinate_map)
                
                if matched_slice_id:
                    # è½¬æ¢ä¸ºå…¨å›¾åæ ‡
                    global_component = self._convert_component_to_global_coordinates(
                        component, matched_slice_id, slice_coordinate_map
                    )
                    
                    match = ComponentMatch(
                        component=global_component,
                        source_slice_id=matched_slice_id,
                        confidence=component.get('confidence', 0.8),
                        matched_texts=[],
                        spatial_relation={}
                    )
                    matched_components.append(match)
                else:
                    logger.warning(f"âš ï¸ æ— æ³•åŒ¹é…åˆ‡ç‰‡: æ„ä»¶ä¸­å¿ƒç‚¹({center_x}, {center_y})")
        
        return matched_components
    
    def _find_slice_by_center(self, center_x: float, center_y: float, 
                            slice_coordinate_map: Dict[str, Any]) -> Optional[str]:
        """æ ¹æ®ä¸­å¿ƒç‚¹æŸ¥æ‰¾å¯¹åº”çš„åˆ‡ç‰‡"""
        for slice_id, slice_info in slice_coordinate_map.items():
            offset_x = slice_info.get('offset_x', 0)
            offset_y = slice_info.get('offset_y', 0)
            width = slice_info.get('slice_width', slice_info.get('width', 0))
            height = slice_info.get('slice_height', slice_info.get('height', 0))
            
            # æ£€æŸ¥ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨åˆ‡ç‰‡èŒƒå›´å†…
            if (offset_x <= center_x <= offset_x + width and 
                offset_y <= center_y <= offset_y + height):
                return slice_id
        
        return None
    
    def _convert_component_to_global_coordinates(self, component: Dict, 
                                               slice_id: str, 
                                               slice_coordinate_map: Dict) -> Dict:
        """å°†æ„ä»¶åæ ‡è½¬æ¢ä¸ºå…¨å›¾åæ ‡"""
        slice_info = slice_coordinate_map.get(slice_id, {})
        offset_x = slice_info.get('offset_x', 0)
        offset_y = slice_info.get('offset_y', 0)
        
        global_component = component.copy()
        
        # è½¬æ¢è¾¹ç•Œæ¡†
        if 'bbox' in component and len(component['bbox']) >= 4:
            bbox = component['bbox']
            global_component['bbox'] = [
                bbox[0] + offset_x,
                bbox[1] + offset_y,
                bbox[2] + offset_x,
                bbox[3] + offset_y
            ]
        
        # è½¬æ¢ä½ç½®
        if 'position' in component:
            position = component['position']
            if isinstance(position, dict):
                global_component['position'] = {
                    'x': position.get('x', 0) + offset_x,
                    'y': position.get('y', 0) + offset_y
                }
            elif isinstance(position, list) and len(position) >= 2:
                global_component['position'] = [
                    position[0] + offset_x,
                    position[1] + offset_y
                ]
        
        # æ·»åŠ åˆ‡ç‰‡æ¥æºä¿¡æ¯
        global_component['slice_source'] = {
            'slice_id': slice_id,
            'offset': (offset_x, offset_y)
        }
        
        return global_component
    
    def _associate_texts_with_components(self, component_matches: List[ComponentMatch], 
                                       text_regions: List[TextRegion]) -> List[ComponentMatch]:
        """å°†OCRæ–‡æœ¬ä¸æ„ä»¶å…³è”"""
        logger.info(f"ğŸ”— å¼€å§‹æ–‡æœ¬æ„ä»¶è”åŠ¨: {len(component_matches)} æ„ä»¶ Ã— {len(text_regions)} æ–‡æœ¬")
        
        for match in component_matches:
            component = match.component
            component_bbox = component.get('bbox')
            
            if not component_bbox or len(component_bbox) < 4:
                continue
            
            # æŸ¥æ‰¾é‚»è¿‘çš„æ–‡æœ¬
            nearby_texts = []
            for text_region in text_regions:
                text_bbox = text_region.global_bbox or text_region.bbox
                
                if not text_bbox or len(text_bbox) < 4:
                    continue
                
                # è®¡ç®—è·ç¦»
                distance = self._calculate_bbox_distance(component_bbox, text_bbox)
                
                if distance <= self.text_association_distance:
                    nearby_texts.append(text_region)
            
            # å°†æ–‡æœ¬æ·»åŠ åˆ°æ„ä»¶
            match.matched_texts = nearby_texts
            
            # æ›´æ–°æ„ä»¶çš„æ–‡æœ¬æ ‡ç­¾
            if nearby_texts:
                text_tags = [t.text for t in nearby_texts if t.text.strip()]
                component['text_tags'] = text_tags
                component['associated_text_count'] = len(nearby_texts)
                
                # å°è¯•ä»æ–‡æœ¬ä¸­æå–è§„æ ¼ä¿¡æ¯
                extracted_specs = self._extract_specs_from_texts(text_tags)
                if extracted_specs:
                    component['extracted_specifications'] = extracted_specs
        
        return component_matches
    
    def _calculate_bbox_distance(self, bbox1: List[float], bbox2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„æœ€çŸ­è·ç¦»"""
        # è·å–ä¸­å¿ƒç‚¹
        center1 = ((bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2)
        center2 = ((bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2)
        
        # è®¡ç®—ä¸­å¿ƒç‚¹è·ç¦»
        return math.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)
    
    def _extract_specs_from_texts(self, texts: List[str]) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­æå–è§„æ ¼ä¿¡æ¯"""
        specs = {}
        
        for text in texts:
            # å°ºå¯¸ä¿¡æ¯
            dimension_patterns = [
                r'(\d+)\s*[xXÃ—]\s*(\d+)',  # 300x600
                r'[bBhH]?\s*(\d+)',        # b300, h600
                r'(\d+)\s*mm'              # 300mm
            ]
            
            for pattern in dimension_patterns:
                import re
                matches = re.findall(pattern, text)
                if matches:
                    specs['dimensions'] = matches
                    break
            
            # ææ–™ä¿¡æ¯
            material_patterns = [
                r'C\d{2}',      # C30
                r'HRB\d{3}',    # HRB400
                r'Q\d{3}'       # Q235
            ]
            
            for pattern in material_patterns:
                import re
                matches = re.findall(pattern, text)
                if matches:
                    specs['materials'] = matches
                    break
        
        return specs
    
    def _merge_by_spatial_and_type_similarity(self, component_matches: List[ComponentMatch]) -> List[Dict]:
        """åŸºäºç©ºé—´é‡å å’Œç±»å‹ç›¸ä¼¼æ€§åˆå¹¶æ„ä»¶"""
        logger.info(f"ğŸ”„ å¼€å§‹ç©ºé—´ç±»å‹åˆå¹¶: {len(component_matches)} ä¸ªæ„ä»¶")
        
        merged_components = []
        used_indices = set()
        
        for i, match in enumerate(component_matches):
            if i in used_indices:
                continue
            
            component = match.component
            
            # æŸ¥æ‰¾éœ€è¦åˆå¹¶çš„æ„ä»¶
            merge_candidates = [i]
            
            for j, other_match in enumerate(component_matches[i+1:], i+1):
                if j in used_indices:
                    continue
                
                other_component = other_match.component
                
                # æ£€æŸ¥ç©ºé—´é‡å 
                spatial_overlap = self._check_spatial_overlap(component, other_component)
                
                # æ£€æŸ¥ç±»å‹ç›¸ä¼¼æ€§
                type_similarity = self._check_type_similarity(component, other_component)
                
                # å¦‚æœæ»¡è¶³åˆå¹¶æ¡ä»¶
                if spatial_overlap > self.spatial_iou_threshold or type_similarity > 0.8:
                    merge_candidates.append(j)
            
            # æ‰§è¡Œåˆå¹¶
            if len(merge_candidates) > 1:
                merged_component = self._merge_similar_components([component_matches[idx] for idx in merge_candidates])
                merged_components.append(merged_component)
                used_indices.update(merge_candidates)
                logger.debug(f"ğŸ“¦ åˆå¹¶æ„ä»¶: {len(merge_candidates)} ä¸ª -> 1 ä¸ª")
            else:
                merged_components.append(component)
                used_indices.add(i)
        
        logger.info(f"âœ… ç©ºé—´ç±»å‹åˆå¹¶å®Œæˆ: {len(component_matches)} -> {len(merged_components)} ä¸ªæ„ä»¶")
        return merged_components
    
    def _check_spatial_overlap(self, comp1: Dict, comp2: Dict) -> float:
        """æ£€æŸ¥ä¸¤ä¸ªæ„ä»¶çš„ç©ºé—´é‡å åº¦"""
        bbox1 = comp1.get('bbox')
        bbox2 = comp2.get('bbox')
        
        if not bbox1 or not bbox2 or len(bbox1) < 4 or len(bbox2) < 4:
            return 0.0
        
        return self.ocr_merger._calculate_iou(bbox1, bbox2)
    
    def _check_type_similarity(self, comp1: Dict, comp2: Dict) -> float:
        """æ£€æŸ¥ä¸¤ä¸ªæ„ä»¶çš„ç±»å‹ç›¸ä¼¼æ€§"""
        type1 = comp1.get('component_type', '').lower()
        type2 = comp2.get('component_type', '').lower()
        
        if not type1 or not type2:
            return 0.0
        
        # ç®€å•çš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
        if type1 == type2:
            return 1.0
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›¸ä¼¼ç±»å‹ï¼ˆå¦‚ï¼šæ¢ vs ä¸»æ¢ï¼‰
        similar_types = [
            ['æ¢', 'ä¸»æ¢', 'æ¬¡æ¢'],
            ['æŸ±', 'æ¡†æ¶æŸ±', 'å‰ªåŠ›å¢™æŸ±'],
            ['æ¿', 'æ¥¼æ¿', 'å±‹é¢æ¿'],
            ['å¢™', 'å‰ªåŠ›å¢™', 'å¡«å……å¢™']
        ]
        
        for group in similar_types:
            if type1 in group and type2 in group:
                return 0.8
        
        return 0.0
    
    def _merge_similar_components(self, matches: List[ComponentMatch]) -> Dict:
        """åˆå¹¶ç›¸ä¼¼çš„æ„ä»¶"""
        if not matches:
            return {}
        
        if len(matches) == 1:
            return matches[0].component
        
        # åŸºç¡€ä¿¡æ¯ä½¿ç”¨ç¬¬ä¸€ä¸ªæ„ä»¶
        merged = matches[0].component.copy()
        
        # åˆå¹¶æ•°é‡
        total_quantity = sum(match.component.get('quantity', 0) for match in matches)
        merged['quantity'] = total_quantity
        
        # åˆå¹¶æ–‡æœ¬æ ‡ç­¾
        all_text_tags = []
        for match in matches:
            text_tags = match.component.get('text_tags', [])
            all_text_tags.extend(text_tags)
        
        if all_text_tags:
            # å»é‡å¹¶ä¿æŒé¡ºåº
            unique_tags = []
            seen = set()
            for tag in all_text_tags:
                if tag not in seen:
                    unique_tags.append(tag)
                    seen.add(tag)
            merged['text_tags'] = unique_tags
        
        # åˆå¹¶è¾¹ç•Œæ¡†ï¼ˆå–å¤–åŒ…çŸ©å½¢ï¼‰
        all_bboxes = [match.component.get('bbox') for match in matches if match.component.get('bbox')]
        if all_bboxes:
            merged_bbox = [
                min(bbox[0] for bbox in all_bboxes),  # min x1
                min(bbox[1] for bbox in all_bboxes),  # min y1
                max(bbox[2] for bbox in all_bboxes),  # max x2
                max(bbox[3] for bbox in all_bboxes)   # max y2
            ]
            merged['bbox'] = merged_bbox
        
        # åˆå¹¶åˆ‡ç‰‡æ¥æº
        slice_sources = [match.source_slice_id for match in matches]
        merged['slice_sources'] = list(set(slice_sources))
        
        # æ·»åŠ åˆå¹¶å…ƒæ•°æ®
        merged['merge_metadata'] = {
            'merged_count': len(matches),
            'merge_method': 'spatial_and_type_similarity',
            'confidence_scores': [match.confidence for match in matches]
        }
        
        return merged
    
    def _generate_enhanced_result(self, final_components: List[Dict], 
                                original_image_info: Dict, task_id: str,
                                start_time: float, input_count: int,
                                merged_texts: List[TextRegion]) -> Dict[str, Any]:
        """ç”Ÿæˆå¢å¼ºåˆå¹¶ç»“æœ"""
        processing_time = time.time() - start_time
        
        # æ„ä»¶ç±»å‹åˆ†å¸ƒç»Ÿè®¡
        type_distribution = {}
        for comp in final_components:
            comp_type = comp.get('component_type', 'æœªçŸ¥')
            type_distribution[comp_type] = type_distribution.get(comp_type, 0) + 1
        
        # æ–‡æœ¬ç»Ÿè®¡
        text_stats = {
            'total_text_regions': len(merged_texts),
            'associated_texts': sum(1 for comp in final_components if comp.get('text_tags')),
            'average_texts_per_component': len([comp for comp in final_components if comp.get('text_tags')]) / len(final_components) if final_components else 0
        }
        
        return {
            'success': True,
            'task_id': task_id,
            'enhanced_result': {
                'components': final_components,
                'component_count': len(final_components),
                'type_distribution': type_distribution,
                'text_integration': text_stats,
                'processing_metadata': {
                    'input_vision_results': input_count,
                    'final_components': len(final_components),
                    'processing_time_seconds': processing_time,
                    'enhancement_features': [
                        'precise_position_matching',
                        'spatial_overlap_detection',
                        'text_component_association',
                        'type_similarity_merging'
                    ]
                }
            },
            'original_image_info': original_image_info,
            'timestamp': time.time()
        } 