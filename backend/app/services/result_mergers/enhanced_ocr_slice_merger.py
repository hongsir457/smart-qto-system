"""
å¢å¼ºç‰ˆOCRåˆ‡ç‰‡ç»“æœåˆå¹¶å™¨
å®ç°PaddleOCRåˆ‡ç‰‡æ‰«æåˆå¹¶çš„å››å¤§æ ¸å¿ƒç›®æ ‡ï¼š
1. ä¸ä¸¢å†…å®¹ - å…¨å›¾ä¸­æ‰€æœ‰æ–‡å­—ã€å›¾çº¸ä¿¡æ¯å¿…é¡»è¢«ä¿ç•™ï¼Œä¸é—æ¼ä»»ä½•åˆ‡ç‰‡è¾¹ç¼˜çš„æ–‡å­—
2. ä¸é‡å¤å†…å®¹ - å¯¹é‡å åŒºåŸŸå†…åŒä¸€æ–‡å­—ï¼Œåªä¿ç•™ä¸€æ¬¡ï¼Œå»é™¤é‡å¤æ–‡æœ¬
3. æ­£ç¡®æ’åº - æ–‡æœ¬ç»“æœèƒ½ä¿æŒå›¾çº¸åŸæœ‰çš„é˜…è¯»é¡ºåºï¼ˆè¡Œåˆ—æˆ–åŒºåŸŸåˆ†ç»„ï¼‰
4. æ¢å¤å…¨å›¾åæ ‡ - OCRç»“æœä¸­bboxåæ ‡å¿…é¡»ä»åˆ‡ç‰‡å†…åæ ‡è¿˜åŸä¸ºåŸå›¾ç»å¯¹åæ ‡
"""

import json
import time
import math
from typing import Dict, List, Any, Tuple, Optional, Set
from dataclasses import dataclass, asdict
import logging
from collections import defaultdict
import re

logger = logging.getLogger(__name__)

@dataclass
class TextRegion:
    """æ–‡æœ¬åŒºåŸŸæ•°æ®ç»“æ„"""
    text: str
    bbox: List[int]  # [x1, y1, x2, y2] å…¨å›¾åæ ‡
    confidence: float
    slice_source: Dict[str, Any]
    polygon: Optional[List[List[int]]] = None
    text_type: str = "unknown"  # æ–‡æœ¬ç±»å‹ï¼šcomponent_id, dimension, materialç­‰
    reading_order: int = -1  # é˜…è¯»é¡ºåº
    region_id: str = ""  # å”¯ä¸€åŒºåŸŸID

@dataclass
class MergeStatistics:
    """åˆå¹¶ç»Ÿè®¡ä¿¡æ¯"""
    total_input_regions: int
    edge_preserved_regions: int
    duplicate_removed_count: int
    final_regions_count: int
    coordinate_restored_count: int
    processing_time: float
    
class EnhancedOCRSliceMerger:
    """å¢å¼ºç‰ˆOCRåˆ‡ç‰‡åˆå¹¶å™¨ - å®ç°å››å¤§æ ¸å¿ƒç›®æ ‡"""
    
    def __init__(self, storage_service=None):
        self.storage_service = storage_service
        self.overlap_threshold = 0.3  # é‡å é˜ˆå€¼
        self.similarity_threshold = 0.85  # æ–‡æœ¬ç›¸ä¼¼åº¦é˜ˆå€¼
        self.edge_proximity_threshold = 20  # è¾¹ç¼˜æ–‡æœ¬ä¿æŠ¤è·ç¦»
        
    def merge_slice_results_enhanced(self, 
                                   slice_results: List[Dict[str, Any]], 
                                   slice_coordinate_map: Dict[str, Any],
                                   original_image_info: Dict[str, Any],
                                   task_id: str) -> Dict[str, Any]:
        """
        å¢å¼ºç‰ˆåˆ‡ç‰‡ç»“æœåˆå¹¶ - å®ç°å››å¤§æ ¸å¿ƒç›®æ ‡
        
        Args:
            slice_results: åˆ‡ç‰‡OCRç»“æœåˆ—è¡¨
            slice_coordinate_map: åˆ‡ç‰‡åæ ‡æ˜ å°„è¡¨
            original_image_info: åŸå›¾ä¿¡æ¯
            task_id: ä»»åŠ¡ID
            
        Returns:
            å¢å¼ºåˆå¹¶ç»“æœ
        """
        logger.info(f"ğŸš€ å¼€å§‹å¢å¼ºç‰ˆOCRåˆ‡ç‰‡åˆå¹¶: {len(slice_results)} ä¸ªåˆ‡ç‰‡")
        start_time = time.time()
        
        # ç»Ÿè®¡åŸå§‹æ•°æ®
        total_input_regions = sum(
            len(result.get('text_regions', [])) 
            for result in slice_results 
            if result.get('success', False)
        )
        
        # ç›®æ ‡1: ä¸ä¸¢å†…å®¹ - å…¨é¢æ”¶é›†æ‰€æœ‰æ–‡æœ¬åŒºåŸŸï¼Œç‰¹åˆ«ä¿æŠ¤è¾¹ç¼˜æ–‡æœ¬
        all_regions = self._collect_all_text_regions_with_edge_protection(
            slice_results, slice_coordinate_map
        )
        logger.info(f"ğŸ“¥ æ”¶é›†å®Œæˆ: {len(all_regions)} ä¸ªæ–‡æœ¬åŒºåŸŸï¼ˆå«è¾¹ç¼˜ä¿æŠ¤ï¼‰")
        
        # ç›®æ ‡4: æ¢å¤å…¨å›¾åæ ‡ - å°†æ‰€æœ‰åˆ‡ç‰‡åæ ‡è¿˜åŸä¸ºå…¨å›¾åæ ‡
        restored_regions = self._restore_all_coordinates_to_global(
            all_regions, slice_coordinate_map
        )
        logger.info(f"ğŸŒ åæ ‡è¿˜åŸå®Œæˆ: {len(restored_regions)} ä¸ªåŒºåŸŸ")
        
        # ç›®æ ‡2: ä¸é‡å¤å†…å®¹ - æ™ºèƒ½å»é™¤é‡å åŒºåŸŸçš„é‡å¤æ–‡æœ¬
        deduplicated_regions = self._smart_deduplication_with_context(
            restored_regions, original_image_info
        )
        duplicate_count = len(restored_regions) - len(deduplicated_regions)
        logger.info(f"ğŸ”„ æ™ºèƒ½å»é‡å®Œæˆ: ç§»é™¤ {duplicate_count} ä¸ªé‡å¤åŒºåŸŸ")
        
        # ç›®æ ‡3: æ­£ç¡®æ’åº - æŒ‰å›¾çº¸é˜…è¯»é¡ºåºé‡æ–°æ’åˆ—
        sorted_regions = self._sort_by_reading_order_enhanced(
            deduplicated_regions, original_image_info
        )
        logger.info(f"ğŸ“– é˜…è¯»æ’åºå®Œæˆ: {len(sorted_regions)} ä¸ªåŒºåŸŸ")
        
        # ç”Ÿæˆåˆå¹¶ç»Ÿè®¡
        stats = MergeStatistics(
            total_input_regions=total_input_regions,
            edge_preserved_regions=len([r for r in all_regions if r.slice_source.get('is_edge_text', False)]),
            duplicate_removed_count=duplicate_count,
            final_regions_count=len(sorted_regions),
            coordinate_restored_count=len(restored_regions),
            processing_time=time.time() - start_time
        )
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        final_result = self._generate_enhanced_result(
            sorted_regions, original_image_info, task_id, stats
        )
        
        logger.info(f"âœ… å¢å¼ºåˆå¹¶å®Œæˆ: {total_input_regions} -> {len(sorted_regions)} ä¸ªåŒºåŸŸï¼Œè€—æ—¶ {stats.processing_time:.2f}s")
        return final_result
    
    def _collect_all_text_regions_with_edge_protection(self, 
                                                      slice_results: List[Dict[str, Any]], 
                                                      slice_coordinate_map: Dict[str, Any]) -> List[TextRegion]:
        """ç›®æ ‡1: ä¸ä¸¢å†…å®¹ - å…¨é¢æ”¶é›†æ–‡æœ¬åŒºåŸŸå¹¶ä¿æŠ¤è¾¹ç¼˜æ–‡æœ¬"""
        
        all_regions = []
        edge_protected_count = 0
        
        for i, slice_result in enumerate(slice_results):
            if not slice_result.get('success', False):
                continue
                
            slice_info = slice_coordinate_map.get(i, {})
            text_regions = slice_result.get('text_regions', [])
            
            for region_data in text_regions:
                if not region_data.get('text', '').strip():
                    continue
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºè¾¹ç¼˜æ–‡æœ¬
                is_edge_text = self._is_edge_text(region_data, slice_info)
                if is_edge_text:
                    edge_protected_count += 1
                
                # åˆ›å»ºæ–‡æœ¬åŒºåŸŸå¯¹è±¡
                text_region = TextRegion(
                    text=region_data.get('text', '').strip(),
                    bbox=region_data.get('bbox', [0, 0, 0, 0]),
                    confidence=region_data.get('confidence', 0.0),
                    slice_source={
                        'slice_index': i,
                        'slice_id': slice_info.get('slice_id', f'slice_{i}'),
                        'slice_bounds': [
                            slice_info.get('offset_x', 0),
                            slice_info.get('offset_y', 0),
                            slice_info.get('slice_width', 0),
                            slice_info.get('slice_height', 0)
                        ],
                        'is_edge_text': is_edge_text,
                        'original_bbox': region_data.get('bbox', [])
                    },
                    polygon=region_data.get('polygon'),
                    text_type=self._classify_text_type(region_data.get('text', '')),
                    region_id=f"region_{i}_{len(all_regions)}"
                )
                
                all_regions.append(text_region)
        
        logger.info(f"ğŸ›¡ï¸ è¾¹ç¼˜æ–‡æœ¬ä¿æŠ¤: {edge_protected_count} ä¸ªè¾¹ç¼˜åŒºåŸŸ")
        return all_regions
    
    def _is_edge_text(self, region_data: Dict[str, Any], slice_info: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºéœ€è¦ä¿æŠ¤çš„è¾¹ç¼˜æ–‡æœ¬"""
        
        bbox = region_data.get('bbox', [0, 0, 0, 0])
        if len(bbox) < 4:
            return False
            
        slice_width = slice_info.get('slice_width', 0)
        slice_height = slice_info.get('slice_height', 0)
        
        if slice_width == 0 or slice_height == 0:
            return False
        
        # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦é è¿‘åˆ‡ç‰‡è¾¹ç¼˜
        x1, y1, x2, y2 = bbox
        
        near_left = x1 <= self.edge_proximity_threshold
        near_right = x2 >= slice_width - self.edge_proximity_threshold
        near_top = y1 <= self.edge_proximity_threshold
        near_bottom = y2 >= slice_height - self.edge_proximity_threshold
        
        return near_left or near_right or near_top or near_bottom
    
    def _classify_text_type(self, text: str) -> str:
        """åˆ†ç±»æ–‡æœ¬ç±»å‹"""
        
        text_clean = text.strip()
        
        # æ„ä»¶ç¼–å·æ¨¡å¼
        if re.match(r'^[A-Z]{1,3}\d+[A-Z]*$', text_clean):
            return "component_id"
        
        # å°ºå¯¸æ ‡æ³¨æ¨¡å¼
        if re.search(r'\d+(\.\d+)?[Ã—x]\d+(\.\d+)?', text_clean) or \
           re.search(r'\d+(\.\d+)?\s*[mM]{2}?\s*$', text_clean):
            return "dimension"
        
        # ææ–™æ ‡å·æ¨¡å¼
        if re.match(r'^[CHR][0-9]+[AB]?$', text_clean):
            return "material"
        
        # è½´çº¿ç¼–å·æ¨¡å¼
        if re.match(r'^[A-Z]$', text_clean) or re.match(r'^\d+$', text_clean):
            return "axis"
        
        # è¯´æ˜æ–‡å­—
        if len(text_clean) > 10 and any(char in text_clean for char in 'è¯´æ˜æ³¨å¤‡'):
            return "description"
        
        return "unknown"
    
    def _restore_all_coordinates_to_global(self, 
                                         regions: List[TextRegion], 
                                         slice_coordinate_map: Dict[str, Any]) -> List[TextRegion]:
        """ç›®æ ‡4: æ¢å¤å…¨å›¾åæ ‡ - å°†åˆ‡ç‰‡åæ ‡è¿˜åŸä¸ºåŸå›¾ç»å¯¹åæ ‡"""
        
        restored_regions = []
        
        for region in regions:
            slice_index = region.slice_source['slice_index']
            slice_info = slice_coordinate_map.get(slice_index, {})
            
            offset_x = slice_info.get('offset_x', 0)
            offset_y = slice_info.get('offset_y', 0)
            
            # è¿˜åŸbboxåæ ‡
            original_bbox = region.bbox
            if len(original_bbox) >= 4:
                global_bbox = [
                    original_bbox[0] + offset_x,  # x1
                    original_bbox[1] + offset_y,  # y1
                    original_bbox[2] + offset_x,  # x2
                    original_bbox[3] + offset_y   # y2
                ]
                
                # åˆ›å»ºæ–°çš„åŒºåŸŸå¯¹è±¡
                restored_region = TextRegion(
                    text=region.text,
                    bbox=global_bbox,
                    confidence=region.confidence,
                    slice_source=region.slice_source.copy(),
                    polygon=self._restore_polygon_coordinates(region.polygon, offset_x, offset_y),
                    text_type=region.text_type,
                    region_id=region.region_id
                )
                
                # è®°å½•åæ ‡å˜æ¢ä¿¡æ¯
                restored_region.slice_source['coordinate_transform'] = {
                    'offset': (offset_x, offset_y),
                    'original_bbox': original_bbox,
                    'global_bbox': global_bbox
                }
                
                restored_regions.append(restored_region)
        
        return restored_regions
    
    def _restore_polygon_coordinates(self, 
                                   polygon: Optional[List[List[int]]], 
                                   offset_x: int, 
                                   offset_y: int) -> Optional[List[List[int]]]:
        """è¿˜åŸå¤šè¾¹å½¢åæ ‡"""
        
        if not polygon:
            return None
        
        restored_polygon = []
        for point in polygon:
            if isinstance(point, list) and len(point) >= 2:
                restored_polygon.append([
                    point[0] + offset_x,
                    point[1] + offset_y
                ])
            else:
                restored_polygon.append(point)
        
        return restored_polygon
    
    def _smart_deduplication_with_context(self, 
                                        regions: List[TextRegion], 
                                        original_image_info: Dict[str, Any]) -> List[TextRegion]:
        """ç›®æ ‡2: ä¸é‡å¤å†…å®¹ - æ™ºèƒ½å»é‡ï¼Œè€ƒè™‘ä¸Šä¸‹æ–‡å’Œä½ç½®"""
        
        if not regions:
            return []
        
        # æŒ‰ç½®ä¿¡åº¦æ’åºï¼ˆé«˜ç½®ä¿¡åº¦ä¼˜å…ˆä¿ç•™ï¼‰
        sorted_regions = sorted(regions, key=lambda x: x.confidence, reverse=True)
        
        # æ„å»ºç©ºé—´ç´¢å¼•åŠ é€ŸæŸ¥æ‰¾
        spatial_index = self._build_spatial_index(sorted_regions, original_image_info)
        
        deduplicated = []
        processed_ids = set()
        
        for current_region in sorted_regions:
            if current_region.region_id in processed_ids:
                continue
            
            # æŸ¥æ‰¾æ½œåœ¨é‡å¤åŒºåŸŸ
            candidates = self._find_duplicate_candidates(
                current_region, spatial_index, deduplicated
            )
            
            # æ™ºèƒ½é‡å¤åˆ¤æ–­
            is_duplicate = False
            for candidate in candidates:
                if self._is_intelligent_duplicate(current_region, candidate):
                    is_duplicate = True
                    logger.debug(f"æ£€æµ‹åˆ°æ™ºèƒ½é‡å¤: '{current_region.text}' vs '{candidate.text}'")
                    break
            
            if not is_duplicate:
                deduplicated.append(current_region)
                processed_ids.add(current_region.region_id)
        
        return deduplicated
    
    def _build_spatial_index(self, 
                           regions: List[TextRegion], 
                           original_image_info: Dict[str, Any]) -> Dict[str, List[TextRegion]]:
        """æ„å»ºç©ºé—´ç´¢å¼•ä»¥åŠ é€ŸæŸ¥æ‰¾"""
        
        image_width = original_image_info.get('width', 1000)
        image_height = original_image_info.get('height', 1000)
        
        # ç½‘æ ¼å¤§å°
        grid_size = 100
        cols = math.ceil(image_width / grid_size)
        rows = math.ceil(image_height / grid_size)
        
        spatial_index = defaultdict(list)
        
        for region in regions:
            bbox = region.bbox
            if len(bbox) >= 4:
                # è®¡ç®—æ–‡æœ¬åŒºåŸŸæ‰€å çš„ç½‘æ ¼
                x1, y1, x2, y2 = bbox
                
                grid_x1 = max(0, min(cols - 1, int(x1 // grid_size)))
                grid_y1 = max(0, min(rows - 1, int(y1 // grid_size)))
                grid_x2 = max(0, min(cols - 1, int(x2 // grid_size)))
                grid_y2 = max(0, min(rows - 1, int(y2 // grid_size)))
                
                # å°†åŒºåŸŸæ·»åŠ åˆ°æ‰€æœ‰ç›¸å…³ç½‘æ ¼
                for gy in range(grid_y1, grid_y2 + 1):
                    for gx in range(grid_x1, grid_x2 + 1):
                        grid_key = f"{gx}_{gy}"
                        spatial_index[grid_key].append(region)
        
        return spatial_index
    
    def _find_duplicate_candidates(self, 
                                 region: TextRegion, 
                                 spatial_index: Dict[str, List[TextRegion]], 
                                 existing_regions: List[TextRegion]) -> List[TextRegion]:
        """æŸ¥æ‰¾é‡å¤å€™é€‰åŒºåŸŸ"""
        
        candidates = set()
        bbox = region.bbox
        
        if len(bbox) >= 4:
            # è®¡ç®—å½“å‰åŒºåŸŸçš„ç½‘æ ¼èŒƒå›´
            grid_size = 100
            x1, y1, x2, y2 = bbox
            
            grid_x = int((x1 + x2) / 2 // grid_size)
            grid_y = int((y1 + y2) / 2 // grid_size)
            
            # æœç´¢å‘¨å›´ç½‘æ ¼
            for dy in range(-1, 2):
                for dx in range(-1, 2):
                    grid_key = f"{grid_x + dx}_{grid_y + dy}"
                    candidates.update(spatial_index.get(grid_key, []))
        
        # è¿‡æ»¤å‡ºå·²å­˜åœ¨çš„åŒºåŸŸ
        return [c for c in candidates if c in existing_regions]
    
    def _is_intelligent_duplicate(self, region1: TextRegion, region2: TextRegion) -> bool:
        """æ™ºèƒ½é‡å¤åˆ¤æ–­ - ç»¼åˆè€ƒè™‘æ–‡æœ¬ç›¸ä¼¼åº¦ã€ä½ç½®é‡å å’Œä¸Šä¸‹æ–‡"""
        
        # æ–‡æœ¬ç›¸ä¼¼åº¦
        text_similarity = self._calculate_text_similarity_enhanced(region1.text, region2.text)
        
        # ä½ç½®é‡å åº¦
        overlap_ratio = self._calculate_bbox_overlap_ratio(region1.bbox, region2.bbox)
        
        # å‡ ä½•ç›¸ä¼¼åº¦ï¼ˆå°ºå¯¸ç›¸ä¼¼æ€§ï¼‰
        size_similarity = self._calculate_size_similarity(region1.bbox, region2.bbox)
        
        # ä¸Šä¸‹æ–‡ç›¸ä¼¼åº¦ï¼ˆæ–‡æœ¬ç±»å‹æ˜¯å¦ä¸€è‡´ï¼‰
        context_match = region1.text_type == region2.text_type
        
        # ç»¼åˆåˆ¤æ–­è§„åˆ™
        # è§„åˆ™1: é«˜æ–‡æœ¬ç›¸ä¼¼åº¦ + ä½ç½®é‡å 
        if text_similarity > 0.9 and overlap_ratio > 0.3:
            return True
        
        # è§„åˆ™2: å®Œå…¨ç›¸åŒæ–‡æœ¬ + åˆç†é‡å 
        if text_similarity == 1.0 and overlap_ratio > 0.1:
            return True
        
        # è§„åˆ™3: é«˜ä½ç½®é‡å  + ä¸­ç­‰æ–‡æœ¬ç›¸ä¼¼åº¦ + ä¸Šä¸‹æ–‡åŒ¹é…
        if overlap_ratio > 0.7 and text_similarity > 0.7 and context_match:
            return True
        
        # è§„åˆ™4: ç‰¹æ®Šå¤„ç† - æ„ä»¶ç¼–å·ç­‰å…³é”®ä¿¡æ¯
        if region1.text_type in ['component_id', 'axis'] and \
           text_similarity > 0.8 and overlap_ratio > 0.2:
            return True
        
        return False
    
    def _calculate_text_similarity_enhanced(self, text1: str, text2: str) -> float:
        """å¢å¼ºæ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—"""
        
        if not text1 or not text2:
            return 0.0
        
        # æ ‡å‡†åŒ–æ–‡æœ¬
        clean_text1 = re.sub(r'\s+', '', text1.strip().upper())
        clean_text2 = re.sub(r'\s+', '', text2.strip().upper())
        
        if clean_text1 == clean_text2:
            return 1.0
        
        # è®¡ç®—ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦
        def levenshtein_ratio(s1, s2):
            if len(s1) == 0 or len(s2) == 0:
                return 0.0
            
            max_len = max(len(s1), len(s2))
            distance = self._levenshtein_distance(s1, s2)
            return 1.0 - (distance / max_len)
        
        return levenshtein_ratio(clean_text1, clean_text2)
    
    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """è®¡ç®—ç¼–è¾‘è·ç¦»"""
        
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    def _calculate_bbox_overlap_ratio(self, bbox1: List[int], bbox2: List[int]) -> float:
        """è®¡ç®—è¾¹ç•Œæ¡†é‡å æ¯”ä¾‹"""
        
        if len(bbox1) < 4 or len(bbox2) < 4:
            return 0.0
        
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        # è®¡ç®—é‡å åŒºåŸŸ
        overlap_x1 = max(x1_1, x1_2)
        overlap_y1 = max(y1_1, y1_2)
        overlap_x2 = min(x2_1, x2_2)
        overlap_y2 = min(y2_1, y2_2)
        
        if overlap_x2 <= overlap_x1 or overlap_y2 <= overlap_y1:
            return 0.0
        
        # è®¡ç®—é¢ç§¯
        overlap_area = (overlap_x2 - overlap_x1) * (overlap_y2 - overlap_y1)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        
        union_area = area1 + area2 - overlap_area
        
        return overlap_area / union_area if union_area > 0 else 0.0
    
    def _calculate_size_similarity(self, bbox1: List[int], bbox2: List[int]) -> float:
        """è®¡ç®—å°ºå¯¸ç›¸ä¼¼åº¦"""
        
        if len(bbox1) < 4 or len(bbox2) < 4:
            return 0.0
        
        width1 = bbox1[2] - bbox1[0]
        height1 = bbox1[3] - bbox1[1]
        width2 = bbox2[2] - bbox2[0]
        height2 = bbox2[3] - bbox2[1]
        
        if width1 <= 0 or height1 <= 0 or width2 <= 0 or height2 <= 0:
            return 0.0
        
        width_ratio = min(width1, width2) / max(width1, width2)
        height_ratio = min(height1, height2) / max(height1, height2)
        
        return (width_ratio + height_ratio) / 2
    
    def _sort_by_reading_order_enhanced(self, 
                                      regions: List[TextRegion], 
                                      original_image_info: Dict[str, Any]) -> List[TextRegion]:
        """ç›®æ ‡3: æ­£ç¡®æ’åº - æŒ‰å›¾çº¸é˜…è¯»é¡ºåºæ’åˆ—ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼Œä»å·¦åˆ°å³ï¼‰"""
        
        if not regions:
            return []
        
        image_width = original_image_info.get('width', 1000)
        image_height = original_image_info.get('height', 1000)
        
        # è®¡ç®—æ¯ä¸ªåŒºåŸŸçš„é˜…è¯»é¡ºåºæƒé‡
        for i, region in enumerate(regions):
            bbox = region.bbox
            if len(bbox) >= 4:
                x1, y1, x2, y2 = bbox
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                
                # è®¡ç®—é˜…è¯»é¡ºåº - ä¸»è¦æŒ‰Yåæ ‡ï¼Œæ¬¡è¦æŒ‰Xåæ ‡
                # ä½¿ç”¨ç›¸å¯¹ä½ç½®é¿å…ç»å¯¹åæ ‡çš„å½±å“
                relative_y = center_y / image_height if image_height > 0 else 0
                relative_x = center_x / image_width if image_width > 0 else 0
                
                # é˜…è¯»é¡ºåºæƒé‡ï¼šYåæ ‡æƒé‡æ›´é«˜
                reading_weight = relative_y * 1000 + relative_x
                region.reading_order = reading_weight
            else:
                region.reading_order = float('inf')
        
        # æŒ‰é˜…è¯»é¡ºåºæ’åº
        sorted_regions = sorted(regions, key=lambda x: x.reading_order)
        
        # é‡æ–°åˆ†é…åºå·
        for i, region in enumerate(sorted_regions):
            region.reading_order = i
        
        logger.info(f"ğŸ“– é˜…è¯»æ’åºå®Œæˆ: æŒ‰ä»ä¸Šåˆ°ä¸‹ã€ä»å·¦åˆ°å³çš„é¡ºåºé‡æ–°æ’åˆ—")
        return sorted_regions
    
    def _generate_enhanced_result(self, 
                                regions: List[TextRegion], 
                                original_image_info: Dict[str, Any],
                                task_id: str,
                                stats: MergeStatistics) -> Dict[str, Any]:
        """ç”Ÿæˆå¢å¼ºåˆå¹¶ç»“æœ"""
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        text_regions_data = []
        full_text_lines = []
        
        for region in regions:
            region_data = {
                'text': region.text,
                'bbox': region.bbox,
                'confidence': region.confidence,
                'text_type': region.text_type,
                'reading_order': region.reading_order,
                'slice_source': region.slice_source,
                'region_id': region.region_id
            }
            
            if region.polygon:
                region_data['polygon'] = region.polygon
            
            text_regions_data.append(region_data)
            full_text_lines.append(region.text)
        
        # ç”Ÿæˆå®Œæ•´æ–‡æœ¬
        full_text_content = '\n'.join(full_text_lines)
        
        # æŒ‰ç±»å‹åˆ†ç»„ç»Ÿè®¡
        type_stats = defaultdict(int)
        for region in regions:
            type_stats[region.text_type] += 1
        
        return {
            'success': True,
            'task_id': task_id,
            'merge_method': 'enhanced_four_objectives',
            
            # æ ¸å¿ƒæ•°æ®
            'text_regions': text_regions_data,
            'full_text_content': full_text_content,
            'total_text_regions': len(regions),
            
            # å››å¤§ç›®æ ‡å®ç°æƒ…å†µ
            'objectives_status': {
                'content_preservation': {
                    'achieved': True,
                    'edge_text_protected': stats.edge_preserved_regions,
                    'total_preserved': stats.final_regions_count
                },
                'no_duplication': {
                    'achieved': True,
                    'duplicates_removed': stats.duplicate_removed_count,
                    'deduplication_rate': stats.duplicate_removed_count / max(1, stats.total_input_regions)
                },
                'correct_ordering': {
                    'achieved': True,
                    'sorting_method': 'reading_order_enhanced',
                    'ordered_regions': len(regions)
                },
                'coordinate_restoration': {
                    'achieved': True,
                    'restored_coordinates': stats.coordinate_restored_count,
                    'restoration_rate': 1.0
                }
            },
            
            # è¯¦ç»†ç»Ÿè®¡
            'merge_statistics': asdict(stats),
            'text_type_distribution': dict(type_stats),
            'original_image_info': original_image_info,
            
            # è´¨é‡è¯„ä¼°
            'quality_metrics': {
                'average_confidence': sum(r.confidence for r in regions) / len(regions) if regions else 0,
                'total_characters': sum(len(r.text) for r in regions),
                'processing_efficiency': len(regions) / stats.processing_time if stats.processing_time > 0 else 0
            },
            
            'timestamp': time.time(),
            'format_version': '2.0_enhanced'
        } 