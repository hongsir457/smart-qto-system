# -*- coding: utf-8 -*-
"""
åˆ‡ç‰‡OCRç®¡ç†å™¨ï¼šè´Ÿè´£OCRåŠ è½½ã€ç¼“å­˜ã€å¤ç”¨ã€è§£æã€å¢å¼ºç­‰
"""
import os
import re
import logging
from typing import List, Dict, Any, Optional
from dataclasses import asdict
from .enhanced_slice_models import OCRTextItem, EnhancedSliceInfo

logger = logging.getLogger(__name__)

class SliceOCRManager:
    def __init__(self, analyzer):
        self.analyzer = analyzer  # å›è°ƒä¸»æµç¨‹
        self.ocr_cache = analyzer.ocr_cache
        self.component_patterns = analyzer._default_component_patterns()

    def can_reuse_slice_ocr(self, slice_info: EnhancedSliceInfo) -> bool:
        try:
            if hasattr(self.analyzer, 'shared_slice_results') and self.analyzer.shared_slice_results:
                for original_path, slice_result in self.analyzer.shared_slice_results.items():
                    slice_infos = slice_result.get('slice_infos', [])
                    for info in slice_infos:
                        if (info.get('row') == slice_info.row and \
                            info.get('col') == slice_info.col and
                            info.get('ocr_results')):
                            return True
            if hasattr(self.analyzer, '_slice_ocr_cache'):
                slice_key = f"{slice_info.row}_{slice_info.col}_{slice_info.slice_path}"
                return slice_key in self.analyzer._slice_ocr_cache
            return False
        except Exception as e:
            logger.debug(f"âš ï¸ æ£€æŸ¥OCRå¤ç”¨å¤±è´¥: {e}")
            return False

    def load_cached_ocr_results(self, slice_info: EnhancedSliceInfo) -> List[OCRTextItem]:
        try:
            if hasattr(self.analyzer, 'shared_slice_results') and self.analyzer.shared_slice_results:
                for original_path, slice_result in self.analyzer.shared_slice_results.items():
                    slice_infos = slice_result.get('slice_infos', [])
                    for info in slice_infos:
                        if (info.get('row') == slice_info.row and \
                            info.get('col') == slice_info.col):
                            ocr_data = info.get('ocr_results', [])
                            if ocr_data:
                                return self.convert_to_ocr_text_items(ocr_data)
            if hasattr(self.analyzer, '_slice_ocr_cache'):
                slice_key = f"{slice_info.row}_{slice_info.col}_{slice_info.slice_path}"
                cached_data = self.analyzer._slice_ocr_cache.get(slice_key)
                if cached_data:
                    return self.convert_to_ocr_text_items(cached_data)
            return []
        except Exception as e:
            logger.debug(f"âš ï¸ åŠ è½½ç¼“å­˜OCRç»“æœå¤±è´¥: {e}")
            return []

    def convert_to_ocr_text_items(self, ocr_data: List[Dict]) -> List[OCRTextItem]:
        ocr_items = []
        for item in ocr_data:
            try:
                if isinstance(item, dict):
                    ocr_item = OCRTextItem(
                        text=item.get('text', ''),
                        position=item.get('position', []),
                        confidence=item.get('confidence', 0.0),
                        category=item.get('category', 'unknown'),
                        bbox=item.get('bbox', {})
                    )
                    ocr_items.append(ocr_item)
                elif hasattr(item, 'text'):
                    ocr_items.append(item)
            except Exception as e:
                logger.debug(f"âš ï¸ è½¬æ¢OCRé¡¹å¤±è´¥: {e}")
                continue
        return ocr_items

    def cache_slice_ocr_results(self, slice_info: EnhancedSliceInfo):
        try:
            if not hasattr(self.analyzer, '_slice_ocr_cache'):
                self.analyzer._slice_ocr_cache = {}
            slice_key = f"{slice_info.row}_{slice_info.col}_{slice_info.slice_path}"
            ocr_data = []
            for ocr_item in slice_info.ocr_results or []:
                ocr_data.append({
                    'text': ocr_item.text,
                    'position': ocr_item.position,
                    'confidence': ocr_item.confidence,
                    'category': ocr_item.category,
                    'bbox': ocr_item.bbox
                })
            self.analyzer._slice_ocr_cache[slice_key] = ocr_data
        except Exception as e:
            logger.debug(f"âš ï¸ ç¼“å­˜OCRç»“æœå¤±è´¥: {e}")

    def save_global_ocr_cache(self):
        try:
            if not hasattr(self.analyzer, '_global_ocr_cache'):
                self.analyzer._global_ocr_cache = {}
            for slice_info in self.analyzer.enhanced_slices:
                if slice_info.ocr_results:
                    slice_key = f"{slice_info.row}_{slice_info.col}"
                    ocr_data = []
                    for ocr_item in slice_info.ocr_results:
                        ocr_data.append({
                            'text': ocr_item.text,
                            'position': ocr_item.position,
                            'confidence': ocr_item.confidence,
                            'category': ocr_item.category,
                            'bbox': ocr_item.bbox
                        })
                    self.analyzer._global_ocr_cache[slice_key] = ocr_data
            logger.debug(f"ğŸ’¾ å…¨å±€OCRç¼“å­˜å·²ä¿å­˜: {len(self.analyzer._global_ocr_cache)} ä¸ªåˆ‡ç‰‡")
        except Exception as e:
            logger.debug(f"âš ï¸ ä¿å­˜å…¨å±€OCRç¼“å­˜å¤±è´¥: {e}")

    def reuse_global_ocr_cache(self) -> Dict[str, Any]:
        try:
            total_text_items = 0
            reused_slices = 0
            for slice_info in self.analyzer.enhanced_slices:
                slice_key = f"{slice_info.row}_{slice_info.col}"
                if slice_key in self.analyzer._global_ocr_cache:
                    ocr_data = self.analyzer._global_ocr_cache[slice_key]
                    slice_info.ocr_results = self.convert_to_ocr_text_items(ocr_data)
                    total_text_items += len(slice_info.ocr_results)
                    reused_slices += 1
                    logger.debug(f"â™»ï¸ åˆ‡ç‰‡ {slice_key} å¤ç”¨å…¨å±€ç¼“å­˜: {len(slice_info.ocr_results)} ä¸ªæ–‡æœ¬é¡¹")
                else:
                    slice_info.ocr_results = []
            logger.info(f"â™»ï¸ å…¨å±€OCRç¼“å­˜å¤ç”¨å®Œæˆ: {reused_slices}/{len(self.analyzer.enhanced_slices)} ä¸ªåˆ‡ç‰‡, å…± {total_text_items} ä¸ªæ–‡æœ¬é¡¹")
            return {
                "success": True,
                "statistics": {
                    "processed_slices": 0,
                    "reused_slices": reused_slices,
                    "total_slices": len(self.analyzer.enhanced_slices),
                    "total_text_items": total_text_items,
                    "success_rate": reused_slices / len(self.analyzer.enhanced_slices) if self.analyzer.enhanced_slices else 0,
                    "reuse_rate": 1.0
                }
            }
        except Exception as e:
            logger.error(f"âŒ å¤ç”¨å…¨å±€OCRç¼“å­˜å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    def parse_ocr_results(self, ocr_texts: List[Dict]) -> List[OCRTextItem]:
        ocr_items = []
        for item in ocr_texts:
            try:
                text = item.get("text", "").strip()
                confidence = item.get("confidence", 0.0)
                bbox_xyxy = item.get("bbox_xyxy", {})
                if bbox_xyxy:
                    x_min = bbox_xyxy.get("x_min", 0)
                    y_min = bbox_xyxy.get("y_min", 0)
                    x_max = bbox_xyxy.get("x_max", 0)
                    y_max = bbox_xyxy.get("y_max", 0)
                    position = [
                        [x_min, y_min],
                        [x_max, y_min],
                        [x_max, y_max],
                        [x_min, y_max]
                    ]
                else:
                    position = []
                if text and position:
                    bbox = self.calculate_bbox_from_position(position)
                    ocr_item = OCRTextItem(
                        text=text,
                        position=position,
                        confidence=confidence,
                        category="unknown",
                        bbox=bbox
                    )
                    ocr_items.append(ocr_item)
            except Exception as e:
                logger.warning(f"âš ï¸ è§£æOCRé¡¹å¤±è´¥: {e}")
                continue
        return ocr_items

    def calculate_bbox_from_position(self, position: List[List[int]]) -> Dict[str, int]:
        if len(position) < 4:
            return {"x": 0, "y": 0, "width": 0, "height": 0}
        xs = [p[0] for p in position]
        ys = [p[1] for p in position]
        x_min, x_max = min(xs), max(xs)
        y_min, y_max = min(ys), max(ys)
        return {
            "x": x_min,
            "y": y_min,
            "width": x_max - x_min,
            "height": y_max - y_min
        }

    def enhance_slices_with_ocr(self, enhanced_slices: List[EnhancedSliceInfo]) -> Dict[str, Any]:
        try:
            enhanced_count = 0
            classification_stats = {
                "component_id": 0,
                "dimension": 0,
                "material": 0,
                "axis": 0,
                "unknown": 0
            }
            for slice_info in enhanced_slices:
                if not slice_info.ocr_results:
                    continue
                self.classify_ocr_texts(slice_info.ocr_results)
                slice_info.enhanced_prompt = self.generate_enhanced_prompt(slice_info)
                if slice_info.enhanced_prompt:
                    enhanced_count += 1
                for ocr_item in slice_info.ocr_results:
                    classification_stats[ocr_item.category] += 1
            logger.info(f"ğŸ“Š OCRå¢å¼ºå®Œæˆ: {enhanced_count}/{len(enhanced_slices)} ä¸ªåˆ‡ç‰‡ç”Ÿæˆå¢å¼ºæç¤º")
            return {
                "success": True,
                "statistics": {
                    "enhanced_slices": enhanced_count,
                    "total_slices": len(enhanced_slices),
                    "classification_stats": classification_stats
                }
            }
        except Exception as e:
            logger.error(f"âŒ OCRå¢å¼ºå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    def classify_ocr_texts(self, ocr_results: List[OCRTextItem]):
        for ocr_item in ocr_results:
            text = ocr_item.text.strip()
            for category, patterns in self.component_patterns.items():
                for pattern in patterns:
                    if re.match(pattern, text, re.IGNORECASE):
                        ocr_item.category = category
                        break
                if ocr_item.category != "unknown":
                    break

    def generate_enhanced_prompt(self, slice_info: EnhancedSliceInfo) -> str:
        if not slice_info.ocr_results:
            return ""
        categorized_items = {}
        for ocr_item in slice_info.ocr_results:
            category = ocr_item.category
            if category not in categorized_items:
                categorized_items[category] = []
            categorized_items[category].append(ocr_item)
        prompt_parts = []
        if hasattr(self.analyzer, 'global_drawing_overview') and self.analyzer.global_drawing_overview:
            overview = self.analyzer.global_drawing_overview
            prompt_parts.append("ğŸŒ å…¨å›¾æ¦‚è§ˆä¿¡æ¯ï¼š")
            if overview.get('natural_language_summary'):
                prompt_parts.append("ã€å…¨å›¾åˆ†ææ‘˜è¦ã€‘")
                prompt_parts.append(overview['natural_language_summary'])
                prompt_parts.append("")
            else:
                drawing_info = overview.get('drawing_info', {})
                if drawing_info:
                    prompt_parts.append(f"- å›¾çº¸ç±»å‹: {drawing_info.get('drawing_type', 'æœªçŸ¥')}")
                    prompt_parts.append(f"- å·¥ç¨‹åç§°: {drawing_info.get('project_name', 'æœªçŸ¥')}")
                    prompt_parts.append(f"- å›¾çº¸æ¯”ä¾‹: {drawing_info.get('scale', 'æœªçŸ¥')}")
                component_ids = overview.get('component_ids', [])
                if component_ids:
                    prompt_parts.append(f"- å…¨å›¾æ„ä»¶ç¼–å·: {', '.join(component_ids[:10])}{'...' if len(component_ids) > 10 else ''}")
                component_types = overview.get('component_types', [])
                if component_types:
                    prompt_parts.append(f"- ä¸»è¦æ„ä»¶ç±»å‹: {', '.join(component_types)}")
                material_grades = overview.get('material_grades', [])
                if material_grades:
                    prompt_parts.append(f"- ææ–™ç­‰çº§: {', '.join(material_grades)}")
                axis_lines = overview.get('axis_lines', [])
                if axis_lines:
                    prompt_parts.append(f"- è½´çº¿ç¼–å·: {', '.join(axis_lines[:8])}{'...' if len(axis_lines) > 8 else ''}")
                summary = overview.get('summary', {})
                if summary:
                    prompt_parts.append(f"- å¤æ‚ç¨‹åº¦: {summary.get('complexity_level', 'æœªçŸ¥')}")
                prompt_parts.append("")
        tile_pos = f"ç¬¬{slice_info.row}è¡Œç¬¬{slice_info.col}åˆ—"
        prompt_parts.append(f"ğŸ“„ å½“å‰å›¾åƒä¸ºç»“æ„å›¾åˆ‡ç‰‡ï¼ˆ{tile_pos}ï¼‰ï¼Œå°ºå¯¸ {slice_info.width}x{slice_info.height}")
        if categorized_items:
            prompt_parts.append("\nğŸ” å½“å‰åˆ‡ç‰‡OCRè¯†åˆ«çš„æ„ä»¶ä¿¡æ¯ï¼š")
            category_names = {
                "component_id": "æ„ä»¶ç¼–å·",
                "dimension": "å°ºå¯¸è§„æ ¼",
                "material": "ææ–™ç­‰çº§",
                "axis": "è½´çº¿ä½ç½®"
            }
            for category, items in categorized_items.items():
                if category == "unknown":
                    continue
                category_name = category_names.get(category, category)
                texts = [item.text for item in items]
                if texts:
                    max_items_per_category = 8
                    if len(texts) > max_items_per_category:
                        display_texts = texts[:max_items_per_category] + [f"...ç­‰{len(texts)}é¡¹"]
                        logger.debug(f"âš ï¸ åˆ‡ç‰‡ {slice_info.row}_{slice_info.col} {category_name}é¡¹ç›®è¿‡å¤šï¼Œå·²æˆªæ–­: {len(texts)}é¡¹")
                    else:
                        display_texts = texts
                    prompt_parts.append(f"- {category_name}: {', '.join(display_texts)}")
        prompt_parts.append("\nğŸ‘ï¸ Visionæ„ä»¶è¯†åˆ«è¦æ±‚ï¼ˆé‡ç‚¹ï¼šå‡ ä½•å½¢çŠ¶ï¼Œéæ–‡æœ¬ï¼‰ï¼š")
        prompt_parts.append("1. ğŸ” OCRæ–‡æœ¬åŒ¹é…ï¼šå°†OCRè¯†åˆ«çš„æ„ä»¶ç¼–å·ä¸å›¾åƒä¸­çš„æ„ä»¶è¿›è¡ŒåŒ¹é…")
        prompt_parts.append("2. ğŸŒ å…¨å›¾ä¸Šä¸‹æ–‡ï¼šç»“åˆå…¨å›¾æ„ä»¶æ¸…å•ï¼Œç†è§£å½“å‰åˆ‡ç‰‡çš„æ„ä»¶åˆ†å¸ƒ")
        prompt_parts.append("3. ğŸ“ å‡ ä½•å½¢çŠ¶è¯†åˆ«ï¼šè¯†åˆ«æ¢ï¼ˆçŸ©å½¢ï¼‰ã€æŸ±ï¼ˆåœ†å½¢/æ–¹å½¢ï¼‰ã€æ¿ï¼ˆé¢çŠ¶ï¼‰ã€å¢™ï¼ˆçº¿çŠ¶ï¼‰ç­‰")
        prompt_parts.append("4. ğŸ“ å°ºå¯¸æµ‹é‡ï¼šåŸºäºå›¾çº¸æ¯”ä¾‹è®¡ç®—æ„ä»¶çš„å®é™…å°ºå¯¸ï¼ˆé•¿å®½é«˜åšï¼‰")
        prompt_parts.append("5. ğŸ”— è¿æ¥å…³ç³»ï¼šè¯†åˆ«æ„ä»¶é—´çš„è¿æ¥å’Œæ”¯æ’‘å…³ç³»")
        prompt_parts.append("6. ğŸ“Š å·¥ç¨‹é‡æ•°æ®ï¼šæä¾›é¢ç§¯ã€ä½“ç§¯ç­‰å·¥ç¨‹é‡è®¡ç®—æ‰€éœ€çš„å‡ ä½•å‚æ•°")
        prompt_parts.append("\nğŸ“‹ è¿”å›JSONæ ¼å¼ï¼Œé‡ç‚¹åŒ…å«ï¼š")
        prompt_parts.append("- æ„ä»¶å‡ ä½•å½¢çŠ¶å’Œç²¾ç¡®å°ºå¯¸ï¼ˆç”¨äºå·¥ç¨‹é‡è®¡ç®—ï¼‰")
        prompt_parts.append("- æ„ä»¶è¾¹ç•Œæ¡†å’Œç©ºé—´ä½ç½®")
        prompt_parts.append("- æ„ä»¶ç»“æ„ä½œç”¨å’Œè¿æ¥å…³ç³»")
        prompt_parts.append("- OCRæ–‡æœ¬ä¸Visionæ„ä»¶çš„åŒ¹é…å…³ç³»")
        prompt_parts.append("æ³¨æ„ï¼šä¸“æ³¨æ„ä»¶è¯†åˆ«ï¼Œä¸è¦é‡å¤OCRçš„æ–‡æœ¬è¯†åˆ«å·¥ä½œ")
        return "\n".join(prompt_parts) 