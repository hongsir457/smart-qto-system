import logging
import json
import re
import base64
from typing import Dict, Any, List, Optional

import openai

from app.core.config import settings
from ..enhanced_slice_models import EnhancedSliceInfo, OCRTextItem
from ...schemas.component import DrawingComponent, ComponentPosition, ComponentConfidence
from ..ai_analyzer import AIAnalyzerService

logger = logging.getLogger(__name__)


class VisionTrackService:
    """
    Visionè½¨é“æœåŠ¡
    è´Ÿè´£Visionè½¨é“2çš„å…¨æµç¨‹ï¼šOCRå¢žå¼ºã€è°ƒç”¨Visionæ¨¡åž‹åˆ†æžã€è§£æžæž„ä»¶ã€‚
    """

    def __init__(self, ai_analyzer: AIAnalyzerService):
        """
        åˆå§‹åŒ–Visionè½¨é“æœåŠ¡
        
        Args:
            ai_analyzer: AIåˆ†æžå™¨å®žä¾‹
        """
        self.ai_analyzer = ai_analyzer
        self.component_patterns = self._default_component_patterns()
        self.vision_cache = {} # å¯é€‰çš„å†…å­˜ç¼“å­˜

    def analyze_slices(self, 
                       enhanced_slices: List[EnhancedSliceInfo], 
                       global_overview: str,
                       drawing_info: Dict[str, Any], 
                       task_id: str) -> Dict[str, Any]:
        """
        å¯¹æ‰€æœ‰åˆ‡ç‰‡æ‰§è¡ŒVisionåˆ†æžï¼ˆè½¨é“2ï¼‰
        
        Args:
            enhanced_slices: å¢žå¼ºåˆ‡ç‰‡åˆ—è¡¨
            global_overview: å…¨å±€æ¦‚è§ˆä¿¡æ¯ (æ¥è‡ªOCRè½¨é“1ï¼ŒçŽ°åœ¨æ˜¯çº¯æ–‡æœ¬å­—ç¬¦ä¸²)
            drawing_info: åŽŸå§‹å›¾çº¸ä¿¡æ¯
            task_id: ä»»åŠ¡ID
            
        Returns:
            åŒ…å«æ‰€æœ‰åˆ‡ç‰‡åˆ†æžç»“æžœçš„å­—å…¸
        """
        try:
            # 1. OCRæ™ºèƒ½åˆ†ç±»ä¸Žå¢žå¼ºæç¤ºç”Ÿæˆ
            self._enhance_slices_with_ocr(enhanced_slices, global_overview)
            
            # 2. å¾ªçŽ¯åˆ†æžæ¯ä¸ªåˆ‡ç‰‡
            slice_components = {}
            analyzed_count = 0
            failed_count = 0

            for slice_info in enhanced_slices:
                cache_key = f"{slice_info.row}_{slice_info.col}"
                if cache_key in self.vision_cache:
                    slice_components[cache_key] = self.vision_cache[cache_key]
                    analyzed_count += 1
                    logger.info(f"â™»ï¸ å¤ç”¨åˆ‡ç‰‡ {cache_key} çš„Visionåˆ†æžç»“æžœ")
                    continue

                logger.info(f"ðŸ‘ï¸ Visionåˆ†æžåˆ‡ç‰‡ {slice_info.row}_{slice_info.col}")
                
                prompt = slice_info.enhanced_prompt or self._generate_basic_vision_prompt(slice_info, global_overview, drawing_info)
                
                vision_result = self._analyze_single_slice(
                    slice_info, prompt, f"{task_id}_vision_{slice_info.row}_{slice_info.col}"
                )
                
                if vision_result["success"]:
                    components = self._parse_vision_components(vision_result["data"], slice_info)
                    slice_components[cache_key] = components
                    self.vision_cache[cache_key] = components # ç¼“å­˜ç»“æžœ
                    analyzed_count += 1
                else:
                    slice_components[cache_key] = []
                    failed_count += 1
            
            return {"success": True, "slice_components": slice_components}

        except Exception as e:
            logger.error(f"âŒ Visionè½¨é“åˆ†æžå¤±è´¥: {e}", exc_info=True)
            return {"success": False, "error": str(e)}

    def _enhance_slices_with_ocr(self, enhanced_slices: List[EnhancedSliceInfo], global_overview: str):
        """OCRæ™ºèƒ½åˆ†ç±»ä¸Žå¢žå¼ºæç¤ºç”Ÿæˆ"""
        for slice_info in enhanced_slices:
            if not slice_info.ocr_results:
                continue
            self._classify_ocr_texts(slice_info.ocr_results)
            slice_info.enhanced_prompt = self._generate_enhanced_prompt(slice_info, global_overview)

    def _classify_ocr_texts(self, ocr_results: List[OCRTextItem]):
        """å¯¹OCRæ–‡æœ¬è¿›è¡Œæ™ºèƒ½åˆ†ç±»"""
        for ocr_item in ocr_results:
            text = ocr_item.text.strip()
            for category, patterns in self.component_patterns.items():
                if any(re.match(p, text, re.IGNORECASE) for p in patterns):
                    ocr_item.category = category
                    break

    def _generate_enhanced_prompt(self, slice_info: EnhancedSliceInfo, global_overview: str) -> str:
        """ç”ŸæˆOCRå¢žå¼ºçš„Visionåˆ†æžæç¤º"""
        prompt_parts = [f"ðŸ“„ å½“å‰å›¾åƒä¸ºç»“æž„å›¾åˆ‡ç‰‡ï¼ˆç¬¬{slice_info.row}è¡Œç¬¬{slice_info.col}åˆ—ï¼‰"]
        
        # æ·»åŠ å…¨å±€æ¦‚è§ˆä¿¡æ¯ (çŽ°åœ¨æ˜¯çº¯æ–‡æœ¬)
        if global_overview:
            prompt_parts.append("\nðŸŒ ä»¥ä¸‹æ˜¯ä½œä¸ºå‚è€ƒçš„å…¨å›¾æ¦‚è§ˆåˆ†æžæŠ¥å‘Šï¼š")
            prompt_parts.append("---")
            prompt_parts.append(global_overview)
            prompt_parts.append("---")

        # æ·»åŠ å•åˆ‡ç‰‡OCRä¿¡æ¯
        categorized_items = {}
        for item in slice_info.ocr_results:
            categorized_items.setdefault(item.category, []).append(item.text)
        
        if categorized_items:
            prompt_parts.append("\nðŸ” å½“å‰åˆ‡ç‰‡OCRè¯†åˆ«ä¿¡æ¯ï¼š")
            for category, texts in categorized_items.items():
                if category != "unknown":
                    prompt_parts.append(f"- {category}: {', '.join(texts)}")

        prompt_parts.append("\nðŸ‘ï¸ Visionæž„ä»¶è¯†åˆ«è¦æ±‚ï¼šè¯·è¯†åˆ«æž„ä»¶å‡ ä½•å½¢çŠ¶ã€å°ºå¯¸å’Œä½ç½®ã€‚")
        return "\n".join(prompt_parts)

    def _generate_basic_vision_prompt(self, slice_info: EnhancedSliceInfo, global_overview: Dict, drawing_info: Dict) -> str:
        """ç”ŸæˆåŸºç¡€Visionåˆ†æžæç¤º"""
        return self._generate_enhanced_prompt(slice_info, global_overview) # å¤ç”¨é€»è¾‘

    def _analyze_single_slice(self, slice_info: EnhancedSliceInfo, prompt: str, vision_task_id: str) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªåˆ‡ç‰‡çš„Visionåˆ†æž"""
        try:
            with open(slice_info.slice_path, "rb") as image_file:
                image_data = base64.b64encode(image_file.read()).decode('utf-8')

            system_prompt = "ä½ æ˜¯ä¸“ä¸šçš„ç»“æž„å·¥ç¨‹å¸ˆï¼Œä¸“é—¨åˆ†æžå»ºç­‘ç»“æž„å›¾çº¸ã€‚è¯·è¯†åˆ«æž„ä»¶çš„å‡ ä½•å½¢çŠ¶ã€ç©ºé—´ä½ç½®ã€å°ºå¯¸ï¼Œå¹¶ä»¥æŒ‡å®šçš„JSONæ ¼å¼è¿”å›žã€‚"
            
            client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
            response = client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_data}", "detail": "high"}}
                    ]}
                ],
                max_tokens=2000,
                temperature=0.1,
                response_format={"type": "json_object"}
            )
            response_text = response.choices[0].message.content
            result_data = json.loads(response_text)
            return {"success": True, "data": result_data}
        except Exception as e:
            logger.error(f"âŒ åˆ‡ç‰‡Visionåˆ†æžAPIè°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            return {"success": False, "error": str(e)}

    def _parse_vision_components(self, vision_data: Dict[str, Any], slice_info: EnhancedSliceInfo) -> List[Dict]:
        """ä»ŽVision APIçš„å“åº”ä¸­è§£æžæž„ä»¶åˆ—è¡¨"""
        components = []
        raw_components = vision_data.get("components", [])
        for i, comp_data in enumerate(raw_components):
            try:
                bbox_local_raw = comp_data.get("location", {}).get("bbox", [0, 0, 0, 0])
                if isinstance(bbox_local_raw, dict):
                     bbox_local = [bbox_local_raw.get('x',0), bbox_local_raw.get('y',0), bbox_local_raw.get('width',0), bbox_local_raw.get('height',0)]
                else:
                     bbox_local = bbox_local_raw

                component = {
                    "id": f"{slice_info.filename}_{comp_data.get('component_id', f'comp_{i}')}",
                    "component_type": comp_data.get("component_type", "æœªçŸ¥"),
                    "component_id": comp_data.get("component_id"),
                    "position": {
                        "slice_id": slice_info.filename,
                        "bbox_local": tuple(bbox_local),
                        "bbox_global": (0, 0, 0, 0) # å ä½ç¬¦
                    },
                    "source_modules": ["Vision"],
                    "confidence": {"vision_confidence": comp_data.get("confidence", 0.8)},
                    "raw_vision_data": comp_data
                }
                components.append(component)
            except Exception as e:
                logger.error(f"è§£æžVisionæž„ä»¶æ—¶å‡ºé”™: {e} - æ•°æ®: {comp_data}")
                continue
        return components

    def _default_component_patterns(self) -> Dict[str, List[str]]:
        return {
            'component_id': [r'^[A-Z]{1,2}\d{2,4}$', r'^[A-Z]{1,2}-\d{1,3}$'],
            'dimension': [r'^\d{2,4}[xXÃ—]\d{2,4}', r'^[bBhH]?\d{2,4}$'],
            'material': [r'^C\d{2}$', r'^HRB\d{3}$'],
            'axis': [r'^[A-Z]-[A-Z]$', r'^\d+-\d+$']
        } 