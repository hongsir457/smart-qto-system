#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI Analyzer Core - é‡æ„åçš„AIåˆ†æå™¨æ ¸å¿ƒ
è´Ÿè´£åè°ƒå„ä¸ªä¸“é—¨çš„åˆ†ææ¨¡å—
"""
import logging
import json
from typing import Dict, Any, List, Optional
from datetime import datetime

# å¯¼å…¥åŒé‡å­˜å‚¨æœåŠ¡
from app.services.dual_storage_service import DualStorageService

# å¯¼å…¥OpenAIäº¤äº’è®°å½•å™¨
try:
    from app.services.openai_interaction_logger import OpenAIInteractionLogger
except ImportError:
    OpenAIInteractionLogger = None
    
# å¯¼å…¥OpenAIå®¢æˆ·ç«¯å’Œé…ç½®
try:
    from openai import OpenAI
    from app.core.config import settings
except ImportError:
    OpenAI = None
    settings = None

logger = logging.getLogger(__name__)

class AIAnalyzerCore:
    """
    AIåˆ†æå™¨æ ¸å¿ƒç±»
    åè°ƒå„ä¸ªä¸“é—¨çš„åˆ†ææ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„åˆ†ææ¥å£
    """
    
    def __init__(self):
        """åˆå§‹åŒ–AIåˆ†æå™¨æ ¸å¿ƒ"""
        self._initialize_openai_client()
        self._initialize_storage_service()
        self._initialize_interaction_logger()
        self._initialize_analysis_modules()
        
    def _initialize_openai_client(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
        if not OpenAI or not settings or not settings.OPENAI_API_KEY:
            self.client = None
            logger.warning("âš ï¸ OpenAIæˆ–é…ç½®ä¸å¯ç”¨ï¼ŒAIåˆ†ææœåŠ¡å°†å¤„äºç¦ç”¨çŠ¶æ€ã€‚")
        else:
            self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
            logger.info("âœ… AI Analyzer Core initialized successfully with OpenAI client.")
    
    def _initialize_storage_service(self):
        """åˆå§‹åŒ–å­˜å‚¨æœåŠ¡"""
        try:
            self.storage_service = DualStorageService()
            logger.info("âœ… AIAnalyzerCore: DualStorageService initialized.")
        except Exception as e:
            self.storage_service = None
            logger.warning(f"âš ï¸ AIAnalyzerCore: DualStorageService failed to initialize: {e}")
    
    def _initialize_interaction_logger(self):
        """åˆå§‹åŒ–äº¤äº’è®°å½•å™¨"""
        if OpenAIInteractionLogger and self.storage_service:
            try:
                self.interaction_logger = OpenAIInteractionLogger(storage_service=self.storage_service)
                logger.info("âœ… OpenAIInteractionLogger åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ OpenAIInteractionLoggeråˆå§‹åŒ–å¼‚å¸¸: {e}")
                self.interaction_logger = None
        else:
            logger.error("âŒ OpenAIInteractionLoggeræœªå®šä¹‰æˆ–DualStorageServiceæœªåˆå§‹åŒ–")
            self.interaction_logger = None
    
    def _initialize_analysis_modules(self):
        """åˆå§‹åŒ–å„ä¸ªåˆ†ææ¨¡å—"""
        # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
        try:
            from .ai.mock_detector import MockDataDetector
            self.mock_detector = MockDataDetector()
        except ImportError:
            logger.warning("âš ï¸ MockDataDetector å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
            self.mock_detector = None
        
        # TODO: æ·»åŠ å…¶ä»–åˆ†ææ¨¡å—çš„åˆå§‹åŒ–
        # from .ai.prompt_builder import PromptBuilder
        # from .ai.vision_analyzer import VisionAnalyzer
        # from .ai.response_synthesizer import ResponseSynthesizer
        
        logger.info("âœ… AIåˆ†ææ¨¡å—åˆå§‹åŒ–å®Œæˆ")
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.client is not None
    
    def generate_qto_from_data(self, extracted_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ¹æ®OCRæ–‡æœ¬å’Œè¡¨æ ¼æ•°æ®ï¼Œè°ƒç”¨LLMç”Ÿæˆç»“æ„åŒ–çš„å·¥ç¨‹é‡æ¸…å•ï¼ˆQTOï¼‰
        
        Args:
            extracted_data: ä»UnifiedOCREngineä¼ æ¥çš„ã€åŒ…å«æ–‡æœ¬å’Œè¡¨æ ¼çš„æ•°æ®
            
        Returns:
            Dict[str, Any]: å¤§æ¨¡å‹ç”Ÿæˆçš„ç»“æ„åŒ–QTOæ•°æ®
        """
        if not self.is_available():
            return {"error": "AI Analyzer Service is not available."}

        logger.info("ğŸ¤– Starting QTO generation with LLM...")

        try:
            # 1. æ„å»ºç³»ç»ŸPrompt
            system_prompt = self._build_system_prompt()

            # 2. æ„å»ºç”¨æˆ·Prompt  
            user_prompt = self._build_user_prompt(extracted_data)
            
            if not user_prompt:
                logger.warning("No data available to build a prompt. Aborting LLM call.")
                return {"error": "No content to analyze."}

            # 3. è°ƒç”¨OpenAI API
            logger.info(f"Sending request to OpenAI model: {settings.OPENAI_MODEL}")
            
            response = self.client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=settings.OPENAI_TEMPERATURE,
                max_tokens=settings.OPENAI_MAX_TOKENS,
                response_format={"type": "json_object"}
            )
            
            # 4. è§£æç»“æœ
            qto_json_string = response.choices[0].message.content
            logger.info("âœ… Successfully received response from LLM.")
            
            if not qto_json_string:
                logger.error("LLM returned empty response")
                return {"error": "Empty response from LLM"}
            
            try:
                qto_data = json.loads(qto_json_string)
                
                # 5. æ¨¡æ‹Ÿæ•°æ®æ£€æµ‹
                if self.mock_detector:
                    has_mock_data = self.mock_detector.check_for_mock_data_patterns(qto_data)
                    if has_mock_data:
                        logger.warning("ğŸš¨ æ£€æµ‹åˆ°å¯èƒ½çš„æ¨¡æ‹Ÿæ•°æ®")
                
                return {"success": True, "qto_data": qto_data}
                
            except json.JSONDecodeError:
                logger.error("Failed to parse JSON from LLM response.")
                return {"error": "Invalid JSON response from LLM", "raw_response": qto_json_string}

        except Exception as e:
            logger.error(f"âŒ An error occurred while calling OpenAI API: {e}", exc_info=True)
            return {"error": str(e)}
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        return """
        # è§’è‰²å®šä¹‰
        ä½ æ˜¯ä¸€åå›½å®¶ä¸€çº§æ³¨å†Œå»ºé€ å¸ˆå’Œé«˜çº§é€ ä»·å·¥ç¨‹å¸ˆï¼Œå…·æœ‰20å¹´å»ºç­‘å·¥ç¨‹é‡æ¸…å•ç¼–åˆ¶ç»éªŒã€‚
        
        # æ ¸å¿ƒä»»åŠ¡
        åˆ†æå»ºç­‘å›¾çº¸OCRè¯†åˆ«æ•°æ®ï¼ŒæŒ‰ç…§å›½å®¶å·¥ç¨‹é‡è®¡ç®—è§„èŒƒç”Ÿæˆæ ‡å‡†åŒ–çš„å·¥ç¨‹é‡æ¸…å•ï¼ˆQTOï¼‰ã€‚
        
        # é‡è¦è¦æ±‚
        1. åŸºäºçœŸå®å›¾çº¸æ•°æ®è¿›è¡Œåˆ†æï¼Œä¸è¦ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        2. ç¡®ä¿æ„ä»¶ç¼–å·ä¸å›¾çº¸å®é™…æ ‡æ³¨ä¸€è‡´
        3. å°ºå¯¸å’Œé…ç­‹ä¿¡æ¯å¿…é¡»æ¥æºäºå›¾çº¸è¯†åˆ«ç»“æœ
        4. è¾“å‡ºJSONæ ¼å¼çš„ç»“æ„åŒ–æ•°æ®
        
        # è¾“å‡ºæ ¼å¼
        è¿”å›åŒ…å«project_infoå’Œcomponentsçš„JSONç»“æ„ã€‚
        """
    
    def _build_user_prompt(self, data: Dict[str, Any]) -> Optional[str]:
        """æ„å»ºç”¨æˆ·æç¤ºè¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            prompt_parts = []
            
            # æ·»åŠ OCRæ–‡æœ¬æ•°æ®
            ocr_texts = data.get("ocr_texts", [])
            if ocr_texts:
                prompt_parts.append("## OCRè¯†åˆ«çš„æ–‡æœ¬æ•°æ®:")
                for text in ocr_texts[:20]:  # é™åˆ¶å‰20ä¸ª
                    prompt_parts.append(f"- {text}")
            
            # æ·»åŠ è¡¨æ ¼æ•°æ®
            tables = data.get("tables", [])
            if tables:
                prompt_parts.append("\n## è¯†åˆ«çš„è¡¨æ ¼æ•°æ®:")
                for i, table in enumerate(tables[:3]):  # é™åˆ¶å‰3ä¸ªè¡¨æ ¼
                    prompt_parts.append(f"è¡¨æ ¼{i+1}: {table}")
            
            if not prompt_parts:
                return None
            
            prompt_parts.append("\n## ä»»åŠ¡è¦æ±‚:")
            prompt_parts.append("è¯·åŸºäºä»¥ä¸Šå›¾çº¸æ•°æ®ï¼Œç”Ÿæˆæ ‡å‡†åŒ–çš„å·¥ç¨‹é‡æ¸…å•JSONã€‚")
            
            return "\n".join(prompt_parts)
            
        except Exception as e:
            logger.error(f"æ„å»ºç”¨æˆ·æç¤ºè¯å¤±è´¥: {e}")
            return None 