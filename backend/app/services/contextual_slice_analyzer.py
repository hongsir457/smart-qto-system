#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸Šä¸‹æ–‡é“¾åˆ‡ç‰‡åˆ†æå™¨
é’ˆå¯¹åˆ‡ç‰‡åçš„å±€éƒ¨å›¾çº¸ï¼Œä¼˜åŒ–äº”æ­¥äº¤äº’å¼åˆ†æï¼Œç¡®ä¿ä¸Šä¸‹æ–‡è¿è´¯æ€§
"""

import logging
import time
import json
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)

@dataclass
class GlobalContext:
    """å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    project_name: str
    drawing_type: str
    scale: str
    main_component_types: List[str]
    estimated_total_components: int
    project_metadata: Dict[str, Any]

@dataclass 
class SliceContext:
    """åˆ‡ç‰‡ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    slice_index: int
    slice_id: str
    slice_bounds: Tuple[int, int, int, int]  # (x, y, width, height)
    slice_position: str  # 'top-left', 'center', 'bottom-right' etc.
    focus_areas: List[str]  # ['components', 'dimensions', 'annotations']
    relative_to_global: Dict[str, float]  # ç›¸å¯¹å…¨å›¾çš„ä½ç½®æ¯”ä¾‹

class ContextualSliceAnalyzer:
    """ä¸Šä¸‹æ–‡é“¾åˆ‡ç‰‡åˆ†æå™¨"""
    
    def __init__(self):
        self.ai_analyzer = None
        try:
            from app.services.ai_analyzer import AIAnalyzerService
            self.ai_analyzer = AIAnalyzerService()
        except Exception as e:
            logger.warning(f"âš ï¸ AIåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        self.global_context: Optional[GlobalContext] = None
        self.slice_contexts: List[SliceContext] = []
        self.context_chain: List[Dict[str, Any]] = []
        
    def analyze_with_contextual_chain(self, 
                                    full_image_path: str,
                                    slice_images: List[str],
                                    slice_configs: List[Dict[str, Any]],
                                    task_id: str,
                                    drawing_id: int = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨ä¸Šä¸‹æ–‡é“¾è¿›è¡Œåˆ‡ç‰‡åˆ†æ
        
        Args:
            full_image_path: å®Œæ•´å›¾çº¸è·¯å¾„
            slice_images: åˆ‡ç‰‡å›¾åƒè·¯å¾„åˆ—è¡¨
            slice_configs: åˆ‡ç‰‡é…ç½®ä¿¡æ¯
            task_id: ä»»åŠ¡ID
            drawing_id: å›¾çº¸ID
            
        Returns:
            åˆ†æç»“æœ
        """
        logger.info(f"ğŸ”„ å¼€å§‹ä¸Šä¸‹æ–‡é“¾åˆ‡ç‰‡åˆ†æ: {len(slice_images)} ä¸ªåˆ‡ç‰‡")
        
        if not self.ai_analyzer or not self.ai_analyzer.is_available():
            return {
                "error": "AI Analyzer Service is not available",
                "success": False
            }
        
        try:
            # Phase 1: å…¨å›¾æ¦‚è§ˆåˆ†æ - å»ºç«‹å…¨å±€ä¸Šä¸‹æ–‡
            logger.info("ğŸŒ Phase 1: å…¨å›¾æ¦‚è§ˆåˆ†æ")
            global_analysis = self._analyze_global_overview(full_image_path, task_id, drawing_id)
            
            if not global_analysis.get("success"):
                logger.error("âŒ å…¨å›¾æ¦‚è§ˆåˆ†æå¤±è´¥")
                return global_analysis
            
            # å»ºç«‹å…¨å±€ä¸Šä¸‹æ–‡
            self.global_context = self._build_global_context(global_analysis["qto_data"])
            logger.info(f"âœ… å…¨å±€ä¸Šä¸‹æ–‡å»ºç«‹: é¡¹ç›®={self.global_context.project_name}, "
                       f"ç±»å‹={self.global_context.drawing_type}")
            
            # Phase 2: åˆ‡ç‰‡ä¸Šä¸‹æ–‡é“¾åˆ†æ
            logger.info("ğŸ”— Phase 2: åˆ‡ç‰‡ä¸Šä¸‹æ–‡é“¾åˆ†æ")
            slice_results = self._analyze_slices_with_context_chain(
                slice_images, slice_configs, task_id, drawing_id
            )
            
            # Phase 3: ç»“æœåˆå¹¶ä¸ä¸€è‡´æ€§æ ¡éªŒ
            logger.info("ğŸ”€ Phase 3: ç»“æœåˆå¹¶ä¸ä¸€è‡´æ€§æ ¡éªŒ")
            merged_result = self._merge_and_validate_results(
                global_analysis, slice_results, task_id
            )
            
            logger.info("âœ… ä¸Šä¸‹æ–‡é“¾åˆ‡ç‰‡åˆ†æå®Œæˆ")
            return merged_result
            
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¸‹æ–‡é“¾åˆ‡ç‰‡åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis_method": "contextual_slice_analysis"
            }
    
    def _analyze_global_overview(self, 
                               full_image_path: str,
                               task_id: str,
                               drawing_id: int = None) -> Dict[str, Any]:
        """å…¨å›¾æ¦‚è§ˆåˆ†æ - å»ºç«‹å…¨å±€ä¸Šä¸‹æ–‡"""
        
        logger.info("ğŸ” æ‰§è¡Œå…¨å›¾æ¦‚è§ˆåˆ†æ...")
        
        # ä½¿ç”¨ç¼©ç•¥å›¾è¿›è¡Œå…¨å±€äº”æ­¥äº¤äº’åˆ†æ
        try:
            # ç”Ÿæˆç¼©ç•¥å›¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
            thumbnail_path = self._create_thumbnail_if_needed(full_image_path)
            
            # æ‰§è¡ŒV2ç‰ˆæœ¬çš„äº”æ­¥äº¤äº’åˆ†æ
            global_result = self.ai_analyzer.generate_qto_from_local_images_v2(
                image_paths=[thumbnail_path],
                task_id=f"{task_id}_global",
                drawing_id=drawing_id
            )
            
            if global_result.get("success"):
                logger.info("âœ… å…¨å›¾æ¦‚è§ˆåˆ†ææˆåŠŸ")
                return global_result
            else:
                logger.error(f"âŒ å…¨å›¾æ¦‚è§ˆåˆ†æå¤±è´¥: {global_result.get('error')}")
                return global_result
                
        except Exception as e:
            logger.error(f"âŒ å…¨å›¾æ¦‚è§ˆåˆ†æå¼‚å¸¸: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _create_thumbnail_if_needed(self, image_path: str, max_size: int = 1024) -> str:
        """å¦‚æœéœ€è¦ï¼Œåˆ›å»ºç¼©ç•¥å›¾"""
        try:
            from PIL import Image
            
            with Image.open(image_path) as img:
                # å¦‚æœå›¾åƒå¤ªå¤§ï¼Œåˆ›å»ºç¼©ç•¥å›¾
                if max(img.size) > max_size:
                    img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                    
                    # ä¿å­˜ç¼©ç•¥å›¾
                    thumbnail_path = image_path.replace('.', '_thumbnail.')
                    img.save(thumbnail_path)
                    logger.info(f"ğŸ“· åˆ›å»ºç¼©ç•¥å›¾: {thumbnail_path}")
                    return thumbnail_path
                else:
                    return image_path
                    
        except Exception as e:
            logger.warning(f"âš ï¸ ç¼©ç•¥å›¾åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨åŸå›¾: {e}")
            return image_path
    
    def _build_global_context(self, global_qto_data: Dict[str, Any]) -> GlobalContext:
        """ä»å…¨å›¾åˆ†æç»“æœæ„å»ºå…¨å±€ä¸Šä¸‹æ–‡"""
        
        try:
            drawing_info = global_qto_data.get("drawing_info", {})
            components = global_qto_data.get("components", [])
            
            return GlobalContext(
                project_name=drawing_info.get("project_name", "æœªçŸ¥é¡¹ç›®"),
                drawing_type=drawing_info.get("drawing_name", "ç»“æ„å›¾"),
                scale=drawing_info.get("scale", "1:100"),
                main_component_types=list(set([
                    comp.get("component_type", "æœªçŸ¥") for comp in components
                ])),
                estimated_total_components=len(components),
                project_metadata={
                    "design_unit": drawing_info.get("design_unit", ""),
                    "design_date": drawing_info.get("design_date", ""),
                    "drawing_number": drawing_info.get("drawing_number", ""),
                    "analysis_timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ æ„å»ºå…¨å±€ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ä¸Šä¸‹æ–‡
            return GlobalContext(
                project_name="æœªçŸ¥é¡¹ç›®",
                drawing_type="ç»“æ„å›¾",
                scale="1:100",
                main_component_types=["æœªçŸ¥æ„ä»¶"],
                estimated_total_components=0,
                project_metadata={}
            )
    
    def _analyze_slices_with_context_chain(self, 
                                         slice_images: List[str],
                                         slice_configs: List[Dict[str, Any]],
                                         task_id: str,
                                         drawing_id: int = None) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ä¸Šä¸‹æ–‡é“¾åˆ†æåˆ‡ç‰‡"""
        
        slice_results = []
        accumulated_context = {
            "global_context": asdict(self.global_context),
            "previous_components": [],
            "previous_positions": [],
            "component_count_running_total": 0
        }
        
        for i, (slice_image, slice_config) in enumerate(zip(slice_images, slice_configs)):
            logger.info(f"ğŸ” åˆ†æåˆ‡ç‰‡ {i+1}/{len(slice_images)}: {slice_config.get('slice_id', f'slice_{i}')}")
            
            # ä¸ºå½“å‰åˆ‡ç‰‡æ„å»ºä¸Šä¸‹æ–‡æç¤º
            contextual_prompt = self._build_slice_contextual_prompt(
                slice_config, accumulated_context, i
            )
            
            # æ‰§è¡Œç®€åŒ–çš„ä¸‰æ­¥åˆ†æï¼ˆè€Œä¸æ˜¯å®Œæ•´çš„äº”æ­¥ï¼‰
            slice_result = self._execute_contextual_slice_analysis(
                slice_image, slice_config, contextual_prompt,
                f"{task_id}_slice_{i}", drawing_id
            )
            
            if slice_result.get("success"):
                # æ›´æ–°ç´¯ç§¯ä¸Šä¸‹æ–‡
                accumulated_context = self._update_accumulated_context(
                    accumulated_context, slice_result["qto_data"]
                )
                
                slice_results.append({
                    "slice_index": i,
                    "slice_config": slice_config,
                    "analysis_result": slice_result,
                    "context_used": contextual_prompt[:200] + "..." if len(contextual_prompt) > 200 else contextual_prompt
                })
                
                logger.info(f"âœ… åˆ‡ç‰‡ {i+1} åˆ†ææˆåŠŸ")
            else:
                logger.error(f"âŒ åˆ‡ç‰‡ {i+1} åˆ†æå¤±è´¥: {slice_result.get('error')}")
                slice_results.append({
                    "slice_index": i,
                    "slice_config": slice_config,
                    "analysis_result": slice_result,
                    "context_used": contextual_prompt[:200] + "..." if len(contextual_prompt) > 200 else contextual_prompt
                })
        
        return slice_results
    
    def _build_slice_contextual_prompt(self, 
                                      slice_config: Dict[str, Any],
                                      accumulated_context: Dict[str, Any],
                                      slice_index: int) -> str:
        """ä¸ºåˆ‡ç‰‡æ„å»ºä¸Šä¸‹æ–‡æç¤º"""
        
        global_ctx = accumulated_context["global_context"]
        previous_components = accumulated_context["previous_components"]
        
        prompt = f"""
ã€å…¨å›¾é¡¹ç›®ä¿¡æ¯ã€‘
é¡¹ç›®åç§°: {global_ctx['project_name']}
å›¾çº¸ç±»å‹: {global_ctx['drawing_type']}
å›¾çº¸æ¯”ä¾‹: {global_ctx['scale']}
è®¾è®¡å•ä½: {global_ctx['project_metadata'].get('design_unit', 'æœªçŸ¥')}

ã€æ•´ä½“æ„ä»¶æ¦‚è§ˆã€‘
ä¸»è¦æ„ä»¶ç±»å‹: {', '.join(global_ctx['main_component_types'])}
é¢„ä¼°æ„ä»¶æ€»æ•°: {global_ctx['estimated_total_components']}
å·²åˆ†ææ„ä»¶æ•°: {len(previous_components)}

ã€å½“å‰åˆ‡ç‰‡ä¿¡æ¯ã€‘
åˆ‡ç‰‡åºå·: {slice_index + 1}
åˆ‡ç‰‡ä½ç½®: {slice_config.get('slice_position', 'æœªçŸ¥')}
åˆ‡ç‰‡ç±»å‹: {slice_config.get('slice_type', 'å¸¸è§„åŒºåŸŸ')}
å…³æ³¨é‡ç‚¹: {', '.join(slice_config.get('focus_areas', ['æ„ä»¶è¯†åˆ«']))}

ã€å‰åºåˆ‡ç‰‡å‘ç°çš„æ„ä»¶ã€‘
"""
        
        # æ·»åŠ å‰åºæ„ä»¶ä¿¡æ¯ï¼ˆæœ€è¿‘3ä¸ªï¼‰
        recent_components = previous_components[-3:] if len(previous_components) > 3 else previous_components
        for comp in recent_components:
            prompt += f"- {comp.get('component_id', 'æœªçŸ¥')}: {comp.get('component_type', 'æœªçŸ¥')} "
            prompt += f"({comp.get('dimensions', 'æœªçŸ¥å°ºå¯¸')})\n"
        
        prompt += f"""

ã€åˆ†æè¦æ±‚ã€‘
è¯·åŸºäºä»¥ä¸Šå…¨å›¾ä¸Šä¸‹æ–‡å’Œå‰åºåˆ†æç»“æœï¼Œé‡ç‚¹åˆ†æå½“å‰åˆ‡ç‰‡ä¸­çš„ï¼š
1. æ„ä»¶è¯¦ç»†ä¿¡æ¯ï¼ˆç¼–å·ã€ç±»å‹ã€å°ºå¯¸ï¼‰
2. æ„ä»¶ä¸æ•´ä½“é¡¹ç›®çš„å…³ç³»
3. é…ç­‹å’Œææ–™ä¿¡æ¯
4. ç‰¹æ®Šæ ‡æ³¨å’Œè¿æ¥å…³ç³»

ã€ä¸€è‡´æ€§è¦æ±‚ã€‘
- æ„ä»¶ç¼–å·åº”ç¬¦åˆæ•´ä½“ç¼–å·è§„å¾‹
- å°ºå¯¸å•ä½åº”ä¸å›¾çº¸æ¯”ä¾‹({global_ctx['scale']})åŒ¹é…
- é¡¹ç›®ä¿¡æ¯åº”ä¸å…¨å›¾åˆ†æä¿æŒä¸€è‡´
- é¿å…é‡å¤è¯†åˆ«å·²åˆ†æçš„æ„ä»¶
"""
        
        return prompt
    
    def _execute_contextual_slice_analysis(self, 
                                         slice_image: str,
                                         slice_config: Dict[str, Any],
                                         contextual_prompt: str,
                                         task_id: str,
                                         drawing_id: int = None) -> Dict[str, Any]:
        """æ‰§è¡Œå¸¦ä¸Šä¸‹æ–‡çš„åˆ‡ç‰‡åˆ†æï¼ˆç®€åŒ–ä¸‰æ­¥ï¼‰"""
        
        try:
            # å‡†å¤‡å›¾åƒæ•°æ®
            encoded_images = self.ai_analyzer._prepare_images([slice_image])
            if not encoded_images:
                return {"success": False, "error": "å›¾åƒå‡†å¤‡å¤±è´¥"}
            
            # æ‰§è¡Œç®€åŒ–çš„ä¸‰æ­¥åˆ†æè€Œä¸æ˜¯å®Œæ•´äº”æ­¥
            # Step 1: æ„ä»¶è¯†åˆ«
            step1_result = self._contextual_step1_component_identification(
                encoded_images, contextual_prompt, task_id, drawing_id
            )
            
            if not step1_result.get("success"):
                return step1_result
            
            # Step 2: å°ºå¯¸æå–
            step2_result = self._contextual_step2_dimension_extraction(
                encoded_images, step1_result["data"], contextual_prompt, task_id, drawing_id
            )
            
            if not step2_result.get("success"):
                return step2_result
            
            # Step 3: å±æ€§æå–
            step3_result = self._contextual_step3_attribute_extraction(
                encoded_images, step1_result["data"], step2_result["data"], 
                contextual_prompt, task_id, drawing_id
            )
            
            if not step3_result.get("success"):
                return step3_result
            
            # åˆæˆåˆ‡ç‰‡QTOæ•°æ®
            slice_qto = self._synthesize_slice_qto(
                step1_result["data"], step2_result["data"], step3_result["data"], slice_config
            )
            
            return {
                "success": True,
                "qto_data": slice_qto,
                "analysis_method": "contextual_three_step",
                "context_prompt_used": len(contextual_prompt)
            }
            
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¸‹æ–‡åˆ‡ç‰‡åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _contextual_step1_component_identification(self, 
                                                 encoded_images: List[Dict],
                                                 contextual_prompt: str,
                                                 task_id: str,
                                                 drawing_id: int) -> Dict[str, Any]:
        """ä¸Šä¸‹æ–‡åŒ–çš„æ­¥éª¤1ï¼šæ„ä»¶è¯†åˆ«"""
        
        system_prompt = f"""ä½ æ˜¯ç»éªŒä¸°å¯Œçš„ç»“æ„å·¥ç¨‹å¸ˆã€‚åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»”ç»†åˆ†æå½“å‰åˆ‡ç‰‡ä¸­çš„æ„ä»¶ã€‚

{contextual_prompt}

è¯·è¯†åˆ«åˆ‡ç‰‡ä¸­çš„æ‰€æœ‰æ„ä»¶ï¼Œè¿”å›JSONæ ¼å¼ï¼š
{{
    "components": [
        {{
            "component_id": "æ„ä»¶ç¼–å·ï¼ˆå¦‚KZ-1ã€L-1ç­‰ï¼Œåº”ç¬¦åˆæ•´ä½“ç¼–å·è§„å¾‹ï¼‰",
            "component_type": "æ„ä»¶ç±»å‹ï¼ˆæŸ±ã€æ¢ã€æ¿ã€å¢™ç­‰ï¼‰",
            "position_in_slice": "åœ¨åˆ‡ç‰‡ä¸­çš„ä½ç½®æè¿°",
            "confidence": "è¯†åˆ«ç½®ä¿¡åº¦(0-1)",
            "is_continuation": "æ˜¯å¦ä¸ºå‰åºåˆ‡ç‰‡æ„ä»¶çš„å»¶ç»­(true/false)"
        }}
    ]
}}"""
        
        user_content = [{
            "type": "text", 
            "text": "è¯·åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¯†åˆ«å½“å‰åˆ‡ç‰‡ä¸­çš„æ„ä»¶ã€‚æ³¨æ„ä¿æŒä¸æ•´ä½“é¡¹ç›®çš„ä¸€è‡´æ€§ã€‚"
        }] + encoded_images
        
        return self.ai_analyzer._execute_vision_step(
            "contextual_step1", system_prompt, user_content, task_id, drawing_id
        )
    
    def _contextual_step2_dimension_extraction(self, 
                                             encoded_images: List[Dict],
                                             components: Dict[str, Any],
                                             contextual_prompt: str,
                                             task_id: str,
                                             drawing_id: int) -> Dict[str, Any]:
        """ä¸Šä¸‹æ–‡åŒ–çš„æ­¥éª¤2ï¼šå°ºå¯¸æå–"""
        
        component_list = components.get("components", [])
        component_ids = [comp.get("component_id", "") for comp in component_list]
        
        system_prompt = f"""åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯å’Œå·²è¯†åˆ«çš„æ„ä»¶ï¼Œæå–è¯¦ç»†å°ºå¯¸ä¿¡æ¯ã€‚

{contextual_prompt}

å·²è¯†åˆ«æ„ä»¶ï¼š{', '.join(component_ids)}

è¯·æå–æ¯ä¸ªæ„ä»¶çš„å°ºå¯¸ä¿¡æ¯ï¼Œè¿”å›JSONæ ¼å¼ï¼š
{{
    "dimensions": [
        {{
            "component_id": "æ„ä»¶ç¼–å·",
            "width": "å®½åº¦ï¼ˆmmï¼‰",
            "height": "é«˜åº¦ï¼ˆmmï¼‰", 
            "length": "é•¿åº¦ï¼ˆmmï¼‰",
            "thickness": "åšåº¦ï¼ˆmmï¼Œå¦‚é€‚ç”¨ï¼‰",
            "section_info": "æˆªé¢ä¿¡æ¯",
            "unit_consistency_check": "å•ä½æ˜¯å¦ä¸å›¾çº¸æ¯”ä¾‹ä¸€è‡´"
        }}
    ]
}}"""
        
        user_content = [{
            "type": "text",
            "text": f"è¯·ä¸ºå·²è¯†åˆ«çš„æ„ä»¶({', '.join(component_ids)})æå–è¯¦ç»†å°ºå¯¸ä¿¡æ¯ã€‚æ³¨æ„å•ä½ä¸€è‡´æ€§ã€‚"
        }] + encoded_images
        
        return self.ai_analyzer._execute_vision_step(
            "contextual_step2", system_prompt, user_content, task_id, drawing_id
        )
    
    def _contextual_step3_attribute_extraction(self, 
                                             encoded_images: List[Dict],
                                             components: Dict[str, Any],
                                             dimensions: Dict[str, Any],
                                             contextual_prompt: str,
                                             task_id: str,
                                             drawing_id: int) -> Dict[str, Any]:
        """ä¸Šä¸‹æ–‡åŒ–çš„æ­¥éª¤3ï¼šå±æ€§æå–"""
        
        system_prompt = f"""åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯ã€æ„ä»¶å’Œå°ºå¯¸ä¿¡æ¯ï¼Œæå–æ„ä»¶å±æ€§ã€‚

{contextual_prompt}

è¯·æå–æ„ä»¶çš„ææ–™ã€é…ç­‹ç­‰å±æ€§ä¿¡æ¯ï¼Œè¿”å›JSONæ ¼å¼ï¼š
{{
    "attributes": [
        {{
            "component_id": "æ„ä»¶ç¼–å·",
            "concrete_grade": "æ··å‡åœŸå¼ºåº¦ç­‰çº§",
            "steel_grade": "é’¢ç­‹ç­‰çº§",
            "reinforcement": "é…ç­‹ä¿¡æ¯",
            "special_requirements": "ç‰¹æ®Šè¦æ±‚",
            "connection_details": "è¿æ¥è¯¦æƒ…"
        }}
    ]
}}"""
        
        user_content = [{
            "type": "text",
            "text": "è¯·æå–æ„ä»¶çš„ææ–™å’Œé…ç­‹å±æ€§ä¿¡æ¯ã€‚"
        }] + encoded_images
        
        return self.ai_analyzer._execute_vision_step(
            "contextual_step3", system_prompt, user_content, task_id, drawing_id
        )
    
    def _synthesize_slice_qto(self, 
                            components: Dict[str, Any],
                            dimensions: Dict[str, Any], 
                            attributes: Dict[str, Any],
                            slice_config: Dict[str, Any]) -> Dict[str, Any]:
        """åˆæˆåˆ‡ç‰‡QTOæ•°æ®"""
        
        try:
            comp_list = components.get("components", [])
            dim_list = dimensions.get("dimensions", [])
            attr_list = attributes.get("attributes", [])
            
            # åˆå¹¶æ„ä»¶ä¿¡æ¯
            merged_components = []
            for comp in comp_list:
                comp_id = comp.get("component_id", "")
                
                # æŸ¥æ‰¾å¯¹åº”çš„å°ºå¯¸ä¿¡æ¯
                comp_dimensions = {}
                for dim in dim_list:
                    if dim.get("component_id", "") == comp_id:
                        comp_dimensions = dim
                        break
                
                # æŸ¥æ‰¾å¯¹åº”çš„å±æ€§ä¿¡æ¯
                comp_attributes = {}
                for attr in attr_list:
                    if attr.get("component_id", "") == comp_id:
                        comp_attributes = attr
                        break
                
                # åˆå¹¶ä¿¡æ¯
                merged_comp = {
                    **comp,
                    "dimensions": comp_dimensions,
                    "attributes": comp_attributes,
                    "slice_metadata": {
                        "slice_index": slice_config.get("slice_index", 0),
                        "slice_position": slice_config.get("slice_position", ""),
                        "analysis_method": "contextual_slice_analysis"
                    }
                }
                merged_components.append(merged_comp)
            
            return {
                "components": merged_components,
                "slice_summary": {
                    "total_components": len(merged_components),
                    "slice_config": slice_config,
                    "analysis_timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                },
                "global_context_applied": True
            }
            
        except Exception as e:
            logger.error(f"âŒ åˆ‡ç‰‡QTOåˆæˆå¤±è´¥: {e}")
            return {
                "components": [],
                "slice_summary": {"error": str(e)},
                "global_context_applied": False
            }
    
    def _update_accumulated_context(self, 
                                  accumulated_context: Dict[str, Any],
                                  slice_qto_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ›´æ–°ç´¯ç§¯ä¸Šä¸‹æ–‡"""
        
        try:
            components = slice_qto_data.get("components", [])
            
            # æ·»åŠ åˆ°ç´¯ç§¯æ„ä»¶åˆ—è¡¨
            accumulated_context["previous_components"].extend(components)
            
            # æ›´æ–°æ„ä»¶è®¡æ•°
            accumulated_context["component_count_running_total"] += len(components)
            
            # æå–ä½ç½®ä¿¡æ¯
            for comp in components:
                if "position_in_slice" in comp:
                    accumulated_context["previous_positions"].append({
                        "component_id": comp.get("component_id", ""),
                        "position": comp.get("position_in_slice", "")
                    })
            
            return accumulated_context
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç´¯ç§¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return accumulated_context
    
    def _merge_and_validate_results(self, 
                                  global_analysis: Dict[str, Any],
                                  slice_results: List[Dict[str, Any]],
                                  task_id: str) -> Dict[str, Any]:
        """åˆå¹¶å’ŒéªŒè¯ç»“æœ"""
        
        try:
            # æ”¶é›†æ‰€æœ‰åˆ‡ç‰‡çš„æ„ä»¶
            all_slice_components = []
            successful_slices = 0
            
            for slice_result in slice_results:
                if slice_result["analysis_result"].get("success"):
                    successful_slices += 1
                    components = slice_result["analysis_result"]["qto_data"].get("components", [])
                    all_slice_components.extend(components)
            
            # å»é‡å’Œä¸€è‡´æ€§æ£€æŸ¥
            deduplicated_components = self._deduplicate_components(all_slice_components)
            
            # ä¸€è‡´æ€§éªŒè¯
            consistency_report = self._validate_consistency_with_global(
                global_analysis["qto_data"], deduplicated_components
            )
            
            # æ„å»ºæœ€ç»ˆç»“æœ
            final_result = {
                "success": True,
                "analysis_method": "contextual_slice_chain",
                "qto_data": {
                    "drawing_info": global_analysis["qto_data"].get("drawing_info", {}),
                    "components": deduplicated_components,
                    "component_summary": {
                        "total_components": len(deduplicated_components),
                        "component_types": list(set([
                            comp.get("component_type", "unknown") for comp in deduplicated_components
                        ])),
                        "sources": {
                            "global_analysis": True,
                            "successful_slices": successful_slices,
                            "total_slices": len(slice_results)
                        }
                    }
                },
                "analysis_metadata": {
                    "global_context": asdict(self.global_context),
                    "slice_analysis_summary": {
                        "total_slices": len(slice_results),
                        "successful_slices": successful_slices,
                        "failed_slices": len(slice_results) - successful_slices
                    },
                    "consistency_report": consistency_report,
                    "analysis_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "task_id": task_id
                }
            }
            
            logger.info(f"âœ… ç»“æœåˆå¹¶å®Œæˆ: {len(deduplicated_components)} ä¸ªæ„ä»¶, "
                       f"æˆåŠŸåˆ‡ç‰‡: {successful_slices}/{len(slice_results)}")
            
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ ç»“æœåˆå¹¶å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis_method": "contextual_slice_chain"
            }
    
    def _deduplicate_components(self, components: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»é™¤é‡å¤æ„ä»¶"""
        
        unique_components = []
        seen_ids = set()
        
        for comp in components:
            comp_id = comp.get("component_id", "")
            if comp_id and comp_id not in seen_ids:
                seen_ids.add(comp_id)
                unique_components.append(comp)
            elif not comp_id:
                # å¯¹äºæ²¡æœ‰IDçš„æ„ä»¶ï¼ŒåŸºäºä½ç½®å’Œç±»å‹åˆ¤æ–­
                position = comp.get("position_in_slice", "")
                comp_type = comp.get("component_type", "")
                identifier = f"{comp_type}_{position}"
                
                if identifier not in seen_ids:
                    seen_ids.add(identifier)
                    unique_components.append(comp)
        
        logger.info(f"ğŸ”„ æ„ä»¶å»é‡: {len(components)} -> {len(unique_components)}")
        return unique_components
    
    def _validate_consistency_with_global(self, 
                                        global_qto: Dict[str, Any],
                                        slice_components: List[Dict[str, Any]]) -> Dict[str, Any]:
        """éªŒè¯åˆ‡ç‰‡ç»“æœä¸å…¨å±€åˆ†æçš„ä¸€è‡´æ€§"""
        
        consistency_report = {
            "project_info_consistent": True,
            "component_numbering_consistent": True,
            "scale_consistent": True,
            "warnings": [],
            "errors": []
        }
        
        try:
            global_drawing_info = global_qto.get("drawing_info", {})
            global_project_name = global_drawing_info.get("project_name", "")
            
            # æ£€æŸ¥é¡¹ç›®åç§°ä¸€è‡´æ€§
            for comp in slice_components:
                slice_metadata = comp.get("slice_metadata", {})
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šä¸€è‡´æ€§æ£€æŸ¥é€»è¾‘
            
            # æ£€æŸ¥æ„ä»¶ç¼–å·è§„å¾‹
            component_ids = [comp.get("component_id", "") for comp in slice_components if comp.get("component_id")]
            
            # ç®€å•çš„ç¼–å·è§„å¾‹æ£€æŸ¥
            prefixes = set()
            for comp_id in component_ids:
                if "-" in comp_id:
                    prefix = comp_id.split("-")[0]
                    prefixes.add(prefix)
            
            if len(prefixes) > 10:  # å¦‚æœå‰ç¼€è¿‡å¤šï¼Œå¯èƒ½å­˜åœ¨ä¸ä¸€è‡´
                consistency_report["warnings"].append(f"æ„ä»¶ç¼–å·å‰ç¼€è¿‡å¤š({len(prefixes)})ï¼Œå¯èƒ½å­˜åœ¨ä¸ä¸€è‡´")
            
        except Exception as e:
            consistency_report["errors"].append(f"ä¸€è‡´æ€§æ£€æŸ¥å¼‚å¸¸: {e}")
        
        return consistency_report 