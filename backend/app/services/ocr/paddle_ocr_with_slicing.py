#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÈõÜÊàêÊô∫ËÉΩÂàáÁâáÂäüËÉΩÁöÑPaddleOCRÊúçÂä°
Â∞ÜÊô∫ËÉΩÂàáÁâáÊ®°ÂùóÊèêÂâçÂà∞OCRÂ§ÑÁêÜÈò∂ÊÆµÔºåÊèêÈ´òOCRÁ≤æÂ∫¶ÂíåÂ§ÑÁêÜÊïàÊûú
"""

import logging
import time
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
import cv2
import numpy as np
from dataclasses import dataclass
import json
import uuid

from app.services.intelligent_image_slicer import IntelligentImageSlicer, SliceInfo
from app.services.ocr.paddle_ocr import PaddleOCRService
from app.services.dual_storage_service import DualStorageService

logger = logging.getLogger(__name__)

@dataclass
class OCRSliceResult:
    """OCRÂàáÁâáÁªìÊûú"""
    slice_id: str
    slice_index: int
    slice_bounds: Tuple[int, int, int, int]  # (x, y, width, height)
    slice_path: str
    ocr_result: Dict[str, Any]
    text_regions: List[Dict[str, Any]]
    processing_time: float
    success: bool
    error_message: str = ""

@dataclass
class MergedOCRResult:
    """ÂêàÂπ∂ÂêéÁöÑOCRÁªìÊûú"""
    task_id: str
    total_slices: int
    successful_slices: int
    success_rate: float
    total_text_regions: int
    merged_text_regions: List[Dict[str, Any]]
    all_text: str
    processing_summary: Dict[str, Any]
    slice_results: List[OCRSliceResult]
    processing_time: float

class PaddleOCRWithSlicing:
    """
    PaddleOCR with intelligent slicing support - ‰ΩøÁî®ÂèåÈáçÂ≠òÂÇ®
    """
    
    def __init__(self):
        """ÂàùÂßãÂåñOCRÂàáÁâáÊúçÂä°"""
        self.ocr_service = PaddleOCRService()
        self.slicer = IntelligentImageSlicer()
        
        # ‰ΩøÁî®ÂèåÈáçÂ≠òÂÇ®ÊúçÂä°
        try:
            self.storage = DualStorageService()
            logger.info("‚úÖ PaddleOCRWithSlicing ‰ΩøÁî®ÂèåÈáçÂ≠òÂÇ®ÊúçÂä°")
        except Exception as e:
            logger.error(f"ÂèåÈáçÂ≠òÂÇ®ÊúçÂä°ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
            self.storage = None
        
        # ÂàáÁâáÈÖçÁΩÆ
        self.slice_config = {
            'max_resolution': 2048,      # OCRÂàáÁâáÊúÄÂ§ßÂàÜËæ®Áéá
            'overlap_ratio': 0.15,       # OCRÈúÄË¶ÅÊõ¥Â§öÈáçÂè†‰ª•Á°Æ‰øùÊñáÂ≠óÂÆåÊï¥
            'quality': 95,               # OCRÈúÄË¶ÅÈ´òË¥®ÈáèÂõæÂÉè
            'min_slice_size': 512,       # ÊúÄÂ∞èÂàáÁâáÂ∞∫ÂØ∏
            'max_slices': 16             # OCRÊúÄÂ§ßÂàáÁâáÊï∞
        }
        
        logger.info("üîß PaddleOCRÊô∫ËÉΩÂàáÁâáÊúçÂä°ÂàùÂßãÂåñÂÆåÊàê")
    
    def is_available(self) -> bool:
        """Ê£ÄÊü•ÊúçÂä°ÊòØÂê¶ÂèØÁî®"""
        return (self.slicer.is_available() and 
                self.ocr_service.is_available())
    
    async def process_image_with_slicing(self, 
                                       image_path: str, 
                                       task_id: str = None,
                                       save_to_storage: bool = True) -> MergedOCRResult:
        """
        ‰ΩøÁî®Êô∫ËÉΩÂàáÁâáÂ§ÑÁêÜÂõæÂÉèOCR
        
        Args:
            image_path: ÂõæÂÉèÊñá‰ª∂Ë∑ØÂæÑ
            task_id: ‰ªªÂä°ID
            save_to_storage: ÊòØÂê¶‰øùÂ≠òÂà∞‰∫ëÂ≠òÂÇ®
            
        Returns:
            ÂêàÂπ∂ÂêéÁöÑOCRÁªìÊûú
        """
        if not task_id:
            task_id = f"ocr_slice_{uuid.uuid4().hex[:8]}"
        
        logger.info(f"üöÄ ÂºÄÂßãÊô∫ËÉΩÂàáÁâáOCRÂ§ÑÁêÜ - ‰ªªÂä°ID: {task_id}")
        start_time = time.time()
        
        try:
            # 1. Ê£ÄÊü•ÊòØÂê¶ÈúÄË¶ÅÂàáÁâá
            needs_slicing = await self._should_slice_image(image_path)
            
            if not needs_slicing:
                logger.info(f"ÂõæÂÉèÂ∞∫ÂØ∏ÈÄÇ‰∏≠Ôºå‰ΩøÁî®Áõ¥Êé•OCRÂ§ÑÁêÜ - {task_id}")
                return await self._process_direct_ocr(image_path, task_id, save_to_storage)
            
            # 2. ÊâßË°åÊô∫ËÉΩÂàáÁâá
            logger.info(f"ÊâßË°åÊô∫ËÉΩÂàáÁâá - {task_id}")
            slice_info = await self._execute_image_slicing(image_path, task_id)
            
            if not slice_info or not slice_info.slices:
                logger.warning(f"ÂàáÁâáÂ§±Ë¥•ÔºåÂõûÈÄÄÂà∞Áõ¥Êé•OCR - {task_id}")
                return await self._process_direct_ocr(image_path, task_id, save_to_storage)
            
            # 3. Âπ∂Ë°åÂ§ÑÁêÜÊâÄÊúâÂàáÁâáÁöÑOCR
            logger.info(f"Âπ∂Ë°åÂ§ÑÁêÜ {len(slice_info.slices)} ‰∏™ÂàáÁâáÁöÑOCR - {task_id}")
            slice_results = await self._process_slices_ocr(slice_info, task_id)
            
            # 4. ÂêàÂπ∂OCRÁªìÊûú
            logger.info(f"ÂêàÂπ∂OCRÁªìÊûú - {task_id}")
            merged_result = await self._merge_ocr_results(
                slice_results, slice_info, task_id, start_time
            )
            
            # 5. ‰øùÂ≠òÁªìÊûúÂà∞ÂèåÈáçÂ≠òÂÇ®
            if save_to_storage:
                await self._save_results_to_storage(merged_result, task_id)
            
            processing_time = time.time() - start_time
            logger.info(f"‚úÖ Êô∫ËÉΩÂàáÁâáOCRÂÆåÊàê - {task_id}, ËÄóÊó∂: {processing_time:.2f}s, "
                       f"ËØÜÂà´ÊñáÊú¨: {merged_result.total_text_regions}")
            
            return merged_result
            
        except Exception as e:
            logger.error(f"‚ùå Êô∫ËÉΩÂàáÁâáOCRÂ§±Ë¥• - {task_id}: {e}")
            # ÂõûÈÄÄÂà∞Áõ¥Êé•OCR
            try:
                logger.info(f"ÂõûÈÄÄÂà∞Áõ¥Êé•OCRÂ§ÑÁêÜ - {task_id}")
                return await self._process_direct_ocr(image_path, task_id, save_to_storage)
            except Exception as fallback_error:
                logger.error(f"‚ùå Áõ¥Êé•OCRÂõûÈÄÄ‰πüÂ§±Ë¥• - {task_id}: {fallback_error}")
                raise Exception(f"OCRÂ§ÑÁêÜÂÆåÂÖ®Â§±Ë¥•: {str(e)} | ÂõûÈÄÄÈîôËØØ: {str(fallback_error)}")
    
    async def _should_slice_image(self, image_path: str) -> bool:
        """Âà§Êñ≠ÊòØÂê¶ÈúÄË¶ÅÂØπÂõæÂÉèËøõË°åÂàáÁâá"""
        try:
            with cv2.imread(image_path) as img:
                if img is None:
                    return False
                
                height, width = img.shape[:2]
                max_dimension = max(width, height)
                total_pixels = width * height
                
                # Âà§Êñ≠Êù°‰ª∂
                needs_slicing = (
                    max_dimension > self.slice_config['max_resolution'] or
                    total_pixels > 4_000_000  # 4MÂÉèÁ¥†‰ª•‰∏ä
                )
                
                logger.info(f"ÂõæÂÉèÂ∞∫ÂØ∏: {width}x{height}, ÊòØÂê¶ÈúÄË¶ÅÂàáÁâá: {needs_slicing}")
                return needs_slicing
                
        except Exception as e:
            logger.error(f"Ê£ÄÊü•ÂõæÂÉèÂ∞∫ÂØ∏Â§±Ë¥•: {e}")
            return False
    
    async def _execute_image_slicing(self, image_path: str, task_id: str) -> SliceInfo:
        """ÊâßË°åÂõæÂÉèÂàáÁâá"""
        try:
            slice_info = await self.slicer.slice_image_async(
                image_path=image_path,
                max_resolution=self.slice_config['max_resolution'],
                overlap_ratio=self.slice_config['overlap_ratio'],
                quality=self.slice_config['quality'],
                output_dir=f"ocr_slices_{task_id}"
            )
            
            logger.info(f"ÂàáÁâáÂÆåÊàê: {len(slice_info.slices)} ‰∏™ÂàáÁâá")
            return slice_info
            
        except Exception as e:
            logger.error(f"ÂõæÂÉèÂàáÁâáÂ§±Ë¥•: {e}")
            raise
    
    async def _process_slices_ocr(self, slice_info: SliceInfo, task_id: str) -> List[OCRSliceResult]:
        """Âπ∂Ë°åÂ§ÑÁêÜÊâÄÊúâÂàáÁâáÁöÑOCR"""
        
        async def process_single_slice(slice_data, index) -> OCRSliceResult:
            """Â§ÑÁêÜÂçï‰∏™ÂàáÁâáÁöÑOCR"""
            slice_id = f"{task_id}_slice_{index}"
            start_time = time.time()
            
            try:
                logger.debug(f"Â§ÑÁêÜÂàáÁâá {index+1}/{len(slice_info.slices)} - {slice_id}")
                
                # Ë∞ÉÁî®PaddleOCRÂ§ÑÁêÜÂàáÁâá
                ocr_result = self.ocr_service.recognize_text(
                    image_path=slice_data.path,
                    save_to_sealos=False,  # ‰∏ç‰øùÂ≠òÂçï‰∏™ÂàáÁâáÁªìÊûú
                    drawing_id=slice_id
                )
                
                processing_time = time.time() - start_time
                
                # ËΩ¨Êç¢ÂùêÊ†áÂà∞ÂéüÂõæÂùêÊ†áÁ≥ª
                adjusted_text_regions = self._adjust_coordinates_to_original(
                    ocr_result.get('text_regions', []),
                    slice_data.bounds
                )
                
                return OCRSliceResult(
                    slice_id=slice_id,
                    slice_index=index,
                    slice_bounds=slice_data.bounds,
                    slice_path=slice_data.path,
                    ocr_result=ocr_result,
                    text_regions=adjusted_text_regions,
                    processing_time=processing_time,
                    success=ocr_result.get('success', False)
                )
                
            except Exception as e:
                processing_time = time.time() - start_time
                logger.error(f"ÂàáÁâá {slice_id} OCRÂ§±Ë¥•: {e}")
                
                return OCRSliceResult(
                    slice_id=slice_id,
                    slice_index=index,
                    slice_bounds=slice_data.bounds,
                    slice_path=slice_data.path,
                    ocr_result={},
                    text_regions=[],
                    processing_time=processing_time,
                    success=False,
                    error_message=str(e)
                )
        
        # Âπ∂Ë°åÂ§ÑÁêÜÊâÄÊúâÂàáÁâá
        logger.info(f"ÂºÄÂßãÂπ∂Ë°åÂ§ÑÁêÜ {len(slice_info.slices)} ‰∏™ÂàáÁâáÁöÑOCR")
        
        # ÈôêÂà∂Âπ∂ÂèëÊï∞Èáè‰ª•ÈÅøÂÖçËµÑÊ∫êËÄóÂ∞Ω
        semaphore = asyncio.Semaphore(4)  # ÊúÄÂ§ö4‰∏™Âπ∂ÂèëOCR
        
        async def process_with_semaphore(slice_data, index):
            async with semaphore:
                return await process_single_slice(slice_data, index)
        
        tasks = [
            process_with_semaphore(slice_data, index)
            for index, slice_data in enumerate(slice_info.slices)
        ]
        
        slice_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Â§ÑÁêÜÂºÇÂ∏∏ÁªìÊûú
        valid_results = []
        for i, result in enumerate(slice_results):
            if isinstance(result, Exception):
                logger.error(f"ÂàáÁâá {i} Â§ÑÁêÜÂºÇÂ∏∏: {result}")
                # ÂàõÂª∫Â§±Ë¥•ÁªìÊûú
                error_result = OCRSliceResult(
                    slice_id=f"{task_id}_slice_{i}",
                    slice_index=i,
                    slice_bounds=(0, 0, 0, 0),
                    slice_path="",
                    ocr_result={},
                    text_regions=[],
                    processing_time=0,
                    success=False,
                    error_message=str(result)
                )
                valid_results.append(error_result)
            else:
                valid_results.append(result)
        
        successful_count = sum(1 for r in valid_results if r.success)
        logger.info(f"OCRÂ§ÑÁêÜÂÆåÊàê: {successful_count}/{len(valid_results)} ‰∏™ÂàáÁâáÊàêÂäü")
        
        return valid_results
    
    def _adjust_coordinates_to_original(self, 
                                      text_regions: List[Dict[str, Any]], 
                                      slice_bounds: Tuple[int, int, int, int]) -> List[Dict[str, Any]]:
        """Â∞ÜÂàáÁâáÂùêÊ†áË∞ÉÊï¥Âà∞ÂéüÂõæÂùêÊ†áÁ≥ª"""
        
        x_offset, y_offset, _, _ = slice_bounds
        adjusted_regions = []
        
        for region in text_regions:
            adjusted_region = region.copy()
            
            # Ë∞ÉÊï¥ËæπÁïåÊ°ÜÂùêÊ†á
            if 'bbox' in adjusted_region:
                bbox = adjusted_region['bbox']
                if isinstance(bbox, list) and len(bbox) == 4:
                    # Ê†ºÂºè: [x1, y1, x2, y2]
                    adjusted_region['bbox'] = [
                        bbox[0] + x_offset,
                        bbox[1] + y_offset,
                        bbox[2] + x_offset,
                        bbox[3] + y_offset
                    ]
            
            # Ë∞ÉÊï¥Â§öËæπÂΩ¢ÂùêÊ†áÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ
            if 'polygon' in adjusted_region:
                polygon = adjusted_region['polygon']
                if isinstance(polygon, list):
                    adjusted_polygon = []
                    for point in polygon:
                        if isinstance(point, list) and len(point) == 2:
                            adjusted_polygon.append([
                                point[0] + x_offset,
                                point[1] + y_offset
                            ])
                    adjusted_region['polygon'] = adjusted_polygon
            
            # Ê∑ªÂä†ÂàáÁâá‰ø°ÊÅØ
            adjusted_region['source_slice'] = {
                'slice_bounds': slice_bounds,
                'original_bbox': region.get('bbox'),
                'original_polygon': region.get('polygon')
            }
            
            adjusted_regions.append(adjusted_region)
        
        return adjusted_regions
    
    async def _merge_ocr_results(self, 
                               slice_results: List[OCRSliceResult],
                               slice_info: SliceInfo,
                               task_id: str,
                               start_time: float) -> MergedOCRResult:
        """ÂêàÂπ∂ÊâÄÊúâÂàáÁâáÁöÑOCRÁªìÊûú"""
        
        logger.info(f"ÂºÄÂßãÂêàÂπ∂ {len(slice_results)} ‰∏™ÂàáÁâáÁöÑOCRÁªìÊûú")
        
        # Êî∂ÈõÜÊâÄÊúâÊñáÊú¨Âå∫Âüü
        all_text_regions = []
        all_texts = []
        successful_slices = 0
        
        for slice_result in slice_results:
            if slice_result.success:
                successful_slices += 1
                all_text_regions.extend(slice_result.text_regions)
                
                # Êî∂ÈõÜÊñáÊú¨ÂÜÖÂÆπ
                for region in slice_result.text_regions:
                    text = region.get('text', '').strip()
                    if text:
                        all_texts.append(text)
        
        # ÂéªÈáçÈáçÂè†Âå∫ÂüüÁöÑÊñáÊú¨
        deduplicated_regions = self._remove_duplicate_text_regions(all_text_regions)
        
        # ÈáçÊñ∞Êî∂ÈõÜÂéªÈáçÂêéÁöÑÊñáÊú¨
        final_texts = []
        for region in deduplicated_regions:
            text = region.get('text', '').strip()
            if text:
                final_texts.append(text)
        
        # ÁîüÊàêÂ§ÑÁêÜÊëòË¶Å
        processing_summary = {
            'original_image': {
                'width': slice_info.original_width,
                'height': slice_info.original_height,
                'total_pixels': slice_info.original_width * slice_info.original_height
            },
            'slicing_info': {
                'total_slices': len(slice_results),
                'successful_slices': successful_slices,
                'success_rate': successful_slices / len(slice_results) if slice_results else 0,
                'slice_config': self.slice_config
            },
            'ocr_statistics': {
                'total_text_regions_before_dedup': len(all_text_regions),
                'total_text_regions_after_dedup': len(deduplicated_regions),
                'deduplication_rate': 1 - (len(deduplicated_regions) / len(all_text_regions)) if all_text_regions else 0,
                'total_characters': sum(len(text) for text in final_texts),
                'avg_confidence': self._calculate_average_confidence(deduplicated_regions)
            },
            'performance': {
                'total_processing_time': time.time() - start_time,
                'avg_slice_processing_time': sum(r.processing_time for r in slice_results) / len(slice_results) if slice_results else 0
            }
        }
        
        merged_result = MergedOCRResult(
            task_id=task_id,
            total_slices=len(slice_results),
            successful_slices=successful_slices,
            success_rate=successful_slices / len(slice_results) if slice_results else 0,
            total_text_regions=len(deduplicated_regions),
            merged_text_regions=deduplicated_regions,
            all_text='\n'.join(final_texts),
            processing_summary=processing_summary,
            slice_results=slice_results,
            processing_time=time.time() - start_time
        )
        
        logger.info(f"OCRÁªìÊûúÂêàÂπ∂ÂÆåÊàê: {len(deduplicated_regions)} ‰∏™ÊñáÊú¨Âå∫Âüü, "
                   f"ÂéªÈáçÁéá: {processing_summary['ocr_statistics']['deduplication_rate']:.2%}")
        
        return merged_result
    
    def _remove_duplicate_text_regions(self, text_regions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ÂéªÈô§ÈáçÂè†Âå∫ÂüüÁöÑÈáçÂ§çÊñáÊú¨"""
        
        if not text_regions:
            return []
        
        # ÊåâÁΩÆ‰ø°Â∫¶ÊéíÂ∫èÔºàÈ´òÁΩÆ‰ø°Â∫¶‰ºòÂÖàÔºâ
        sorted_regions = sorted(
            text_regions, 
            key=lambda x: x.get('confidence', 0), 
            reverse=True
        )
        
        deduplicated = []
        
        for current_region in sorted_regions:
            current_text = current_region.get('text', '').strip()
            current_bbox = current_region.get('bbox', [0, 0, 0, 0])
            
            if not current_text:
                continue
            
            # Ê£ÄÊü•ÊòØÂê¶‰∏éÂ∑≤ÊúâÂå∫ÂüüÈáçÂ§ç
            is_duplicate = False
            
            for existing_region in deduplicated:
                existing_text = existing_region.get('text', '').strip()
                existing_bbox = existing_region.get('bbox', [0, 0, 0, 0])
                
                # ÊñáÊú¨Áõ∏‰ººÂ∫¶Ê£ÄÊü•
                text_similarity = self._calculate_text_similarity(current_text, existing_text)
                
                # ‰ΩçÁΩÆÈáçÂè†Ê£ÄÊü•
                overlap_ratio = self._calculate_bbox_overlap(current_bbox, existing_bbox)
                
                # Âà§Êñ≠ÊòØÂê¶‰∏∫ÈáçÂ§ç
                if (text_similarity > 0.8 and overlap_ratio > 0.3) or \
                   (text_similarity > 0.9) or \
                   (overlap_ratio > 0.7 and text_similarity > 0.5):
                    is_duplicate = True
                    logger.debug(f"Ê£ÄÊµãÂà∞ÈáçÂ§çÊñáÊú¨: '{current_text}' vs '{existing_text}', "
                               f"ÊñáÊú¨Áõ∏‰ººÂ∫¶: {text_similarity:.2f}, ÈáçÂè†Áéá: {overlap_ratio:.2f}")
                    break
            
            if not is_duplicate:
                deduplicated.append(current_region)
        
        logger.info(f"ÂéªÈáçÂÆåÊàê: {len(text_regions)} -> {len(deduplicated)} ‰∏™ÊñáÊú¨Âå∫Âüü")
        return deduplicated
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """ËÆ°ÁÆóÊñáÊú¨Áõ∏‰ººÂ∫¶"""
        if not text1 or not text2:
            return 0.0
        
        # ÁÆÄÂçïÁöÑÂ≠óÁ¨¶Á∫ßÁõ∏‰ººÂ∫¶ËÆ°ÁÆó
        set1 = set(text1)
        set2 = set(text2)
        
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        return intersection / union if union > 0 else 0.0
    
    def _calculate_bbox_overlap(self, bbox1: List[int], bbox2: List[int]) -> float:
        """ËÆ°ÁÆóËæπÁïåÊ°ÜÈáçÂè†Áéá"""
        if len(bbox1) != 4 or len(bbox2) != 4:
            return 0.0
        
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        # ËÆ°ÁÆó‰∫§ÈõÜ
        x_left = max(x1_1, x1_2)
        y_top = max(y1_1, y1_2)
        x_right = min(x2_1, x2_2)
        y_bottom = min(y2_1, y2_2)
        
        if x_right < x_left or y_bottom < y_top:
            return 0.0
        
        intersection_area = (x_right - x_left) * (y_bottom - y_top)
        
        # ËÆ°ÁÆóÂπ∂ÈõÜ
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union_area = area1 + area2 - intersection_area
        
        return intersection_area / union_area if union_area > 0 else 0.0
    
    def _calculate_average_confidence(self, text_regions: List[Dict[str, Any]]) -> float:
        """ËÆ°ÁÆóÂπ≥ÂùáÁΩÆ‰ø°Â∫¶"""
        if not text_regions:
            return 0.0
        
        confidences = [region.get('confidence', 0) for region in text_regions]
        return sum(confidences) / len(confidences)
    
    async def _process_direct_ocr(self, 
                                image_path: str, 
                                task_id: str, 
                                save_to_storage: bool) -> MergedOCRResult:
        """Áõ¥Êé•OCRÂ§ÑÁêÜÔºà‰∏çÂàáÁâáÔºâ"""
        
        logger.info(f"ÊâßË°åÁõ¥Êé•OCRÂ§ÑÁêÜ - {task_id}")
        start_time = time.time()
        
        try:
            # Ë∞ÉÁî®ÂéüÂßãOCRÊúçÂä°
            ocr_result = self.ocr_service.recognize_text(
                image_path=image_path,
                save_to_sealos=save_to_storage,
                drawing_id=task_id
            )
            
            processing_time = time.time() - start_time
            
            # ËΩ¨Êç¢‰∏∫Áªü‰∏ÄÊ†ºÂºè
            text_regions = ocr_result.get('text_regions', [])
            all_text = ocr_result.get('all_text', '')
            
            # Ëé∑ÂèñÂõæÂÉè‰ø°ÊÅØ
            with cv2.imread(image_path) as img:
                height, width = img.shape[:2] if img is not None else (0, 0)
            
            processing_summary = {
                'original_image': {
                    'width': width,
                    'height': height,
                    'total_pixels': width * height
                },
                'slicing_info': {
                    'total_slices': 1,
                    'successful_slices': 1 if ocr_result.get('success', False) else 0,
                    'success_rate': 1.0 if ocr_result.get('success', False) else 0.0,
                    'slice_config': None
                },
                'ocr_statistics': {
                    'total_text_regions_before_dedup': len(text_regions),
                    'total_text_regions_after_dedup': len(text_regions),
                    'deduplication_rate': 0.0,
                    'total_characters': len(all_text),
                    'avg_confidence': self._calculate_average_confidence(text_regions)
                },
                'performance': {
                    'total_processing_time': processing_time,
                    'avg_slice_processing_time': processing_time
                }
            }
            
            # ÂàõÂª∫ËôöÊãüÂàáÁâáÁªìÊûú
            slice_result = OCRSliceResult(
                slice_id=f"{task_id}_direct",
                slice_index=0,
                slice_bounds=(0, 0, width, height),
                slice_path=image_path,
                ocr_result=ocr_result,
                text_regions=text_regions,
                processing_time=processing_time,
                success=ocr_result.get('success', False)
            )
            
            return MergedOCRResult(
                task_id=task_id,
                total_slices=1,
                successful_slices=1 if ocr_result.get('success', False) else 0,
                success_rate=1.0 if ocr_result.get('success', False) else 0.0,
                total_text_regions=len(text_regions),
                merged_text_regions=text_regions,
                all_text=all_text,
                processing_summary=processing_summary,
                slice_results=[slice_result],
                processing_time=processing_time
            )
            
        except Exception as e:
            logger.error(f"Áõ¥Êé•OCRÂ§ÑÁêÜÂ§±Ë¥• - {task_id}: {e}")
            raise
    
    async def _save_results_to_storage(self, merged_result: MergedOCRResult, task_id: str):
        """‰øùÂ≠òÁªìÊûúÂà∞ÂèåÈáçÂ≠òÂÇ®"""
        if not self.storage:
            logger.warning("Â≠òÂÇ®ÊúçÂä°‰∏çÂèØÁî®ÔºåË∑≥ËøáÁªìÊûú‰øùÂ≠ò")
            return
            
        try:
            # ‰øùÂ≠òÂêàÂπ∂ÂêéÁöÑOCRÁªìÊûú
            result_data = {
                'task_id': merged_result.task_id,
                'total_text_regions': merged_result.total_text_regions,
                'merged_text_regions': merged_result.merged_text_regions,
                'all_text': merged_result.all_text,
                'processing_summary': merged_result.processing_summary,
                'timestamp': time.time()
            }
            
            # ‰ΩøÁî®ÂèåÈáçÂ≠òÂÇ®ÂºÇÊ≠•‰∏ä‰º†
            result_key = f"ocr_slicing_results/{task_id}/merged_result.json"
            url = await self.storage.upload_json_content_async(
                data=result_data,
                file_path=result_key
            )
            
            logger.info(f"‚úÖ OCRÂàáÁâáÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞ÂèåÈáçÂ≠òÂÇ®: {url}")
            
        except Exception as e:
            logger.error(f"‰øùÂ≠òOCRÂàáÁâáÁªìÊûúÂà∞ÂèåÈáçÂ≠òÂÇ®Â§±Ë¥•: {e}")
            # ‰∏çÊäõÂá∫ÂºÇÂ∏∏ÔºåÂõ†‰∏∫‰øùÂ≠òÂ§±Ë¥•‰∏çÂ∫îËØ•ÂΩ±Âìç‰∏ªË¶ÅÂ§ÑÁêÜÊµÅÁ®ã
    
    async def process_image_async(self, image_path: str, use_slicing: Optional[bool] = None) -> Dict[str, Any]:
        """
        ÂºÇÊ≠•Â§ÑÁêÜÂõæÂÉèOCRÔºàÂÖºÂÆπÂéüÂßãÊé•Âè£Ôºâ
        
        Args:
            image_path: ÂõæÂÉèÊñá‰ª∂Ë∑ØÂæÑ
            use_slicing: ÂÖºÂÆπÊÄßÂèÇÊï∞ÔºåÊô∫ËÉΩÂàáÁâáÁâàÊú¨‰ºöÂøΩÁï•Ê≠§ÂèÇÊï∞
            
        Returns:
            OCRÁªìÊûúÔºàÂÖºÂÆπÂéüÂßãÊ†ºÂºèÔºâ
        """
        try:
            merged_result = await self.process_image_with_slicing(image_path)
            
            # ËΩ¨Êç¢‰∏∫ÂÖºÂÆπÊ†ºÂºè
            return {
                'success': merged_result.success_rate > 0,
                'texts': [
                    {
                        'text': region.get('text', ''),
                        'bbox': region.get('bbox', []),
                        'confidence': region.get('confidence', 0.0)
                    }
                    for region in merged_result.merged_text_regions
                ],
                'text_regions': merged_result.merged_text_regions,
                'all_text': merged_result.all_text,
                'statistics': {
                    'total_regions': merged_result.total_text_regions,
                    'avg_confidence': merged_result.processing_summary['ocr_statistics']['avg_confidence'],
                    'processing_time': merged_result.processing_time
                },
                'processing_summary': merged_result.processing_summary,
                'avg_confidence': merged_result.processing_summary['ocr_statistics']['avg_confidence'],
                'processing_time': merged_result.processing_time
            }
            
        except Exception as e:
            logger.error(f"ÂºÇÊ≠•OCRÂ§ÑÁêÜÂ§±Ë¥•: {e}")
            return {
                'success': False,
                'error': str(e),
                'texts': [],
                'text_regions': [],
                'all_text': '',
                'statistics': {'total_regions': 0, 'avg_confidence': 0, 'processing_time': 0}
            }

# ÂÖ®Â±ÄÂÆû‰æã
paddle_ocr_with_slicing = PaddleOCRWithSlicing() 