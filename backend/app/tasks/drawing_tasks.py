#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾çº¸å¤„ç†ç›¸å…³çš„ Celery ä»»åŠ¡ - æŒ‰æ–°çš„æ•°æ®æµç¨‹é‡æ„
"""

import os
import sys
import logging
import tempfile
import asyncio
import time
import json
from typing import Dict, Any, List
from pathlib import Path

from celery import Task
from sqlalchemy.orm import Session

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.append(project_root)

from app.database import get_celery_db_session
from app.models.drawing import Drawing
from app.models.user import User
from app.core.celery_app import celery_app
from app.services.s3_service import S3Service
from app.services.file_processor import FileProcessor
from app.services.unified_quantity_engine import UnifiedQuantityEngine
from app.services.result_merger_service import ResultMergerService
# from app.services.simplified_ocr_processor import SimplifiedOCRProcessor
from app.services.ocr.paddle_ocr import PaddleOCRService
from app.tasks.real_time_task_manager import RealTimeTaskManager, TaskStatus, TaskStage
from ..services.s3_service import s3_service
from ..services.file_processor import FileProcessor
from ..services.vision_scanner import VisionScannerService
from ..database import SessionLocal
from .task_status_pusher import track_progress
from . import task_manager  # ç›´æ¥ä» tasks åŒ…å¯¼å…¥å”¯ä¸€çš„å®ä¾‹

logger = logging.getLogger(__name__)

async def process_images_with_shared_slices(image_paths: List[str], 
                                          shared_slice_results: Dict[str, Any],
                                          drawing_id: int, 
                                          task_id: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨å…±äº«æ™ºèƒ½åˆ‡ç‰‡ç»“æœå¤„ç†å›¾åƒOCR
    
    Args:
        image_paths: åŸå§‹å›¾åƒè·¯å¾„åˆ—è¡¨
        shared_slice_results: ç»Ÿä¸€æ™ºèƒ½åˆ‡ç‰‡çš„ç»“æœ
        drawing_id: å›¾çº¸ID
        task_id: ä»»åŠ¡ID
        
    Returns:
        OCRå¤„ç†ç»“æœ
    """
    logger.info(f"ğŸ” å¼€å§‹åŸºäºå…±äº«åˆ‡ç‰‡çš„PaddleOCRå¤„ç†: {len(image_paths)} å¼ å›¾ç‰‡")
    
    all_results = []
    total_text_regions = 0
    successful_images = 0
    total_slices_processed = 0
    
    for i, image_path in enumerate(image_paths):
        try:
            logger.info(f"å¤„ç†å›¾åƒ {i+1}/{len(image_paths)}: {Path(image_path).name}")
            
            slice_info = shared_slice_results.get(image_path, {})
            
            if slice_info.get('sliced', False):
                # ä½¿ç”¨åˆ‡ç‰‡ç»“æœè¿›è¡ŒOCR
                slice_infos = slice_info.get('slice_infos', [])
                logger.info(f"  ğŸ”ª ä½¿ç”¨å…±äº«åˆ‡ç‰‡ç»“æœ: {len(slice_infos)} ä¸ªåˆ‡ç‰‡")
                
                # å¯¹æ¯ä¸ªåˆ‡ç‰‡æ‰§è¡ŒOCR
                slice_ocr_results = []
                for j, slice_data in enumerate(slice_infos):
                    try:
                        # å°†base64æ•°æ®è½¬æ¢ä¸ºä¸´æ—¶å›¾ç‰‡æ–‡ä»¶
                        import base64
                        import tempfile
                        
                        slice_image_data = base64.b64decode(slice_data.base64_data)
                        temp_slice_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
                        temp_slice_file.write(slice_image_data)
                        temp_slice_file.close()
                        
                        # ä½¿ç”¨åŸºç¡€OCRæœåŠ¡å¤„ç†å•ä¸ªåˆ‡ç‰‡
                        from app.services.ocr.paddle_ocr import PaddleOCRService
                        basic_ocr = PaddleOCRService()
                        # ä¸ºåˆ‡ç‰‡ç”Ÿæˆå”¯ä¸€æ ‡è¯†ï¼Œä¾¿äºå­˜å‚¨ç®¡ç†
                        slice_identifier = f"{drawing_id}_{task_id}_slice_{j}"
                        slice_result = basic_ocr.recognize_text(temp_slice_file.name, save_to_sealos=True, drawing_id=str(drawing_id))
                        
                        if slice_result.get('success', True):  # PaddleOCRé€šå¸¸æ²¡æœ‰explicit successå­—æ®µ
                            # è°ƒæ•´åæ ‡åˆ°åŸå›¾åæ ‡ç³»
                            adjusted_regions = []
                            for region in slice_result.get('text_regions', []):
                                adjusted_region = region.copy()
                                if 'bbox' in adjusted_region:
                                    bbox = adjusted_region['bbox']
                                    # è°ƒæ•´åæ ‡: åŠ ä¸Šåˆ‡ç‰‡åœ¨åŸå›¾ä¸­çš„åç§»
                                    adjusted_bbox = [
                                        bbox[0] + slice_data.x,
                                        bbox[1] + slice_data.y,
                                        bbox[2] + slice_data.x,
                                        bbox[3] + slice_data.y
                                    ]
                                    adjusted_region['bbox'] = adjusted_bbox
                                adjusted_regions.append(adjusted_region)
                            
                            slice_ocr_results.append({
                                'slice_id': slice_data.slice_id,
                                'text_regions': adjusted_regions,
                                'slice_text': slice_result.get('all_text', ''),
                                'slice_index': j
                            })
                            total_slices_processed += 1
                            logger.info(f"    âœ… åˆ‡ç‰‡ {j+1}/{len(slice_infos)} OCRå®Œæˆ: {len(adjusted_regions)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
                        else:
                            logger.warning(f"    âŒ åˆ‡ç‰‡ {j+1} OCRå¤±è´¥")
                        
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        os.unlink(temp_slice_file.name)
                        
                    except Exception as slice_ocr_error:
                        logger.error(f"    âŒ åˆ‡ç‰‡ {j+1} OCRå¼‚å¸¸: {slice_ocr_error}")
                
                # åˆå¹¶æ‰€æœ‰åˆ‡ç‰‡çš„OCRç»“æœ
                if slice_ocr_results:
                    merged_text_regions = []
                    merged_text = []
                    
                    for slice_result in slice_ocr_results:
                        merged_text_regions.extend(slice_result['text_regions'])
                        if slice_result['slice_text']:
                            merged_text.append(slice_result['slice_text'])
                    
                    # å»é‡å¤„ç†ï¼ˆç®€å•çš„åŸºäºä½ç½®çš„å»é‡ï¼‰
                    deduplicated_regions = remove_duplicate_regions(merged_text_regions)
                    
                    result = {
                        'success': True,
                        'texts': [{'text': region.get('text', ''), 'bbox': region.get('bbox', [])} for region in deduplicated_regions],
                        'text_regions': deduplicated_regions,
                        'all_text': '\n'.join(merged_text),
                        'statistics': {
                            'total_regions': len(deduplicated_regions),
                            'total_slices': len(slice_infos),
                            'processed_slices': len(slice_ocr_results),
                            'avg_confidence': calculate_average_confidence(deduplicated_regions)
                        },
                        'processing_method': 'shared_slice_ocr'
                    }
                    
                    all_results.append(result)
                    total_text_regions += len(deduplicated_regions)
                    successful_images += 1
                    
                    logger.info(f"  âœ… å…±äº«åˆ‡ç‰‡OCRæˆåŠŸ: {len(slice_ocr_results)} ä¸ªåˆ‡ç‰‡å¤„ç†å®Œæˆ, {len(deduplicated_regions)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
                else:
                    logger.warning(f"  âŒ æ‰€æœ‰åˆ‡ç‰‡OCRéƒ½å¤±è´¥")
            else:
                # å·²ç§»é™¤é™çº§å¤„ç†
                logger.info(f"  ğŸ“„ ä½¿ç”¨åŸå›¾OCRå¤„ç†: {slice_info.get('reason', 'unknown')}")
                
                from app.services.ocr.paddle_ocr import PaddleOCRService
                basic_ocr = PaddleOCRService()
                result = basic_ocr.recognize_text(image_path, save_to_sealos=True, drawing_id=str(drawing_id))
                
                if result.get('text_regions'):  # PaddleOCRæˆåŠŸçš„åˆ¤æ–­
                    result['processing_method'] = 'direct_ocr_error'
                    result['success'] = True
                    all_results.append(result)
                    total_text_regions += len(result.get('text_regions', []))
                    successful_images += 1
                    logger.info(f"  âœ… åŸå›¾OCRæˆåŠŸ: {len(result.get('text_regions', []))} ä¸ªæ–‡æœ¬åŒºåŸŸ")
                else:
                    logger.warning(f"  âŒ åŸå›¾OCRå¤±è´¥")
                    
        except Exception as e:
            logger.error(f"  âŒ å¤„ç†å›¾åƒå¼‚å¸¸: {e}")
    
    # æ±‡æ€»ç»“æœ
    if successful_images > 0:
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬åŒºåŸŸ
        all_text_regions = []
        all_text = []
        
        for result in all_results:
            all_text_regions.extend(result.get('text_regions', []))
            if result.get('all_text'):
                all_text.append(result['all_text'])
        
        # æ”¶é›†å­˜å‚¨ä¿¡æ¯
        storage_summaries = []
        for result in all_results:
            if result.get('storage_info', {}).get('saved'):
                storage_summaries.append(result['storage_info'])
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        final_result = {
            'success': True,
            'total_images_processed': len(image_paths),
            'successful_images': successful_images,
            'failed_images': len(image_paths) - successful_images,
            'text_regions': all_text_regions,
            'all_text': '\n'.join(all_text),
            'statistics': {
                'total_regions': total_text_regions,
                'total_slices_processed': total_slices_processed,
                'avg_confidence': calculate_average_confidence(all_text_regions),
                'processing_time': sum(r.get('statistics', {}).get('processing_time', 0) for r in all_results)
            },
            'storage_summary': {
                'total_saved_files': len(storage_summaries),
                'storage_details': storage_summaries
            },
            'processing_summary': {
                'shared_slice_used': True,
                'slicing_enabled': True,
                'individual_results': [
                    {
                        'image': Path(image_paths[i]).name,
                        'success': i < len(all_results),
                        'method': all_results[i].get('processing_method') if i < len(all_results) else 'failed',
                        'regions': all_results[i].get('statistics', {}).get('total_regions', 0) if i < len(all_results) else 0
                    }
                    for i in range(len(image_paths))
                ]
            }
        }
        
        # ä¸ºäº†å…¼å®¹ç°æœ‰ä»£ç ï¼Œç”Ÿæˆä¸€ä¸ªä¸»è¦çš„result_s3_keyï¼ˆå¦‚æœæœ‰å­˜å‚¨ç»“æœçš„è¯ï¼‰
        primary_s3_key = None
        if storage_summaries:
            # é€‰æ‹©ç¬¬ä¸€ä¸ªJSONç»“æœä½œä¸ºä¸»è¦çš„S3 key
            for storage_info in storage_summaries:
                if storage_info.get('json_result', {}).get('s3_key'):
                    primary_s3_key = storage_info['json_result']['s3_key']
                    break
        
        if primary_s3_key:
            final_result['result_s3_key'] = primary_s3_key
            logger.info(f"ğŸ“ OCRç»“æœä¸»è¦å­˜å‚¨ä½ç½®: {primary_s3_key}")
        
        # ğŸ”§ æ–°å¢ï¼šä¿å­˜åˆå¹¶åçš„PaddleOCRç»“æœ
        if successful_images > 0:
            merged_ocr_storage = _save_merged_paddleocr_result(
                final_result, 
                drawing_id, 
                task_id
            )
            if merged_ocr_storage.get('success'):
                final_result['merged_ocr_storage'] = merged_ocr_storage
                logger.info(f"ğŸ’¾ åˆå¹¶OCRç»“æœå·²ä¿å­˜: {merged_ocr_storage.get('s3_key', 'N/A')}")
        
        logger.info(f"âœ… å…±äº«åˆ‡ç‰‡OCRå¤„ç†å®Œæˆ: {successful_images}/{len(image_paths)} æˆåŠŸ, "
                   f"æ€»è®¡ {total_text_regions} ä¸ªæ–‡æœ¬åŒºåŸŸ, {total_slices_processed} ä¸ªåˆ‡ç‰‡å¤„ç†")
        
        return final_result
    else:
        return {
            'success': False,
            'error': 'æ‰€æœ‰å›¾åƒå¤„ç†éƒ½å¤±è´¥',
            'total_images_processed': len(image_paths),
            'successful_images': 0,
            'failed_images': len(image_paths)
        }

def remove_duplicate_regions(text_regions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """ç®€å•çš„æ–‡æœ¬åŒºåŸŸå»é‡"""
    if not text_regions:
        return []
    
    deduplicated = []
    for region in text_regions:
        bbox = region.get('bbox', [])
        text = region.get('text', '')
        
        # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰åŒºåŸŸé‡å¤
        is_duplicate = False
        for existing in deduplicated:
            existing_bbox = existing.get('bbox', [])
            existing_text = existing.get('text', '')
            
            # ç®€å•çš„é‡å¤åˆ¤æ–­ï¼šæ–‡æœ¬ç›¸åŒä¸”ä½ç½®æ¥è¿‘
            if text == existing_text and bbox and existing_bbox:
                if (abs(bbox[0] - existing_bbox[0]) < 10 and 
                    abs(bbox[1] - existing_bbox[1]) < 10):
                    is_duplicate = True
                    break
        
        if not is_duplicate:
            deduplicated.append(region)
    
    return deduplicated

def calculate_average_confidence(text_regions: List[Dict[str, Any]]) -> float:
    """è®¡ç®—å¹³å‡ç½®ä¿¡åº¦"""
    if not text_regions:
        return 0.0
    
    confidences = [region.get('confidence', 0.0) for region in text_regions if 'confidence' in region]
    return sum(confidences) / len(confidences) if confidences else 0.0

def _save_merged_paddleocr_result(final_result: Dict[str, Any], 
                                drawing_id: int, 
                                task_id: str) -> Dict[str, Any]:
    """
    ä¿å­˜åˆå¹¶åçš„PaddleOCRç»“æœåˆ°å­˜å‚¨æœåŠ¡ã€‚
    æ–‡ä»¶åæ˜¯å›ºå®šçš„ï¼Œä½†åŸºäºtask_idæ˜¯å”¯ä¸€çš„ã€‚
    ã€æœ€ç»ˆä¿®å¤ã€‘ç²¾ç¡®åŒ¹é…ä¸‹æ¸¸æœåŠ¡æœŸæœ›çš„JSONç»“æ„ã€‚
    """
    from app.services.dual_storage_service import DualStorageService
    storage_service = DualStorageService()

    try:
        # ä»final_resultä¸­æå–æ‰€æœ‰æ–‡æœ¬åŒºåŸŸ
        all_regions = final_result.get("text_regions", [])
        
        # ã€æœ€ç»ˆä¿®å¤ã€‘æ„å»ºä¸ ocr_result_corrector.py ä¸­
        # _preprocess_ocr_text_simple å‡½æ•°æœŸæœ›å®Œå…¨ä¸€è‡´çš„ç»“æ„
        merged_data = {
            "task_id": task_id,
            "drawing_id": drawing_id,
            "merged_result": {
                "all_text_regions": all_regions,
                "statistics": final_result.get("statistics", {}),
            },
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S%z"),
        }
        
        # ä½¿ç”¨åŸºäº task_id çš„å›ºå®šæ–‡ä»¶å
        s3_key = f"ocr_results/{drawing_id}/merged_ocr_result_{task_id}.json"
        
        # ä¸Šä¼ åˆå¹¶ç»“æœ
        result_upload = storage_service.upload_content_sync(
            content=json.dumps(merged_data, ensure_ascii=False, indent=2),
            s3_key=s3_key,
            content_type="application/json"
        )
        
        if result_upload.get("success"):
            logger.info(f"âœ… åˆå¹¶OCRç»“æœå·²ä¿å­˜åˆ°å­˜å‚¨: {s3_key}")
            return {
                "success": True,
                "s3_key": s3_key,
                "message": "åˆå¹¶OCRç»“æœä¿å­˜æˆåŠŸ"
            }
        
        logger.error(f"âŒ ä¿å­˜åˆå¹¶OCRç»“æœå¤±è´¥: {result_upload.get('error')}")
        return {"success": False, "error": result_upload.get('error')}

    except Exception as e:
        logger.error(f"ä¿å­˜åˆå¹¶OCRç»“æœæ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
        return {"success": False, "error": str(e)}

async def process_images_with_enhanced_ocr(image_paths: List[str], drawing_id: int, task_id: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨å¢å¼ºç‰ˆPaddleOCRæœåŠ¡å¤„ç†å›¾åƒåˆ—è¡¨ï¼ˆæ”¯æŒæ™ºèƒ½åˆ‡ç‰‡ï¼‰
    
    Args:
        image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        drawing_id: å›¾çº¸ID
        task_id: ä»»åŠ¡ID
        
    Returns:
        OCRå¤„ç†ç»“æœ
    """
    logger.info(f"å¼€å§‹å¤„ç† {len(image_paths)} ä¸ªå›¾åƒæ–‡ä»¶ï¼Œæ”¯æŒæ™ºèƒ½åˆ‡ç‰‡")
    
    all_results = []
    total_text_regions = 0
    successful_images = 0
    
    for i, image_path in enumerate(image_paths):
        try:
            logger.info(f"å¤„ç†å›¾åƒ {i+1}/{len(image_paths)}: {Path(image_path).name}")
            
            # ä½¿ç”¨å¢å¼ºç‰ˆPaddleOCRæœåŠ¡ï¼ˆè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦ä½¿ç”¨åˆ‡ç‰‡ï¼‰
            result = await paddle_ocr_service.process_image_async(
                image_path=image_path,
                use_slicing=None  # è‡ªåŠ¨åˆ¤æ–­
            )
            
            if result.get('success'):
                all_results.append(result)
                total_text_regions += result.get('statistics', {}).get('total_regions', 0)
                successful_images += 1
                
                processing_method = result.get('processing_method', 'unknown')
                regions_count = result.get('statistics', {}).get('total_regions', 0)
                logger.info(f"  âœ… å¤„ç†æˆåŠŸ: {processing_method}, {regions_count} ä¸ªæ–‡æœ¬åŒºåŸŸ")
                
                # å¦‚æœä½¿ç”¨äº†åˆ‡ç‰‡ï¼Œè®°å½•åˆ‡ç‰‡ä¿¡æ¯
                if 'slicing_info' in result:
                    slicing_info = result['slicing_info']
                    logger.info(f"  ğŸ”ª åˆ‡ç‰‡ä¿¡æ¯: {slicing_info.get('total_slices', 0)} ä¸ªåˆ‡ç‰‡, "
                              f"æˆåŠŸç‡ {slicing_info.get('success_rate', 0):.1%}")
            else:
                logger.warning(f"  âŒ å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
        except Exception as e:
            logger.error(f"  âŒ å¤„ç†å›¾åƒå¼‚å¸¸: {e}")
    
    # æ±‡æ€»ç»“æœ
    if successful_images > 0:
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬åŒºåŸŸ
        all_text_regions = []
        all_text = []
        
        for result in all_results:
            all_text_regions.extend(result.get('text_regions', []))
            if result.get('all_text'):
                all_text.append(result['all_text'])
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        final_result = {
            'success': True,
            'total_images_processed': len(image_paths),
            'successful_images': successful_images,
            'failed_images': len(image_paths) - successful_images,
            'text_regions': all_text_regions,
            'all_text': '\n'.join(all_text),
            'statistics': {
                'total_regions': total_text_regions,
                'avg_confidence': sum(r.get('statistics', {}).get('avg_confidence', 0) for r in all_results) / len(all_results) if all_results else 0,
                'processing_time': sum(r.get('statistics', {}).get('processing_time', 0) for r in all_results)
            },
            'processing_summary': {
                'enhanced_ocr_used': True,
                'slicing_enabled': True,
                'individual_results': [
                    {
                        'image': Path(image_paths[i]).name,
                        'success': i < len(all_results),
                        'method': all_results[i].get('processing_method') if i < len(all_results) else 'failed',
                        'regions': all_results[i].get('statistics', {}).get('total_regions', 0) if i < len(all_results) else 0
                    }
                    for i in range(len(image_paths))
                ]
            }
        }
        
        logger.info(f"âœ… å¢å¼ºç‰ˆOCRå¤„ç†å®Œæˆ: {successful_images}/{len(image_paths)} æˆåŠŸ, "
                   f"æ€»è®¡ {total_text_regions} ä¸ªæ–‡æœ¬åŒºåŸŸ")
        
        return final_result
    else:
        return {
            'success': False,
            'error': 'æ‰€æœ‰å›¾åƒå¤„ç†éƒ½å¤±è´¥',
            'total_images_processed': len(image_paths),
            'successful_images': 0,
            'failed_images': len(image_paths)
        }

# åˆå§‹åŒ–æœåŠ¡
s3_service = S3Service()
file_processor = FileProcessor()
quantity_engine = UnifiedQuantityEngine()
# simplified_ocr_processor = SimplifiedOCRProcessor()
# ä½¿ç”¨æ”¯æŒæ™ºèƒ½åˆ‡ç‰‡çš„PaddleOCRæœåŠ¡
from app.services.ocr.paddle_ocr_with_slicing import PaddleOCRWithSlicing
paddle_ocr_service = PaddleOCRWithSlicing()

class CallbackTask(Task):
    """å¸¦å›è°ƒçš„ Celery ä»»åŠ¡åŸºç±»"""
    
    def on_success(self, retval, task_id, args, kwargs):
        """ä»»åŠ¡æˆåŠŸå®Œæˆæ—¶çš„å›è°ƒ"""
        logger.info(f"âœ… Celery ä»»åŠ¡æˆåŠŸå®Œæˆ: {task_id}")
        
    def on_failure(self, exc, task_id, args, kwargs, einfo):
        """ä»»åŠ¡å¤±è´¥æ—¶çš„å›è°ƒ"""
        logger.error(f"âŒ Celery ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(exc)}")

@celery_app.task(bind=True, base=CallbackTask, name='process_drawing_upload')
def process_drawing_celery_task(self, db_drawing_id: int, task_id: str):
    """
    ç»Ÿä¸€æ–‡ä»¶å¤„ç†ä»»åŠ¡ - æ”¯æŒDWG/PDF/å›¾ç‰‡ä¸‰ç§æ–‡ä»¶ç±»å‹
    
    Args:
        self: Celeryä»»åŠ¡å®ä¾‹
        db_drawing_id: æ•°æ®åº“ä¸­çš„å›¾çº¸ID
        task_id: å®æ—¶ä»»åŠ¡ID
    """
    
    logger.info(f"ğŸš€ å¼€å§‹Celeryç»Ÿä¸€æ–‡ä»¶å¤„ç†ä»»åŠ¡: å›¾çº¸ID={db_drawing_id}, ä»»åŠ¡ID={task_id}")
    
    # åˆ›å»ºäº‹ä»¶å¾ªç¯
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    local_file_path = None
    temp_files = []
    
    try:
        with get_celery_db_session() as db:
            # é˜¶æ®µ1: ä»»åŠ¡åˆå§‹åŒ–
            loop.run_until_complete(
                task_manager.update_task_status(
                    task_id, TaskStatus.PROCESSING, TaskStage.INITIALIZING,
                    progress=5, message="Celery Worker æ­£åœ¨åˆå§‹åŒ–ä»»åŠ¡..."
                )
            )
            
            # 1ï¸âƒ£ è·å–å›¾çº¸ä¿¡æ¯
            drawing = db.query(Drawing).filter(Drawing.id == db_drawing_id).first()
            if not drawing:
                raise ValueError(f"æ‰¾ä¸åˆ°å›¾çº¸è®°å½•: ID={db_drawing_id}")
            
            logger.info(f"ğŸ“„ å¤„ç†å›¾çº¸: {drawing.filename} (ç±»å‹: {drawing.file_type})")
            
            # é˜¶æ®µ2: æ–‡ä»¶ä¸‹è½½
            loop.run_until_complete(
                task_manager.update_task_status(
                    task_id, TaskStatus.PROCESSING, TaskStage.FILE_PROCESSING,
                    progress=10, message="Celery Worker æ­£åœ¨ä¸‹è½½æ–‡ä»¶..."
                )
            )
            
            # 2ï¸âƒ£ ä»S3ä¸‹è½½æ–‡ä»¶
            logger.info(f"ğŸ“¥ ä»åŒé‡å­˜å‚¨ä¸‹è½½æ–‡ä»¶: {drawing.filename}")
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä½†ç«‹å³å…³é—­å¥æŸ„ï¼Œé¿å…Windowsæ–‡ä»¶é”å®šé—®é¢˜
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=f".{drawing.file_type}")
            local_file_path = temp_file.name
            temp_file.close()  # ç«‹å³å…³é—­æ–‡ä»¶å¥æŸ„ï¼Œé¿å…Windowsé”å®š
            
            # ä½¿ç”¨åŒé‡å­˜å‚¨æœåŠ¡ä¸‹è½½æ–‡ä»¶
            from app.services.dual_storage_service import DualStorageService
            dual_storage_service = DualStorageService()
            
            download_success = dual_storage_service.download_file(
                s3_key=drawing.s3_key,
                local_path=local_file_path
            )
            
            if not download_success:
                # å¦‚æœåŒé‡å­˜å‚¨ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ˆæœ¬åœ°å¤‡ä»½ï¼‰
                logger.warning(f"âš ï¸ åŒé‡å­˜å‚¨ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°å¤‡ä»½: {drawing.file_path}")
                if drawing.file_path and os.path.exists(drawing.file_path):
                    try:
                        import shutil
                        shutil.copy2(drawing.file_path, local_file_path)
                        logger.info(f"âœ… ä½¿ç”¨æœ¬åœ°å¤‡ä»½æ–‡ä»¶æˆåŠŸ: {drawing.file_path}")
                        download_success = True
                    except Exception as backup_error:
                        logger.error(f"âŒ æœ¬åœ°å¤‡ä»½æ–‡ä»¶ä¹Ÿæ— æ³•ä½¿ç”¨: {backup_error}")
                
                if not download_success:
                    raise Exception(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {drawing.s3_key} (åŒ…æ‹¬æœ¬åœ°å¤‡ä»½)")
            
            # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
            if not os.path.exists(local_file_path):
                raise Exception(f"ä¸‹è½½æ–‡ä»¶ä¸å­˜åœ¨: {local_file_path}")
            
            file_size = os.path.getsize(local_file_path)
            if file_size == 0:
                raise Exception(f"ä¸‹è½½çš„æ–‡ä»¶ä¸ºç©º: {drawing.s3_key}")
            
            logger.info(f"ğŸ“ æ–‡ä»¶ä¸‹è½½å®Œæˆ: {local_file_path} (å¤§å°: {file_size} å­—èŠ‚)")
            
            # æ£€æŸ¥å¹¶ä¿®å¤file_typeå­—æ®µ
            from app.utils.file_utils import extract_file_type
            if not drawing.file_type:
                # å¦‚æœfile_typeä¸ºç©ºï¼Œä»æ–‡ä»¶åæ¨æ–­
                file_ext = os.path.splitext(drawing.filename)[1].lower()
                drawing.file_type = extract_file_type(drawing.filename)
                    
                # æ›´æ–°æ•°æ®åº“
                db.commit()
                logger.info(f"ğŸ”§ è‡ªåŠ¨ä¿®å¤file_type: {file_ext} -> {drawing.file_type}")
            
            # å¦‚æœæ˜¯PDFæ–‡ä»¶ï¼Œé¢å¤–éªŒè¯æ–‡ä»¶å¤´
            if drawing.file_type and drawing.file_type.lower() == 'pdf':
                try:
                    with open(local_file_path, 'rb') as f:
                        header = f.read(8)
                        if not header.startswith(b'%PDF'):
                            raise Exception(f"ä¸‹è½½çš„PDFæ–‡ä»¶æ ¼å¼æ— æ•ˆ: æ–‡ä»¶å¤´ {header}")
                    logger.info("âœ… PDFæ–‡ä»¶å¤´éªŒè¯é€šè¿‡")
                except Exception as header_error:
                    raise Exception(f"PDFæ–‡ä»¶éªŒè¯å¤±è´¥: {header_error}")
            
            # é˜¶æ®µ3: æ–‡ä»¶é¢„å¤„ç†
            loop.run_until_complete(
                task_manager.update_task_status(
                    task_id, TaskStatus.PROCESSING, TaskStage.FILE_PROCESSING,
                    progress=20, message="Celery Worker æ­£åœ¨é¢„å¤„ç†æ–‡ä»¶..."
                )
            )
            
            # 3ï¸âƒ£ ç»Ÿä¸€æ–‡ä»¶é¢„å¤„ç†ï¼ˆè½¬æ¢ä¸ºå›¾ç‰‡ï¼‰
            logger.info(f"ğŸ”„ å¼€å§‹ç»Ÿä¸€æ–‡ä»¶é¢„å¤„ç†: {drawing.file_type}")
            file_processing_result = file_processor.process_file(local_file_path, drawing.file_type)
            
            if file_processing_result.get('status') != 'success':
                raise Exception(f"æ–‡ä»¶é¢„å¤„ç†å¤±è´¥: {file_processing_result.get('error')}")
            
            # è®°å½•ä¸´æ—¶æ–‡ä»¶ä»¥ä¾¿æ¸…ç†
            temp_files = file_processing_result.get('image_paths', [])
            source_type = file_processing_result.get('processing_method', 'unknown')
            
            logger.info(f"âœ… æ–‡ä»¶é¢„å¤„ç†å®Œæˆ: {len(temp_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶ (æ¥æº: {source_type})")
            
            # ========= æ–°å¢ï¼šç»Ÿä¸€æ™ºèƒ½åˆ‡ç‰‡é˜¶æ®µ =========
            loop.run_until_complete(
                task_manager.update_task_status(
                    task_id, TaskStatus.PROCESSING, TaskStage.FILE_PROCESSING,
                    progress=25, message="Celery Worker æ­£åœ¨è¿›è¡Œç»Ÿä¸€æ™ºèƒ½åˆ‡ç‰‡..."
                )
            )
            
            # 3ï¸âƒ£ ç»Ÿä¸€æ™ºèƒ½åˆ‡ç‰‡é¢„å¤„ç†
            logger.info("ğŸ”ª å¼€å§‹ç»Ÿä¸€æ™ºèƒ½åˆ‡ç‰‡é¢„å¤„ç†...")
            shared_slice_results = {}
            original_images = {}
            
            try:
                from app.services.intelligent_image_slicer import IntelligentImageSlicer
                unified_slicer = IntelligentImageSlicer()
                
                for image_path in temp_files:
                    try:
                        logger.info(f"ğŸ” åˆ†æå›¾ç‰‡åˆ‡ç‰‡éœ€æ±‚: {Path(image_path).name}")
                        
                        # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸å’Œæ–‡ä»¶å¤§å°
                        file_size = os.path.getsize(image_path)
                        
                        from PIL import Image
                        with Image.open(image_path) as img:
                            width, height = img.size
                            logger.info(f"ğŸ“ å›¾ç‰‡å°ºå¯¸: {width}x{height}, æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
                            
                            # ç»Ÿä¸€åˆ‡ç‰‡åˆ¤æ–­æ¡ä»¶ï¼šå°ºå¯¸>2048x2048 æˆ– æ–‡ä»¶å¤§å°>1.5MB
                            max_dimension = 2048
                            max_file_size = int(1.5 * 1024 * 1024)  # 1.5MB
                            
                            needs_slicing = (width > max_dimension or height > max_dimension or file_size > max_file_size)
                            
                            if needs_slicing:
                                slice_reason = []
                                if width > max_dimension or height > max_dimension:
                                    slice_reason.append(f"å°ºå¯¸{width}x{height}è¶…è¿‡{max_dimension}x{max_dimension}")
                                if file_size > max_file_size:
                                    slice_reason.append(f"æ–‡ä»¶å¤§å°{file_size / 1024 / 1024:.1f}MBè¶…è¿‡1.5MB")
                                
                                logger.info(f"ğŸ”ª æ‰§è¡Œæ™ºèƒ½åˆ‡ç‰‡: {', '.join(slice_reason)}")
                                
                                # æ‰§è¡Œæ™ºèƒ½åˆ‡ç‰‡
                                task_slice_id = f"unified_{task_id}_{Path(image_path).stem}"
                                slice_infos = unified_slicer.slice_image(img, task_slice_id)
                                
                                if slice_infos and len(slice_infos) > 0:
                                    shared_slice_results[image_path] = {
                                        'sliced': True,
                                        'slice_count': len(slice_infos),
                                        'slice_infos': slice_infos,
                                        'original_size': (width, height),
                                        'slice_reason': slice_reason
                                    }
                                    logger.info(f"âœ… æ™ºèƒ½åˆ‡ç‰‡å®Œæˆ: {len(slice_infos)} ä¸ªåˆ‡ç‰‡")
                                else:
                                    logger.warning("âš ï¸ æ™ºèƒ½åˆ‡ç‰‡è¿”å›ç©ºç»“æœï¼Œä½¿ç”¨åŸå›¾")
                                    shared_slice_results[image_path] = {
                                        'sliced': False,
                                        'reason': 'slice_failed',
                                        'error_to_original': True
                                    }
                            else:
                                logger.info(f"âœ… å›¾ç‰‡å°ºå¯¸é€‚ä¸­ï¼Œæ— éœ€åˆ‡ç‰‡")
                                shared_slice_results[image_path] = {
                                    'sliced': False,
                                    'reason': 'size_appropriate',
                                    'original_size': (width, height)
                                }
                            
                            # ä¿å­˜åŸå›¾å¼•ç”¨
                            original_images[image_path] = {
                                'path': image_path,
                                'size': (width, height),
                                'file_size': file_size
                            }
                    
                    except Exception as slice_error:
                        logger.error(f"âŒ å›¾ç‰‡åˆ‡ç‰‡å¤±è´¥ {image_path}: {slice_error}")
                        shared_slice_results[image_path] = {
                            'sliced': False,
                            'reason': 'slice_error',
                            'error': str(slice_error),
                            'error_to_original': True
                        }
                
                # ç»Ÿè®¡åˆ‡ç‰‡ç»“æœ
                total_images = len(temp_files)
                sliced_images = sum(1 for result in shared_slice_results.values() if result.get('sliced', False))
                total_slices = sum(result.get('slice_count', 0) for result in shared_slice_results.values())
                
                logger.info(f"ğŸ¯ ç»Ÿä¸€æ™ºèƒ½åˆ‡ç‰‡å®Œæˆ: {sliced_images}/{total_images} å¼ å›¾ç‰‡è¢«åˆ‡ç‰‡, æ€»è®¡ {total_slices} ä¸ªåˆ‡ç‰‡")
                
            except Exception as unified_slice_error:
                logger.error(f"âŒ ç»Ÿä¸€æ™ºèƒ½åˆ‡ç‰‡å¤±è´¥: {unified_slice_error}")
                # å·²ç§»é™¤é™çº§å¤„ç†
                shared_slice_results = {}
                for image_path in temp_files:
                    shared_slice_results[image_path] = {
                        'sliced': False,
                        'reason': 'unified_slice_failed',
                        'error': str(unified_slice_error),
                        'error_to_original': True
                    }
            
            # ã€ä¿®å¤ã€‘æå–åŸå§‹å›¾ç‰‡ä¿¡æ¯ï¼Œä»¥ä¾›åç»­æ­¥éª¤ä½¿ç”¨
            original_image_info = {}
            if original_images:
                # å‡è®¾æˆ‘ä»¬åªå¤„ç†å•ä¸ªå›¾çº¸è½¬æ¢åçš„ç¬¬ä¸€å¼ å›¾ç‰‡
                first_image_path = next(iter(original_images))
                original_image_info = original_images[first_image_path]
                logger.info(f"æå–åˆ°åŸå§‹å›¾ç‰‡ä¿¡æ¯: {original_image_info.get('size')}")

            ocr_result = {}
            vision_scan_result = {}
            
            # ========= è½¨é“ 1: PaddleOCR åˆ†æï¼ˆä½¿ç”¨å…±äº«åˆ‡ç‰‡ç»“æœï¼‰=========
            loop.run_until_complete(
                task_manager.update_task_status(
                    task_id, TaskStatus.PROCESSING, TaskStage.OCR_PROCESSING,
                    progress=40, message="Celery Worker æ­£åœ¨è¿›è¡ŒPaddleOCRæ‰«æï¼ˆä½¿ç”¨å…±äº«åˆ‡ç‰‡ï¼‰..."
                )
            )
            
            ocr_success = False
            try:
                logger.info("è½¨é“ 1: ğŸ” å¼€å§‹ PaddleOCR åˆ†æï¼ˆä½¿ç”¨å…±äº«æ™ºèƒ½åˆ‡ç‰‡ç»“æœï¼‰...")
                # ä½¿ç”¨å…±äº«åˆ‡ç‰‡ç»“æœçš„å¢å¼ºç‰ˆPaddleOCRæœåŠ¡
                ocr_result = loop.run_until_complete(
                    process_images_with_shared_slices(temp_files, shared_slice_results, drawing.id, task_id)
                )
                
                if ocr_result.get("success"):
                    logger.info("è½¨é“ 1: âœ… PaddleOCR åˆ†ææˆåŠŸã€‚")
                    drawing.ocr_result_s3_key = ocr_result.get("result_s3_key")
                    ocr_success = True
                else:
                    logger.warning(f"è½¨é“ 1: âš ï¸ PaddleOCR åˆ†æå¤±è´¥: {ocr_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    drawing.error_message = f"OCR failed: {ocr_result.get('error')}"
            except Exception as ocr_exc:
                logger.error(f"è½¨é“ 1: âŒ PaddleOCR åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡å¼‚å¸¸: {ocr_exc}", exc_info=True)
                drawing.error_message = f"OCR exception: {ocr_exc}"
                # å¦‚æœOCRå¤±è´¥ï¼Œæä¾›ä¸€ä¸ªç©ºçš„é»˜è®¤ç»“æ„ä»¥é¿å…åç»­æ­¥éª¤å´©æºƒ
                ocr_result = {
                    "success": False, 
                    "error": "OCR track failed completely.",
                    "storage_summary": {}
                }

            # å¦‚æœOCRå¤±è´¥ï¼Œæä¾›ä¸€ä¸ªç©ºçš„é»˜è®¤ç»“æ„ä»¥é¿å…åç»­æ­¥éª¤å´©æºƒ
            if not ocr_result:
                logger.warning("âš ï¸ OCRè½¨é“å¤„ç†ç»“æœä¸ºNoneï¼Œå°†ä½¿ç”¨ç©ºç»“æœç»§ç»­æ‰§è¡Œï¼ŒVisionè½¨é“å°†ç‹¬ç«‹åˆ†æã€‚")
                ocr_result = {
                    "success": False, 
                    "error": "OCR track failed completely.",
                    "storage_summary": {}
                }

            # ã€æœ€ç»ˆä¿®å¤ã€‘ç›´æ¥ä½¿ç”¨OCRè½¨é“çš„ç»“æœï¼Œç»•è¿‡æœ‰é—®é¢˜çš„ä¸­é—´åˆå¹¶æ­¥éª¤
            logger.info(f"âœ… OCRè½¨é“å®Œæˆï¼ŒæˆåŠŸ={ocr_success}ã€‚å°†ç›´æ¥ä½¿ç”¨æ­¤ç»“æœè¿›è¡Œåç»­æ­¥éª¤ã€‚")
            
            # ========= Visionè½¨é“å°†ä¾èµ–è¿™ä¸ª ocr_result =========
            # (è¿™ä¸ªå˜é‡åä¿æŒä¸å˜ï¼Œå› ä¸ºå®ƒå°†è¢«ä¼ é€’ç»™vision_scanner)
            enhanced_ocr_result = dict(ocr_result) 
            
            # ========= ç§»é™¤æœ‰é—®é¢˜çš„OCRç»“æœåˆå¹¶é˜¶æ®µ =========
            logger.info("â© è·³è¿‡å·²çŸ¥çš„ã€æœ‰é—®é¢˜çš„'OCRç»“æœåˆå¹¶é˜¶æ®µ'ã€‚")
            ocr_full_result = None # ç¡®ä¿è¿™ä¸ªå˜é‡ä¸ºç©ºï¼Œä»¥å…å¹²æ‰°åç»­é€»è¾‘

            # ========= æ–°å¢ï¼šOCRç»“æœæ™ºèƒ½çº æ­£é˜¶æ®µ =========
            loop.run_until_complete(
                task_manager.update_task_status(
                    task_id, TaskStatus.PROCESSING, TaskStage.OCR_PROCESSING,
                    progress=55, message="Celery Worker æ­£åœ¨è¿›è¡ŒOCRç»“æœæ™ºèƒ½çº æ­£..."
                )
            )
            
            logger.info("ğŸ§  å¼€å§‹OCRç»“æœæ™ºèƒ½çº æ­£é˜¶æ®µ...")
            ocr_correction_success = False
            corrected_ocr_result = None
            
            try:
                # ğŸ”§ ã€æœ€ç»ˆä¿®å¤ã€‘ç›´æ¥ä» ocr_result ä¸­æŸ¥æ‰¾S3 Key
                merged_ocr_key = None
                
                logger.info(f"ğŸ” åœ¨ ocr_result ä¸­æœç´¢åˆå¹¶OCRç»“æœå­˜å‚¨é”®...")
                if ocr_success and isinstance(ocr_result, dict):
                    # è·¯å¾„: ocr_result.merged_ocr_storage.s3_key
                    if 'merged_ocr_storage' in ocr_result and isinstance(ocr_result['merged_ocr_storage'], dict):
                        merged_ocr_key = ocr_result['merged_ocr_storage'].get('s3_key')
                        if merged_ocr_key:
                            logger.info(f"âœ… ä» ocr_result.merged_ocr_storage ä¸­æ‰¾åˆ°å­˜å‚¨é”®: {merged_ocr_key}")

                if merged_ocr_key:
                    logger.info(f"ğŸ¯ ç¡®è®¤ä½¿ç”¨OCRå­˜å‚¨é”®: {merged_ocr_key}")
                    
                    # åˆå§‹åŒ–OCRçº æ­£æœåŠ¡
                    from app.services.ocr_result_corrector import OCRResultCorrector
                    from app.services.ai_analyzer import AIAnalyzerService
                    from app.services.dual_storage_service import DualStorageService
                    
                    ai_analyzer = AIAnalyzerService()
                    storage_service = DualStorageService()
                    
                    # ç¡®ä¿storage_serviceå·²æ­£ç¡®åˆå§‹åŒ–
                    if not storage_service:
                        raise Exception("å­˜å‚¨æœåŠ¡æœªåˆå§‹åŒ–ï¼Œæ— æ³•è¿›è¡ŒOCRæ™ºèƒ½çº æ­£")
                    
                    ocr_corrector = OCRResultCorrector(ai_analyzer=ai_analyzer, storage_service=storage_service)
                    
                    # æ‰§è¡ŒOCRçº æ­£
                    corrected_ocr_result = loop.run_until_complete(
                        ocr_corrector.correct_ocr_result(
                            merged_ocr_key=merged_ocr_key,
                            drawing_id=drawing.id,
                            task_id=task_id,
                            original_image_info={
                                'width': original_image_info.get('size', (0,0))[0],
                                'height': original_image_info.get('size', (0,0))[1],
                                'filename': drawing.filename
                            }
                        )
                    )
                    
                    if corrected_ocr_result:
                        # ä¿å­˜çº æ­£ç»“æœåˆ°æ•°æ®åº“
                        drawing.ocr_merged_result_key = merged_ocr_key
                        drawing.ocr_corrected_result_key = corrected_ocr_result.corrected_result_key
                        drawing.ocr_correction_summary = {
                            "processing_time": corrected_ocr_result.processing_metadata.get("processing_time"),
                            "correction_method": corrected_ocr_result.processing_metadata.get("correction_method"),
                            "components_extracted": len(corrected_ocr_result.component_list),
                            "notes_extracted": len(corrected_ocr_result.global_notes),
                            "drawing_info_extracted": bool(corrected_ocr_result.drawing_basic_info),
                            "timestamp": corrected_ocr_result.timestamp
                        }
                        
                        ocr_correction_success = True
                        logger.info(f"âœ… OCRç»“æœæ™ºèƒ½çº æ­£å®Œæˆ: æå–äº† {len(corrected_ocr_result.component_list)} ä¸ªæ„ä»¶å’Œ {len(corrected_ocr_result.global_notes)} æ¡è¯´æ˜")
                        
                        # æ›´æ–°OCRç»“æœï¼Œæä¾›çº æ­£åçš„æ•°æ®ç»™Visionåˆ†æä½¿ç”¨
                        ocr_result['corrected_data'] = {
                            "drawing_basic_info": corrected_ocr_result.drawing_basic_info,
                            "component_list": corrected_ocr_result.component_list,
                            "global_notes": corrected_ocr_result.global_notes,
                            "corrected_text_regions": corrected_ocr_result.text_regions_corrected,
                            "correction_summary": corrected_ocr_result.correction_summary
                        }
                    else:
                        logger.warning("âš ï¸ OCRçº æ­£ç»“æœä¸ºç©ºï¼Œç»§ç»­ä½¿ç”¨åŸå§‹OCRç»“æœ")
                else:
                    logger.warning("âš ï¸ æœªåœ¨ ocr_result ä¸­æ‰¾åˆ°åˆå¹¶OCRç»“æœå­˜å‚¨é”®ï¼Œè·³è¿‡OCRçº æ­£")
                    
            except Exception as correction_exc:
                logger.error(f"âŒ OCRç»“æœæ™ºèƒ½çº æ­£å¤±è´¥: {correction_exc}")
                # çº æ­£å¤±è´¥ä¸å½±å“åç»­æµç¨‹ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹OCRç»“æœ
                current_error = getattr(drawing, 'error_message', None)
                drawing.error_message = f"{current_error}; OCR correction failed: {correction_exc}" if current_error else f"OCR correction failed: {correction_exc}"
            
            logger.info(f"ğŸ“‹ OCRæ™ºèƒ½çº æ­£é˜¶æ®µå®Œæˆ: æˆåŠŸ={ocr_correction_success}")

            # ========= è½¨é“ 2: å¤§æ¨¡å‹ Vision æ‰«æï¼ˆä½¿ç”¨å…±äº«æ™ºèƒ½åˆ‡ç‰‡ç»“æœ + çº æ­£åOCRç»“æœï¼‰=========
            loop.run_until_complete(
                task_manager.update_task_status(
                    task_id, TaskStatus.PROCESSING, TaskStage.GPT_ANALYSIS,
                    progress=60, message="Celery Worker æ­£åœ¨è¿›è¡Œå¤§æ¨¡å‹å›¾çº¸æ‰«æï¼ˆä½¿ç”¨å…±äº«æ™ºèƒ½åˆ‡ç‰‡ç»“æœ + çº æ­£åOCRç»“æœï¼‰..."
                )
            )
            
            vision_success = False
            try:
                logger.info("è½¨é“ 2: ğŸ¤– å¼€å§‹ Vision Scan åˆ†æï¼ˆä½¿ç”¨å…±äº«æ™ºèƒ½åˆ‡ç‰‡ç»“æœ + çº æ­£åOCRç»“æœï¼‰...")
                vision_scanner = VisionScannerService()
                
                # ã€æœ€ç»ˆä¿®å¤ã€‘ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„OCRç»“æœå˜é‡
                # enhanced_ocr_result åœ¨ä¸Šé¢å·²ç»ä» ocr_result å¤åˆ¶è€Œæ¥
                if ocr_correction_success and corrected_ocr_result:
                    # å¦‚æœçº æ­£æˆåŠŸï¼Œå°†çº æ­£æ•°æ®æ·»åŠ åˆ° enhanced_ocr_result
                    enhanced_ocr_result['corrected_data'] = {
                        "drawing_basic_info": corrected_ocr_result.drawing_basic_info,
                        "component_list": corrected_ocr_result.component_list,
                        "global_notes": corrected_ocr_result.global_notes,
                        "corrected_text_regions": corrected_ocr_result.text_regions_corrected,
                        "correction_summary": corrected_ocr_result.correction_summary
                    }
                    logger.info(f"ğŸ“‹ å°†çº æ­£åçš„OCRæ•°æ®ä¼ é€’ç»™Visionåˆ†æ: {len(corrected_ocr_result.component_list)} ä¸ªæ„ä»¶")
                
                vision_scan_result = vision_scanner.scan_images_with_shared_slices(
                    temp_files, 
                    shared_slice_results,
                    drawing.id, 
                    task_id=task_id,
                    ocr_result=enhanced_ocr_result  # ä¼ é€’åŒ…å«çº æ­£ä¿¡æ¯çš„OCRç»“æœ
                )

                if vision_scan_result.get("success"):
                    logger.info("è½¨é“ 2: âœ… Vision æ‰«ææˆåŠŸã€‚")
                    drawing.llm_result_s3_key = vision_scan_result.get("result_s3_key")
                    vision_success = True
                else:
                    error_message = vision_scan_result.get('error', 'æœªçŸ¥çš„Visionæ‰«æé”™è¯¯')
                    logger.error(f"è½¨é“ 2: âŒ Vision æ‰«æå¤±è´¥: {error_message}")
                    # å¦‚æœå·²æœ‰OCRé”™è¯¯ä¿¡æ¯ï¼Œè¿½åŠ æ–°çš„é”™è¯¯
                    current_error = getattr(drawing, 'error_message', None)
                    drawing.error_message = f"{current_error}; Vision failed: {error_message}" if current_error else f"Vision failed: {error_message}"
            
            except Exception as vision_exc:
                logger.error(f"è½¨é“ 2: âŒ Vision Scan åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡å¼‚å¸¸: {vision_exc}", exc_info=True)
                current_error = getattr(drawing, 'error_message', None)
                drawing.error_message = f"{current_error}; Vision exception: {vision_exc}" if current_error else f"Vision exception: {vision_exc}"
                # åˆ›å»ºç©ºçš„Visionç»“æœ
                vision_scan_result = {
                    "success": False,
                    "error": str(vision_exc)
                }

            # ========= Visionç»“æœåˆå¹¶é˜¶æ®µï¼ˆç®€åŒ–ç‰ˆï¼‰=========
            logger.info("ğŸ”„ å¼€å§‹Visionç»“æœåˆå¹¶é˜¶æ®µ...")
            
            # åˆå§‹åŒ–ç»“æœåˆå¹¶æœåŠ¡
            merger_service = ResultMergerService(storage_service=s3_service)
            
            # åˆå¹¶Visionåˆ†æç»“æœï¼ˆå¦‚æœVisionæˆåŠŸï¼‰
            if vision_success:
                try:
                    logger.info("ğŸ”„ å¼€å§‹åˆå¹¶Visionåˆ†æç»“æœ...")
                    # å®šä¹‰slice_coordinate_mapï¼Œé¿å…æœªå®šä¹‰é”™è¯¯
                    slice_coordinate_map = {}
                    # ä»vision_scan_resultä¸­æå–åˆ‡ç‰‡ç»“æœ
                    vision_slice_results = []
                    if isinstance(vision_scan_result, dict):
                        # å¦‚æœvision_scan_resultåŒ…å«åˆ†æ‰¹ç»“æœ
                        if 'batch_results' in vision_scan_result:
                            vision_slice_results = vision_scan_result['batch_results']
                        elif 'qto_data' in vision_scan_result:
                            # å¦‚æœæ˜¯å•ä¸ªç»“æœï¼ŒåŒ…è£…æˆåˆ—è¡¨
                            vision_slice_results = [vision_scan_result]
                    
                    if vision_slice_results:
                        vision_merge_result = merger_service.merge_vision_analysis_results(
                            vision_results=vision_slice_results,
                            slice_coordinate_map=slice_coordinate_map,
                            original_image_info=original_image_info,
                            task_id=task_id,
                            drawing_id=drawing.id
                        )
                        
                        if vision_merge_result.get('success'):
                            logger.info(f"âœ… Visionåˆ†æç»“æœåˆå¹¶å®Œæˆï¼Œç”Ÿæˆ vision_full.json")
                            # å°†åˆå¹¶ç»“æœæ·»åŠ åˆ°æœ€ç»ˆç»“æœä¸­
                            vision_scan_result['merged_full_result'] = vision_merge_result.get('vision_full_result')
                            vision_scan_result['vision_full_storage'] = vision_merge_result.get('storage_result')
                        else:
                            logger.warning(f"âš ï¸ Visionåˆ†æç»“æœåˆå¹¶å¤±è´¥")
                    else:
                        logger.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„Visionåˆ‡ç‰‡ç»“æœè¿›è¡Œåˆå¹¶")
                        
                except Exception as vision_merge_exc:
                    logger.error(f"âŒ Visionåˆ†æç»“æœåˆå¹¶å¼‚å¸¸: {vision_merge_exc}")

            logger.info("âœ… ç»“æœåˆå¹¶é˜¶æ®µå®Œæˆ")

            # ========= æ•°æ®æ±‡æ€»ä¸åç»­å¤„ç† =========
            logger.info(f"æ•°æ®æ±‡æ€»é˜¶æ®µ: OCRæˆåŠŸ={ocr_success}, VisionæˆåŠŸ={vision_success}")
            
            # å¦‚æœä¸¤ä¸ªæµç¨‹éƒ½å¤±è´¥ï¼Œåˆ™ä»»åŠ¡å¤±è´¥
            if not ocr_success and not vision_success:
                raise Exception("OCRå’ŒVisionåˆ†ææµç¨‹éƒ½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåç»­å¤„ç†ã€‚")
            
            # å¦‚æœè‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸï¼Œå°è¯•è¿›è¡Œå·¥ç¨‹é‡è®¡ç®—
            analysis_result = {}
            components = []
            
            if vision_success:
                logger.info("âœ… ä½¿ç”¨Vision Scanç»“æœè¿›è¡Œåç»­è®¡ç®—ã€‚")
                
                # ä¼˜å…ˆä½¿ç”¨åˆå¹¶åçš„Visionç»“æœï¼ˆåŒ…å«æ‰€æœ‰æ„ä»¶ï¼‰
                analysis_result = {}
                components = []
                
                # 1. ä¼˜å…ˆæ£€æŸ¥åˆå¹¶åçš„å®Œæ•´ç»“æœ
                if vision_scan_result.get('merged_full_result'):
                    merged_result = vision_scan_result['merged_full_result']
                    components = merged_result.get('merged_components', [])
                    analysis_result = {
                        "components": components,
                        "project_info": merged_result.get('project_info', {}),
                        "component_summary": merged_result.get('component_summary', {}),
                        "source": "vision_merged_full",
                        "total_slices": merged_result.get('total_slices', 0)
                    }
                    logger.info(f"ğŸ¯ ä½¿ç”¨åˆå¹¶Visionç»“æœ: {len(components)} ä¸ªæ„ä»¶ (æ¥æº: merged_full_result)")
                
                # å·²ç§»é™¤é™çº§å¤„ç†
                elif 'batch_results' in vision_scan_result:
                    batch_results = vision_scan_result['batch_results']
                    for batch_result in batch_results:
                        if batch_result.get('qto_data', {}).get('components'):
                            components.extend(batch_result['qto_data']['components'])
                    analysis_result = {
                        "components": components,
                        "source": "vision_batch_results",
                        "total_batches": len(batch_results)
                    }
                    logger.info(f"ğŸ¯ ä½¿ç”¨æ‰¹æ¬¡Visionç»“æœ: {len(components)} ä¸ªæ„ä»¶ (æ¥æº: batch_results)")
                
                # å·²ç§»é™¤é™çº§å¤„ç†
                elif vision_scan_result.get("qto_data"):
                    analysis_result = vision_scan_result.get("qto_data", {})
                    components = analysis_result.get("components", [])
                    logger.info(f"ğŸ¯ ä½¿ç”¨å•ä¸€Visionç»“æœ: {len(components)} ä¸ªæ„ä»¶ (æ¥æº: qto_data)")
                
                # 4. å…œåº•ä½¿ç”¨åŸå§‹ç»“æœ
                else:
                    analysis_result = vision_scan_result if isinstance(vision_scan_result, dict) and "components" in vision_scan_result else {}
                    components = analysis_result.get("components", [])
                    logger.info(f"ğŸ¯ ä½¿ç”¨åŸå§‹Visionç»“æœ: {len(components)} ä¸ªæ„ä»¶ (æ¥æº: error)")
            elif ocr_success:
                logger.info("âš ï¸ Visionå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨OCRç»“æœè¿›è¡ŒåŸºç¡€è®¡ç®—ã€‚")
                # åŸºäºOCRç»“æœåˆ›å»ºåŸºç¡€åˆ†ææ•°æ®
                analysis_result = {
                    "components": [],
                    "source": "OCR_only",
                    "confidence": "low"
                }
                components = []
            
            logger.info(f"ğŸ” åˆ†æå®Œæˆ: è¯†åˆ« {len(components)} ä¸ªæ„ä»¶")
            
            # é˜¶æ®µ5: ç»Ÿä¸€å·¥ç¨‹é‡è®¡ç®—
            loop.run_until_complete(
                task_manager.update_task_status(
                    task_id, TaskStatus.PROCESSING, TaskStage.QUANTITY_CALCULATION,
                    progress=70, message="Celery Worker æ­£åœ¨è®¡ç®—å·¥ç¨‹é‡..."
                )
            )
            
            # 5ï¸âƒ£ ç»Ÿä¸€å·¥ç¨‹é‡è®¡ç®—
            logger.info("ğŸ“Š å¼€å§‹ç»Ÿä¸€å·¥ç¨‹é‡è®¡ç®—...")
            try:
                quantity_result = quantity_engine.calculate_quantities(analysis_result)
                
                if quantity_result.get('status') != 'success':
                    logger.warning(f"å·¥ç¨‹é‡è®¡ç®—å¤±è´¥: {quantity_result.get('error')}")
                    # åˆ›å»ºåŸºç¡€çš„å·¥ç¨‹é‡ç»“æœ
                    quantity_result = {
                        'status': 'partial_success',
                        'error': quantity_result.get('error'),
                        'summary': {'total_components': len(components)},
                        'message': 'ç”±äºåˆ†æç»“æœä¸å®Œæ•´ï¼Œå·¥ç¨‹é‡è®¡ç®—ä»…æä¾›åŸºç¡€ä¿¡æ¯'
                    }
            except Exception as calc_exc:
                logger.error(f"å·¥ç¨‹é‡è®¡ç®—å¼‚å¸¸: {calc_exc}")
                quantity_result = {
                    'status': 'error',
                    'error': str(calc_exc),
                    'summary': {'total_components': len(components)},
                    'message': 'å·¥ç¨‹é‡è®¡ç®—å¤±è´¥ï¼Œä½†åŸºç¡€ä¿¡æ¯å·²ä¿å­˜'
                }
            
            summary = quantity_result.get('summary', {})
            logger.info(f"ğŸ“ˆ å·¥ç¨‹é‡è®¡ç®—å®Œæˆ: {summary.get('total_components', 0)} ä¸ªæ„ä»¶")
            
            # 6ï¸âƒ£ å°†æœ€ç»ˆç»“æœä¿å­˜åˆ°æ•°æ®åº“
            logger.info("ğŸ’¾ å¼€å§‹ä¿å­˜æœ€ç»ˆç»“æœåˆ°æ•°æ®åº“...")
            final_result_payload = {
                "vision_scan_result": vision_scan_result,
                "ocr_result": ocr_result,
                "quantity_result": quantity_result,
                "processing_summary": {
                    "ocr_success": ocr_success,
                    "vision_success": vision_success,
                    "components_count": len(components),
                    "merged_results": {
                        "ocr_full_generated": bool(ocr_success and ocr_result.get('merged_full_result')),
                        "vision_full_generated": bool(vision_success and vision_scan_result.get('merged_full_result')),
                        "ocr_full_url": ocr_result.get('ocr_full_storage', {}).get('s3_url') if ocr_success else None,
                        "vision_full_url": vision_scan_result.get('vision_full_storage', {}).get('s3_url') if vision_success else None
                    }
                }
            }
            drawing.processing_result = final_result_payload
            drawing.status = 'completed'
            db.commit()
            logger.info("âœ… æœ€ç»ˆç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ã€‚")
            
            # é˜¶æ®µ7: ä»»åŠ¡æˆåŠŸå®Œæˆ
            loop.run_until_complete(
                task_manager.update_task_status(
                    task_id,
                    TaskStatus.SUCCESS,
                    TaskStage.COMPLETED,
                    progress=100,
                    message="å›¾çº¸å¤„ç†æˆåŠŸå®Œæˆï¼",
                    results=final_result_payload
                )
            )
            
            logger.info(f"ğŸ‰ Celery Dual-Track Analysiså¤„ç†æµç¨‹æˆåŠŸå®Œæˆ: å›¾çº¸ID={db_drawing_id}")
            
            return {
                'status': 'success',
                'drawing_id': db_drawing_id,
                'source_type': source_type,
                'pipeline_type': 'Dual-Track Analysis',
                'components_count': len(components),
                'processed_images': len(temp_files),
                'ai_model': 'GPT-4o',
                'summary': summary,
                'message': 'Dual-Track Analysiså¤„ç†æµç¨‹æˆåŠŸå®Œæˆ'
            }
            
    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡å¤„ç†å¤±è´¥: {e}", exc_info=True)
        # æ›´æ–°æ•°æ®åº“ä¸­çš„å›¾çº¸çŠ¶æ€ä¸ºå¤±è´¥
        with get_celery_db_session() as db:
            drawing = db.query(Drawing).filter(Drawing.id == db_drawing_id).first()
            if drawing:
                drawing.status = 'failed'
                drawing.error_message = str(e)
                db.commit()

        # æ›´æ–°å®æ—¶ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        loop.run_until_complete(
            task_manager.update_task_status(
                task_id,
                TaskStatus.FAILURE,
                TaskStage.FAILED,
                progress=0,
                message=f"ä»»åŠ¡å¤„ç†å¤±è´¥: {e}",
                error_message=str(e)
            )
        )
    
    finally:
        if 'loop' in locals() and loop:
            loop.close()
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        try:
            # æ¸…ç†æœ¬åœ°ä¸‹è½½çš„æ–‡ä»¶
            if local_file_path and os.path.exists(local_file_path):
                os.unlink(local_file_path)
                logger.info(f"ğŸ—‘ï¸ å·²æ¸…ç†æœ¬åœ°æ–‡ä»¶: {local_file_path}")
            
            # æ¸…ç†æ–‡ä»¶å¤„ç†äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶
            if temp_files:
                file_processor.cleanup_temp_files(temp_files)
                
        except Exception as cleanup_error:
            logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_error}")

@celery_app.task(bind=True, base=CallbackTask, name='batch_process_drawings')
def batch_process_drawings_celery_task(
    self,
    drawing_tasks: list
):
    """
    æ‰¹é‡å¤„ç†å›¾çº¸çš„ Celery ä»»åŠ¡
    
    Args:
        self: Celery ä»»åŠ¡å®ä¾‹
        drawing_tasks: å›¾çº¸ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«å¤„ç†å‚æ•°
    """
    
    logger.info(f"ğŸš€ å¼€å§‹ Celery æ‰¹é‡å›¾çº¸å¤„ç†ä»»åŠ¡: {len(drawing_tasks)} ä¸ªå›¾çº¸")
    
    results = []
    
    for i, task_params in enumerate(drawing_tasks):
        try:
            logger.info(f"ğŸ“‹ å¤„ç†ç¬¬ {i+1}/{len(drawing_tasks)} ä¸ªå›¾çº¸...")
            
            # è°ƒç”¨å•ä¸ªå›¾çº¸å¤„ç†ä»»åŠ¡
            result = process_drawing_celery_task.apply(
                args=(
                    task_params['db_drawing_id'],
                    task_params['task_id']
                )
            )
            
            results.append({
                "drawing_id": task_params['db_drawing_id'],
                "status": "success",
                "result": result.get()
            })
            
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡å¤„ç†ç¬¬ {i+1} ä¸ªå›¾çº¸å¤±è´¥: {str(e)}")
            results.append({
                "drawing_id": task_params.get('db_drawing_id', 'unknown'),
                "status": "error",
                "error": str(e)
            })
    
    logger.info(f"âœ… Celery æ‰¹é‡å›¾çº¸å¤„ç†å®Œæˆ: {len(results)} ä¸ªç»“æœ")
    
    return {
        "status": "completed",
        "total_tasks": len(drawing_tasks),
        "successful_tasks": len([r for r in results if r["status"] == "success"]),
        "failed_tasks": len([r for r in results if r["status"] == "error"]),
        "results": results
    }