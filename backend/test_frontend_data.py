#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json

def test_normalize_ocr_data():
    """æµ‹è¯•å‰ç«¯OCRæ•°æ®æ ‡å‡†åŒ–é€»è¾‘"""
    
    print("ğŸ§ª æµ‹è¯•å‰ç«¯OCRæ•°æ®æ ‡å‡†åŒ–é€»è¾‘")
    print("="*60)
    
    # æ¨¡æ‹Ÿå‰ç«¯normalizeOcrDataå‡½æ•°
    def normalize_ocr_data(data):
        print(f"ğŸ”§ æ ‡å‡†åŒ–OCRæ•°æ®ï¼Œè¾“å…¥ç±»å‹: {type(data)}")
        
        # å¦‚æœæ•°æ®ä¸ºç©ºæˆ–None
        if not data:
            return {
                "text_regions": [
                    {"text": "æ— OCRæ•°æ®", "confidence": 0.0}
                ]
            }
        
        # å¦‚æœå·²ç»æ˜¯æ­£ç¡®çš„text_regionsæ ¼å¼
        if isinstance(data, dict) and "text_regions" in data and isinstance(data["text_regions"], list):
            return data
        
        # å¦‚æœæ˜¯PaddleOCRæ ¼å¼
        if isinstance(data, dict) and "rec_texts" in data and isinstance(data["rec_texts"], list):
            scores = data.get("rec_scores", [])
            return {
                "text_regions": [
                    {
                        "text": text,
                        "confidence": scores[i] if i < len(scores) else 1.0
                    }
                    for i, text in enumerate(data["rec_texts"])
                ]
            }
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²
        if isinstance(data, str):
            return {
                "text_regions": [
                    {"text": data, "confidence": 1.0}
                ]
            }
        
        # å¦‚æœæ˜¯æ•°ç»„
        if isinstance(data, list):
            return {
                "text_regions": [
                    {
                        "text": item.get("text", item.get("rec_text", str(item))) if isinstance(item, dict) else str(item),
                        "confidence": item.get("confidence", item.get("score", 1.0)) if isinstance(item, dict) else 1.0
                    }
                    for item in data
                ]
            }
        
        # å…¶ä»–æƒ…å†µ
        return {
            "text_regions": [
                {"text": json.dumps(data), "confidence": 0.5}
            ]
        }
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "name": "å­—ç¬¦ä¸²æ ¼å¼",
            "input": "KZI 400*600 C20"
        },
        {
            "name": "å·²æœ‰text_regionsæ ¼å¼",
            "input": {
                "text_regions": [
                    {"text": "KZI", "confidence": 0.85},
                    {"text": "400*600", "confidence": 0.88}
                ]
            }
        },
        {
            "name": "PaddleOCRæ ¼å¼", 
            "input": {
                "rec_texts": ["KZI", "400*600", "C20"],
                "rec_scores": [0.85, 0.88, 0.79]
            }
        },
        {
            "name": "æ•°ç»„æ ¼å¼",
            "input": [
                {"text": "KZI", "confidence": 0.85},
                {"text": "400*600", "confidence": 0.88}
            ]
        },
        {
            "name": "ç©ºæ•°æ®",
            "input": None
        },
        {
            "name": "å¤æ‚å¯¹è±¡",
            "input": {"some": "unknown", "format": 123}
        }
    ]
    
    for case in test_cases:
        print(f"\nğŸ“‹ æµ‹è¯•: {case['name']}")
        print(f"è¾“å…¥: {case['input']}")
        
        try:
            result = normalize_ocr_data(case['input'])
            print(f"âœ… è¾“å‡º: {json.dumps(result, ensure_ascii=False, indent=2)}")
            
            # éªŒè¯ç»“æœæ ¼å¼
            if "text_regions" in result and isinstance(result["text_regions"], list):
                print(f"âœ… æ ¼å¼éªŒè¯é€šè¿‡ï¼ŒåŒ…å« {len(result['text_regions'])} ä¸ªæ–‡æœ¬åŒºåŸŸ")
            else:
                print("âŒ æ ¼å¼éªŒè¯å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
    
    print("\nğŸ¯ æ€»ç»“:")
    print("  âœ… å‰ç«¯æ•°æ®æ ‡å‡†åŒ–é€»è¾‘å¯ä»¥å¤„ç†å„ç§OCRæ•°æ®æ ¼å¼")
    print("  âœ… ç»Ÿä¸€è½¬æ¢ä¸º text_regions æ ¼å¼ï¼Œç¬¦åˆåç«¯APIæœŸæœ›")
    print("  âœ… åŒ…å«é”™è¯¯å¤„ç†ï¼Œé¿å…å› æ•°æ®æ ¼å¼é—®é¢˜å¯¼è‡´422é”™è¯¯")

if __name__ == "__main__":
    test_normalize_ocr_data() 