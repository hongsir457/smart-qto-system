#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VisionScannerService æ”¹è¿›å»ºè®®å®Œæ•´å®ç°æ–¹æ¡ˆ
æå‡å‡†ç¡®æ€§å’Œå¯ç»´æŠ¤æ€§çš„å››å¤§æ ¸å¿ƒæ”¹è¿›
"""

import json
import time
import logging
import math
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import numpy as np

logger = logging.getLogger(__name__)

# ============================================================================
# æ”¹è¿›1: ç²¾ç¡®ä½ç½®åŒ¹é… - æ›¿ä»£ round-robin åŒ¹é…
# ============================================================================

class PrecisePositionMatcher:
    """ç²¾ç¡®ä½ç½®åŒ¹é…å™¨"""
    
    def __init__(self):
        self.matching_tolerance = 10  # åƒç´ å®¹å·®
    
    def match_component_to_slice(self, component: Dict[str, Any], 
                               slice_coordinate_map: Dict[str, Any]) -> Optional[str]:
        """
        æ ¹æ®æ„ä»¶çš„bboxåæ ‡ç²¾ç¡®åŒ¹é…å¯¹åº”çš„åˆ‡ç‰‡
        
        Args:
            component: æ„ä»¶ä¿¡æ¯ï¼Œå¿…é¡»åŒ…å«bboxæˆ–position
            slice_coordinate_map: åˆ‡ç‰‡åæ ‡æ˜ å°„
            
        Returns:
            åŒ¹é…çš„åˆ‡ç‰‡IDï¼Œå¦‚æœæ— æ³•åŒ¹é…åˆ™è¿”å›None
        """
        # è·å–æ„ä»¶ä¸­å¿ƒç‚¹
        center_point = self._extract_component_center(component)
        if not center_point:
            logger.warning(f"âš ï¸ æ„ä»¶ç¼ºå°‘æœ‰æ•ˆä½ç½®ä¿¡æ¯: {component.get('component_id', 'unknown')}")
            return None
        
        # æŸ¥æ‰¾åŒ…å«è¯¥ä¸­å¿ƒç‚¹çš„åˆ‡ç‰‡
        for slice_id, slice_info in slice_coordinate_map.items():
            if self._point_in_slice(center_point, slice_info):
                logger.debug(f"ğŸ¯ æ„ä»¶ {component.get('component_id')} åŒ¹é…åˆ°åˆ‡ç‰‡ {slice_id}")
                return slice_id
        
        logger.warning(f"âš ï¸ æ„ä»¶ä¸­å¿ƒç‚¹ {center_point} æœªæ‰¾åˆ°åŒ¹é…çš„åˆ‡ç‰‡")
        return None
    
    def _extract_component_center(self, component: Dict[str, Any]) -> Optional[Tuple[float, float]]:
        """æå–æ„ä»¶ä¸­å¿ƒç‚¹"""
        # æ–¹æ³•1: ä»bboxè®¡ç®—ä¸­å¿ƒç‚¹
        bbox = component.get('bbox')
        if bbox and len(bbox) >= 4:
            center_x = (bbox[0] + bbox[2]) / 2
            center_y = (bbox[1] + bbox[3]) / 2
            return (center_x, center_y)
        
        # æ–¹æ³•2: ä»positionç›´æ¥è·å–
        position = component.get('position')
        if position:
            if isinstance(position, dict):
                x = position.get('x')
                y = position.get('y')
                if x is not None and y is not None:
                    return (float(x), float(y))
            elif isinstance(position, (list, tuple)) and len(position) >= 2:
                return (float(position[0]), float(position[1]))
        
        # æ–¹æ³•3: ä»polygonè®¡ç®—ä¸­å¿ƒç‚¹
        polygon = component.get('polygon')
        if polygon and len(polygon) >= 3:
            x_coords = [p[0] for p in polygon if len(p) >= 2]
            y_coords = [p[1] for p in polygon if len(p) >= 2]
            if x_coords and y_coords:
                center_x = sum(x_coords) / len(x_coords)
                center_y = sum(y_coords) / len(y_coords)
                return (center_x, center_y)
        
        return None
    
    def _point_in_slice(self, point: Tuple[float, float], 
                       slice_info: Dict[str, Any]) -> bool:
        """æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨åˆ‡ç‰‡èŒƒå›´å†…"""
        x, y = point
        
        # è·å–åˆ‡ç‰‡è¾¹ç•Œ
        offset_x = slice_info.get('offset_x', 0)
        offset_y = slice_info.get('offset_y', 0)
        width = slice_info.get('slice_width', slice_info.get('width', 0))
        height = slice_info.get('slice_height', slice_info.get('height', 0))
        
        # æ£€æŸ¥æ˜¯å¦åœ¨èŒƒå›´å†…ï¼ˆåŒ…å«å®¹å·®ï¼‰
        in_x_range = (offset_x - self.matching_tolerance <= x <= 
                      offset_x + width + self.matching_tolerance)
        in_y_range = (offset_y - self.matching_tolerance <= y <= 
                      offset_y + height + self.matching_tolerance)
        
        return in_x_range and in_y_range

# ============================================================================
# æ”¹è¿›2: ç©ºé—´é‡å  + ç±»å‹ç›¸ä¼¼åˆ¤å®š
# ============================================================================

class SpatialTypeMerger:
    """ç©ºé—´é‡å å’Œç±»å‹ç›¸ä¼¼æ€§åˆå¹¶å™¨"""
    
    def __init__(self, iou_threshold: float = 0.5, similarity_threshold: float = 0.8):
        self.iou_threshold = iou_threshold
        self.similarity_threshold = similarity_threshold
        
        # æ„ä»¶ç±»å‹ç›¸ä¼¼æ€§æ˜ å°„
        self.type_similarity_groups = {
            'æŸ±ç±»': ['æŸ±', 'æ¡†æ¶æŸ±', 'å‰ªåŠ›å¢™æŸ±', 'KZ', 'å¼‚å½¢æŸ±'],
            'æ¢ç±»': ['æ¢', 'ä¸»æ¢', 'æ¬¡æ¢', 'GL', 'LL', 'è¿æ¢'],
            'æ¿ç±»': ['æ¿', 'æ¥¼æ¿', 'å±‹é¢æ¿', 'LB', 'ç°æµ‡æ¿'],
            'å¢™ç±»': ['å¢™', 'å‰ªåŠ›å¢™', 'å¡«å……å¢™', 'QT', 'æŒ¡åœŸå¢™'],
            'åŸºç¡€ç±»': ['åŸºç¡€', 'ç‹¬ç«‹åŸºç¡€', 'æ¡å½¢åŸºç¡€', 'DJZ', 'TJZ']
        }
    
    def merge_components_by_spatial_and_type(self, components: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åŸºäºç©ºé—´é‡å å’Œç±»å‹ç›¸ä¼¼æ€§åˆå¹¶æ„ä»¶
        
        Args:
            components: æ„ä»¶åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„æ„ä»¶åˆ—è¡¨
        """
        if not components:
            return []
        
        logger.info(f"ğŸ”„ å¼€å§‹ç©ºé—´+ç±»å‹åˆå¹¶: {len(components)} ä¸ªæ„ä»¶")
        
        merged_components = []
        used_indices = set()
        
        for i, component in enumerate(components):
            if i in used_indices:
                continue
            
            # æŸ¥æ‰¾éœ€è¦åˆå¹¶çš„æ„ä»¶
            merge_group = [i]
            
            for j, other_component in enumerate(components[i+1:], i+1):
                if j in used_indices:
                    continue
                
                # æ£€æŸ¥åˆå¹¶æ¡ä»¶
                should_merge = self._should_merge_components(component, other_component)
                
                if should_merge:
                    merge_group.append(j)
            
            # æ‰§è¡Œåˆå¹¶
            if len(merge_group) > 1:
                merged_component = self._merge_component_group([components[idx] for idx in merge_group])
                merged_components.append(merged_component)
                used_indices.update(merge_group)
                logger.debug(f"ğŸ“¦ åˆå¹¶æ„ä»¶ç»„: {len(merge_group)} ä¸ªæ„ä»¶ -> 1 ä¸ª")
            else:
                merged_components.append(component)
                used_indices.add(i)
        
        logger.info(f"âœ… ç©ºé—´+ç±»å‹åˆå¹¶å®Œæˆ: {len(components)} -> {len(merged_components)} ä¸ªæ„ä»¶")
        return merged_components
    
    def _should_merge_components(self, comp1: Dict[str, Any], comp2: Dict[str, Any]) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªæ„ä»¶æ˜¯å¦åº”è¯¥åˆå¹¶"""
        # æ¡ä»¶1: ç©ºé—´é‡å æ£€æŸ¥
        spatial_overlap = self._calculate_spatial_overlap(comp1, comp2)
        
        # æ¡ä»¶2: ç±»å‹ç›¸ä¼¼æ€§æ£€æŸ¥
        type_similarity = self._calculate_type_similarity(comp1, comp2)
        
        # æ¡ä»¶3: æ–‡æœ¬æ ‡ç­¾ç›¸ä¼¼æ€§æ£€æŸ¥ï¼ˆå¦‚æœæœ‰ï¼‰
        text_similarity = self._calculate_text_similarity(comp1, comp2)
        
        # åˆå¹¶é€»è¾‘ï¼šæ»¡è¶³ä»»ä¸€å¼ºæ¡ä»¶æˆ–å¤šä¸ªå¼±æ¡ä»¶ç»„åˆ
        strong_spatial = spatial_overlap > self.iou_threshold
        strong_type = type_similarity > self.similarity_threshold
        moderate_text = text_similarity > 0.6
        
        # å¼ºæ¡ä»¶ï¼šé«˜ç©ºé—´é‡å 
        if strong_spatial:
            logger.debug(f"ğŸ¯ å¼ºç©ºé—´é‡å åˆå¹¶: IOU={spatial_overlap:.3f}")
            return True
        
        # å¼ºæ¡ä»¶ï¼šé«˜ç±»å‹ç›¸ä¼¼æ€§ + ä¸­ç­‰ç©ºé—´é‡å 
        if strong_type and spatial_overlap > 0.2:
            logger.debug(f"ğŸ¯ ç±»å‹+ç©ºé—´åˆå¹¶: ç±»å‹={type_similarity:.3f}, IOU={spatial_overlap:.3f}")
            return True
        
        # å¼±æ¡ä»¶ç»„åˆï¼šä¸­ç­‰ç±»å‹ç›¸ä¼¼æ€§ + æ–‡æœ¬ç›¸ä¼¼æ€§ + è½»å¾®ç©ºé—´é‡å 
        if type_similarity > 0.6 and moderate_text and spatial_overlap > 0.1:
            logger.debug(f"ğŸ¯ ç»¼åˆç›¸ä¼¼æ€§åˆå¹¶: ç±»å‹={type_similarity:.3f}, æ–‡æœ¬={text_similarity:.3f}, IOU={spatial_overlap:.3f}")
            return True
        
        return False
    
    def _calculate_spatial_overlap(self, comp1: Dict, comp2: Dict) -> float:
        """è®¡ç®—ç©ºé—´é‡å åº¦ï¼ˆIOUï¼‰"""
        bbox1 = comp1.get('bbox')
        bbox2 = comp2.get('bbox')
        
        if not bbox1 or not bbox2 or len(bbox1) < 4 or len(bbox2) < 4:
            return 0.0
        
        return self._calculate_iou(bbox1, bbox2)
    
    def _calculate_iou(self, bbox1: List[float], bbox2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IOU"""
        # è®¡ç®—äº¤é›†
        x1 = max(bbox1[0], bbox2[0])
        y1 = max(bbox1[1], bbox2[1])
        x2 = min(bbox1[2], bbox2[2])
        y2 = min(bbox1[3], bbox2[3])
        
        if x2 <= x1 or y2 <= y1:
            return 0.0
        
        intersection = (x2 - x1) * (y2 - y1)
        
        # è®¡ç®—å¹¶é›†
        area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
        area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _calculate_type_similarity(self, comp1: Dict, comp2: Dict) -> float:
        """è®¡ç®—ç±»å‹ç›¸ä¼¼æ€§"""
        type1 = comp1.get('component_type', '').strip().lower()
        type2 = comp2.get('component_type', '').strip().lower()
        
        if not type1 or not type2:
            return 0.0
        
        # å®Œå…¨åŒ¹é…
        if type1 == type2:
            return 1.0
        
        # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€ç±»å‹ç»„
        for group_name, types in self.type_similarity_groups.items():
            types_lower = [t.lower() for t in types]
            if type1 in types_lower and type2 in types_lower:
                return 0.8
        
        # å­ä¸²åŒ¹é…
        if type1 in type2 or type2 in type1:
            return 0.6
        
        return 0.0
    
    def _calculate_text_similarity(self, comp1: Dict, comp2: Dict) -> float:
        """è®¡ç®—æ–‡æœ¬æ ‡ç­¾ç›¸ä¼¼æ€§"""
        tags1 = set(comp1.get('text_tags', []))
        tags2 = set(comp2.get('text_tags', []))
        
        if not tags1 and not tags2:
            return 0.0
        
        if not tags1 or not tags2:
            return 0.0
        
        # Jaccardç›¸ä¼¼æ€§
        intersection = len(tags1.intersection(tags2))
        union = len(tags1.union(tags2))
        
        return intersection / union if union > 0 else 0.0
    
    def _merge_component_group(self, components: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆå¹¶ä¸€ç»„æ„ä»¶"""
        if not components:
            return {}
        
        if len(components) == 1:
            return components[0]
        
        # åŸºç¡€ä¿¡æ¯å–ç¬¬ä¸€ä¸ª
        merged = components[0].copy()
        
        # åˆå¹¶æ•°é‡
        total_quantity = sum(comp.get('quantity', 0) for comp in components)
        merged['quantity'] = total_quantity
        
        # åˆå¹¶è¾¹ç•Œæ¡†ï¼ˆå¤–åŒ…çŸ©å½¢ï¼‰
        all_bboxes = [comp.get('bbox') for comp in components if comp.get('bbox')]
        if all_bboxes:
            merged_bbox = [
                min(bbox[0] for bbox in all_bboxes),
                min(bbox[1] for bbox in all_bboxes),
                max(bbox[2] for bbox in all_bboxes),
                max(bbox[3] for bbox in all_bboxes)
            ]
            merged['bbox'] = merged_bbox
        
        # åˆå¹¶æ–‡æœ¬æ ‡ç­¾
        all_tags = []
        for comp in components:
            tags = comp.get('text_tags', [])
            all_tags.extend(tags)
        
        # å»é‡ä¿æŒé¡ºåº
        unique_tags = []
        seen = set()
        for tag in all_tags:
            if tag not in seen:
                unique_tags.append(tag)
                seen.add(tag)
        merged['text_tags'] = unique_tags
        
        # æ·»åŠ åˆå¹¶å…ƒæ•°æ®
        merged['merge_metadata'] = {
            'merged_count': len(components),
            'merge_method': 'spatial_type_similarity',
            'original_ids': [comp.get('component_id', '') for comp in components],
            'confidence_scores': [comp.get('confidence', 0) for comp in components]
        }
        
        return merged

# ============================================================================
# æ”¹è¿›3: åˆ‡ç‰‡å†…æ–‡æœ¬ä¸æ„ä»¶è”åŠ¨
# ============================================================================

class TextComponentLinker:
    """æ–‡æœ¬ä¸æ„ä»¶è”åŠ¨å™¨"""
    
    def __init__(self, association_distance: float = 100):
        self.association_distance = association_distance  # åƒç´ 
        
        # æ–‡æœ¬åˆ†ç±»æ¨¡å¼
        self.text_patterns = {
            'component_id': [
                r'^[A-Z]{1,2}\d{1,4}$',  # KZ1, GL201
                r'^[A-Z]{1,2}-\d{1,3}$'  # KZ-1
            ],
            'dimension': [
                r'^\d{2,4}[Ã—xX]\d{2,4}$',           # 300Ã—600
                r'^\d{2,4}[Ã—xX]\d{2,4}[Ã—xX]\d{2,4}$', # 300Ã—600Ã—800
                r'^[bBhH]?\d{2,4}$'                  # b300, h600
            ],
            'material': [
                r'^C\d{2}$',      # C30
                r'^HRB\d{3}$',    # HRB400
                r'^Q\d{3}$'       # Q235
            ],
            'reinforcement': [
                r'^\d+[Ï†Î¦]\d+',                    # 4Ï†12
                r'^[Ï†Î¦]\d+@\d+',                   # Ï†8@200
                r'^\d+[Ï†Î¦]\d+@\d+',                # 2Ï†12@150
            ]
        }
    
    def link_texts_to_components(self, components: List[Dict[str, Any]], 
                               text_regions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°†OCRæ–‡æœ¬å…³è”åˆ°æ„ä»¶
        
        Args:
            components: æ„ä»¶åˆ—è¡¨
            text_regions: æ–‡æœ¬åŒºåŸŸåˆ—è¡¨
            
        Returns:
            å…³è”äº†æ–‡æœ¬çš„æ„ä»¶åˆ—è¡¨
        """
        logger.info(f"ğŸ”— å¼€å§‹æ–‡æœ¬æ„ä»¶è”åŠ¨: {len(components)} æ„ä»¶ Ã— {len(text_regions)} æ–‡æœ¬")
        
        linked_components = []
        
        for component in components:
            linked_component = component.copy()
            
            # æŸ¥æ‰¾é‚»è¿‘æ–‡æœ¬
            nearby_texts = self._find_nearby_texts(component, text_regions)
            
            if nearby_texts:
                # åˆ†ç±»æ–‡æœ¬
                categorized_texts = self._categorize_texts(nearby_texts)
                
                # æ·»åŠ åˆ°æ„ä»¶
                linked_component['text_tags'] = [t['text'] for t in nearby_texts]
                linked_component['categorized_texts'] = categorized_texts
                linked_component['text_association_count'] = len(nearby_texts)
                
                # å°è¯•ä»æ–‡æœ¬ä¸­å¢å¼ºæ„ä»¶ä¿¡æ¯
                enhanced_info = self._enhance_component_from_texts(categorized_texts)
                if enhanced_info:
                    linked_component['enhanced_from_text'] = enhanced_info
                
                logger.debug(f"ğŸ”— æ„ä»¶ {component.get('component_id')} å…³è”äº† {len(nearby_texts)} ä¸ªæ–‡æœ¬")
            else:
                linked_component['text_tags'] = []
                linked_component['categorized_texts'] = {}
                linked_component['text_association_count'] = 0
            
            linked_components.append(linked_component)
        
        associated_count = sum(1 for comp in linked_components if comp.get('text_tags'))
        logger.info(f"âœ… æ–‡æœ¬æ„ä»¶è”åŠ¨å®Œæˆ: {associated_count}/{len(components)} ä¸ªæ„ä»¶å…³è”äº†æ–‡æœ¬")
        
        return linked_components
    
    def _find_nearby_texts(self, component: Dict[str, Any], 
                          text_regions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾æ„ä»¶é™„è¿‘çš„æ–‡æœ¬"""
        component_bbox = component.get('bbox')
        if not component_bbox or len(component_bbox) < 4:
            return []
        
        component_center = (
            (component_bbox[0] + component_bbox[2]) / 2,
            (component_bbox[1] + component_bbox[3]) / 2
        )
        
        nearby_texts = []
        
        for text_region in text_regions:
            text_bbox = text_region.get('bbox', text_region.get('global_bbox'))
            if not text_bbox or len(text_bbox) < 4:
                continue
            
            text_center = (
                (text_bbox[0] + text_bbox[2]) / 2,
                (text_bbox[1] + text_bbox[3]) / 2
            )
            
            # è®¡ç®—è·ç¦»
            distance = math.sqrt(
                (component_center[0] - text_center[0])**2 + 
                (component_center[1] - text_center[1])**2
            )
            
            if distance <= self.association_distance:
                text_info = text_region.copy()
                text_info['distance_to_component'] = distance
                nearby_texts.append(text_info)
        
        # æŒ‰è·ç¦»æ’åº
        nearby_texts.sort(key=lambda x: x['distance_to_component'])
        
        return nearby_texts
    
    def _categorize_texts(self, text_regions: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»"""
        categorized = {category: [] for category in self.text_patterns.keys()}
        
        for text_region in text_regions:
            text = text_region.get('text', '').strip()
            if not text:
                continue
            
            # æ£€æŸ¥æ–‡æœ¬å±äºå“ªä¸ªç±»åˆ«
            for category, patterns in self.text_patterns.items():
                for pattern in patterns:
                    import re
                    if re.match(pattern, text):
                        categorized[category].append(text)
                        break
        
        # ç§»é™¤ç©ºç±»åˆ«
        return {k: v for k, v in categorized.items() if v}
    
    def _enhance_component_from_texts(self, categorized_texts: Dict[str, List[str]]) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­å¢å¼ºæ„ä»¶ä¿¡æ¯"""
        enhanced = {}
        
        # ä»å°ºå¯¸æ–‡æœ¬ä¸­æå–å°ºå¯¸ä¿¡æ¯
        dimensions = categorized_texts.get('dimension', [])
        if dimensions:
            enhanced['extracted_dimensions'] = dimensions
            
            # å°è¯•è§£æå…·ä½“å°ºå¯¸å€¼
            for dim_text in dimensions:
                parsed_dims = self._parse_dimension_text(dim_text)
                if parsed_dims:
                    enhanced['parsed_dimensions'] = parsed_dims
                    break
        
        # ä»ææ–™æ–‡æœ¬ä¸­æå–ææ–™ä¿¡æ¯
        materials = categorized_texts.get('material', [])
        if materials:
            enhanced['extracted_materials'] = materials
        
        # ä»é…ç­‹æ–‡æœ¬ä¸­æå–é…ç­‹ä¿¡æ¯
        reinforcements = categorized_texts.get('reinforcement', [])
        if reinforcements:
            enhanced['extracted_reinforcements'] = reinforcements
        
        return enhanced if enhanced else None
    
    def _parse_dimension_text(self, dim_text: str) -> Optional[Dict[str, float]]:
        """è§£æå°ºå¯¸æ–‡æœ¬"""
        import re
        
        # è§£æ 300Ã—600 æ ¼å¼
        match = re.match(r'^(\d{2,4})[Ã—xX](\d{2,4})$', dim_text)
        if match:
            return {
                'width': float(match.group(1)),
                'height': float(match.group(2))
            }
        
        # è§£æ 300Ã—600Ã—800 æ ¼å¼
        match = re.match(r'^(\d{2,4})[Ã—xX](\d{2,4})[Ã—xX](\d{2,4})$', dim_text)
        if match:
            return {
                'width': float(match.group(1)),
                'height': float(match.group(2)),
                'depth': float(match.group(3))
            }
        
        # è§£æ b300, h600 æ ¼å¼
        match = re.match(r'^[bB](\d{2,4})$', dim_text)
        if match:
            return {'width': float(match.group(1))}
        
        match = re.match(r'^[hH](\d{2,4})$', dim_text)
        if match:
            return {'height': float(match.group(1))}
        
        return None

# ============================================================================
# æ”¹è¿›4: ç‹¬ç«‹çš„OCRç»“æœåˆå¹¶å™¨
# ============================================================================

class IndependentOCRMerger:
    """ç‹¬ç«‹çš„OCRç»“æœåˆå¹¶å™¨"""
    
    def __init__(self, iou_threshold: float = 0.7, distance_threshold: float = 50):
        self.iou_threshold = iou_threshold
        self.distance_threshold = distance_threshold
    
    def merge_all_ocr_results(self, slice_ocr_results: List[Dict[str, Any]], 
                            overlap_strategy: str = "IOU") -> List[Dict[str, Any]]:
        """
        åˆå¹¶æ‰€æœ‰åˆ‡ç‰‡çš„OCRç»“æœ
        
        Args:
            slice_ocr_results: åˆ‡ç‰‡OCRç»“æœåˆ—è¡¨
            overlap_strategy: é‡å å¤„ç†ç­–ç•¥ ("IOU", "distance", "hybrid")
            
        Returns:
            åˆå¹¶åçš„æ–‡æœ¬åŒºåŸŸåˆ—è¡¨
        """
        logger.info(f"ğŸ“ å¼€å§‹OCRç»“æœåˆå¹¶: {len(slice_ocr_results)} ä¸ªåˆ‡ç‰‡ï¼Œç­–ç•¥={overlap_strategy}")
        
        # æ­¥éª¤1: æ”¶é›†æ‰€æœ‰æ–‡æœ¬åŒºåŸŸå¹¶è½¬æ¢ä¸ºå…¨å›¾åæ ‡
        all_text_regions = []
        
        for slice_result in slice_ocr_results:
            if not slice_result.get('success', False):
                continue
            
            slice_id = slice_result.get('slice_id', '')
            offset_x = slice_result.get('offset_x', 0)
            offset_y = slice_result.get('offset_y', 0)
            text_regions = slice_result.get('text_regions', [])
            
            for region in text_regions:
                # è½¬æ¢ä¸ºå…¨å›¾åæ ‡
                local_bbox = region.get('bbox', [0, 0, 0, 0])
                global_bbox = [
                    local_bbox[0] + offset_x,
                    local_bbox[1] + offset_y,
                    local_bbox[2] + offset_x,
                    local_bbox[3] + offset_y
                ]
                
                text_item = {
                    'text': region.get('text', ''),
                    'bbox': local_bbox,
                    'global_bbox': global_bbox,
                    'confidence': region.get('confidence', 0.0),
                    'slice_id': slice_id,
                    'original_slice_position': (offset_x, offset_y)
                }
                all_text_regions.append(text_item)
        
        logger.info(f"ğŸ“Š æ”¶é›†åˆ° {len(all_text_regions)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
        
        # æ­¥éª¤2: æ ¹æ®ç­–ç•¥åˆå¹¶é‡å åŒºåŸŸ
        if overlap_strategy == "IOU":
            merged_regions = self._merge_by_iou(all_text_regions)
        elif overlap_strategy == "distance":
            merged_regions = self._merge_by_distance(all_text_regions)
        elif overlap_strategy == "hybrid":
            # å…ˆIOUåè·ç¦»
            iou_merged = self._merge_by_iou(all_text_regions)
            merged_regions = self._merge_by_distance(iou_merged)
        else:
            merged_regions = all_text_regions
        
        logger.info(f"âœ… OCRåˆå¹¶å®Œæˆ: {len(all_text_regions)} -> {len(merged_regions)} ä¸ªåŒºåŸŸ")
        
        return merged_regions
    
    def _merge_by_iou(self, text_regions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åŸºäºIOUåˆå¹¶é‡å æ–‡æœ¬"""
        merged = []
        used_indices = set()
        
        for i, region in enumerate(text_regions):
            if i in used_indices:
                continue
            
            # æŸ¥æ‰¾é‡å åŒºåŸŸ
            overlapping_indices = [i]
            
            for j, other_region in enumerate(text_regions[i+1:], i+1):
                if j in used_indices:
                    continue
                
                iou = self._calculate_bbox_iou(
                    region['global_bbox'], 
                    other_region['global_bbox']
                )
                
                if iou > self.iou_threshold:
                    overlapping_indices.append(j)
            
            # åˆå¹¶é‡å åŒºåŸŸ
            if len(overlapping_indices) > 1:
                merged_region = self._merge_text_regions([text_regions[idx] for idx in overlapping_indices])
                merged.append(merged_region)
                used_indices.update(overlapping_indices)
            else:
                merged.append(region)
                used_indices.add(i)
        
        return merged
    
    def _merge_by_distance(self, text_regions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """åŸºäºè·ç¦»åˆå¹¶é‚»è¿‘æ–‡æœ¬"""
        merged = []
        used_indices = set()
        
        for i, region in enumerate(text_regions):
            if i in used_indices:
                continue
            
            # æŸ¥æ‰¾é‚»è¿‘åŒºåŸŸ
            nearby_indices = [i]
            region_center = self._get_bbox_center(region['global_bbox'])
            
            for j, other_region in enumerate(text_regions[i+1:], i+1):
                if j in used_indices:
                    continue
                
                other_center = self._get_bbox_center(other_region['global_bbox'])
                distance = math.sqrt(
                    (region_center[0] - other_center[0])**2 + 
                    (region_center[1] - other_center[1])**2
                )
                
                if distance < self.distance_threshold:
                    nearby_indices.append(j)
            
            # åˆå¹¶é‚»è¿‘åŒºåŸŸ
            if len(nearby_indices) > 1:
                merged_region = self._merge_text_regions([text_regions[idx] for idx in nearby_indices])
                merged.append(merged_region)
                used_indices.update(nearby_indices)
            else:
                merged.append(region)
                used_indices.add(i)
        
        return merged
    
    def _calculate_bbox_iou(self, bbox1: List[float], bbox2: List[float]) -> float:
        """è®¡ç®—è¾¹ç•Œæ¡†IOU"""
        if len(bbox1) != 4 or len(bbox2) != 4:
            return 0.0
        
        # è®¡ç®—äº¤é›†
        x1 = max(bbox1[0], bbox2[0])
        y1 = max(bbox1[1], bbox2[1])
        x2 = min(bbox1[2], bbox2[2])
        y2 = min(bbox1[3], bbox2[3])
        
        if x2 <= x1 or y2 <= y1:
            return 0.0
        
        intersection = (x2 - x1) * (y2 - y1)
        
        # è®¡ç®—å¹¶é›†
        area1 = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])
        area2 = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _get_bbox_center(self, bbox: List[float]) -> Tuple[float, float]:
        """è·å–è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹"""
        return ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)
    
    def _merge_text_regions(self, regions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆå¹¶å¤šä¸ªæ–‡æœ¬åŒºåŸŸ"""
        if not regions:
            return {}
        
        if len(regions) == 1:
            return regions[0]
        
        # åˆå¹¶æ–‡æœ¬
        merged_text = " ".join([r['text'] for r in regions if r['text'].strip()])
        
        # è®¡ç®—åˆå¹¶è¾¹ç•Œæ¡†
        all_global_bboxes = [r['global_bbox'] for r in regions]
        merged_global_bbox = [
            min(bbox[0] for bbox in all_global_bboxes),
            min(bbox[1] for bbox in all_global_bboxes),
            max(bbox[2] for bbox in all_global_bboxes),
            max(bbox[3] for bbox in all_global_bboxes)
        ]
        
        # ä½¿ç”¨æœ€é«˜ç½®ä¿¡åº¦
        merged_confidence = max(r['confidence'] for r in regions)
        
        # åˆå¹¶åˆ‡ç‰‡ä¿¡æ¯
        slice_ids = list(set(r['slice_id'] for r in regions if r['slice_id']))
        
        return {
            'text': merged_text,
            'bbox': regions[0]['bbox'],  # ä¿ç•™ç¬¬ä¸€ä¸ªçš„æœ¬åœ°åæ ‡
            'global_bbox': merged_global_bbox,
            'confidence': merged_confidence,
            'slice_id': ','.join(slice_ids),
            'merged_from': len(regions),
            'merge_method': 'ocr_overlap_merge'
        }

# ============================================================================
# é›†æˆæµ‹è¯•å’ŒéªŒè¯
# ============================================================================

def test_enhanced_vision_components():
    """æµ‹è¯•å¢å¼ºVisionç»„ä»¶"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºVisionç»„ä»¶...")
    print("=" * 80)
    
    # æµ‹è¯•æ•°æ®
    test_components = [
        {
            'component_id': 'KZ1',
            'component_type': 'æ¡†æ¶æŸ±',
            'bbox': [100, 100, 200, 300],
            'quantity': 2,
            'confidence': 0.9
        },
        {
            'component_id': 'KZ2',
            'component_type': 'æŸ±',  # ç›¸ä¼¼ç±»å‹
            'bbox': [150, 150, 250, 350],  # æœ‰é‡å 
            'quantity': 1,
            'confidence': 0.85
        }
    ]
    
    test_slice_map = {
        'slice_0_0': {'offset_x': 0, 'offset_y': 0, 'slice_width': 500, 'slice_height': 500},
        'slice_0_1': {'offset_x': 400, 'offset_y': 0, 'slice_width': 500, 'slice_height': 500}
    }
    
    test_text_regions = [
        {'text': 'KZ1', 'bbox': [110, 80, 150, 100], 'confidence': 0.9},
        {'text': '300Ã—600', 'bbox': [160, 80, 220, 100], 'confidence': 0.8},
        {'text': 'C30', 'bbox': [170, 320, 200, 340], 'confidence': 0.85}
    ]
    
    test_ocr_results = [
        {
            'slice_id': 'slice_0_0',
            'success': True,
            'offset_x': 0,
            'offset_y': 0,
            'text_regions': test_text_regions[:2]
        },
        {
            'slice_id': 'slice_0_1',
            'success': True,
            'offset_x': 400,
            'offset_y': 0,
            'text_regions': test_text_regions[2:]
        }
    ]
    
    # æµ‹è¯•1: ç²¾ç¡®ä½ç½®åŒ¹é…
    print("1ï¸âƒ£ æµ‹è¯•ç²¾ç¡®ä½ç½®åŒ¹é…...")
    matcher = PrecisePositionMatcher()
    for component in test_components:
        slice_id = matcher.match_component_to_slice(component, test_slice_map)
        print(f"   æ„ä»¶ {component['component_id']} -> åˆ‡ç‰‡ {slice_id}")
    
    # æµ‹è¯•2: ç©ºé—´ç±»å‹åˆå¹¶
    print("\n2ï¸âƒ£ æµ‹è¯•ç©ºé—´ç±»å‹åˆå¹¶...")
    merger = SpatialTypeMerger(iou_threshold=0.3)
    merged_components = merger.merge_components_by_spatial_and_type(test_components)
    print(f"   åˆå¹¶å‰: {len(test_components)} ä¸ªæ„ä»¶")
    print(f"   åˆå¹¶å: {len(merged_components)} ä¸ªæ„ä»¶")
    for comp in merged_components:
        if 'merge_metadata' in comp:
            print(f"   åˆå¹¶æ„ä»¶: {comp['component_id']}, åŸå§‹æ•°é‡: {comp['merge_metadata']['merged_count']}")
    
    # æµ‹è¯•3: æ–‡æœ¬æ„ä»¶è”åŠ¨
    print("\n3ï¸âƒ£ æµ‹è¯•æ–‡æœ¬æ„ä»¶è”åŠ¨...")
    linker = TextComponentLinker(association_distance=150)
    linked_components = linker.link_texts_to_components(test_components, test_text_regions)
    for comp in linked_components:
        if comp.get('text_tags'):
            print(f"   æ„ä»¶ {comp['component_id']} å…³è”æ–‡æœ¬: {comp['text_tags']}")
    
    # æµ‹è¯•4: OCRç»“æœåˆå¹¶
    print("\n4ï¸âƒ£ æµ‹è¯•OCRç»“æœåˆå¹¶...")
    ocr_merger = IndependentOCRMerger()
    merged_ocr = ocr_merger.merge_all_ocr_results(test_ocr_results, overlap_strategy="hybrid")
    print(f"   OCRåˆå¹¶: {sum(len(r.get('text_regions', [])) for r in test_ocr_results)} -> {len(merged_ocr)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
    for text in merged_ocr:
        print(f"   æ–‡æœ¬: '{text['text']}' åæ ‡: {text['global_bbox']}")
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

def generate_enhancement_summary():
    """ç”Ÿæˆæ”¹è¿›æ–¹æ¡ˆæ€»ç»“"""
    summary = {
        'enhancement_title': 'VisionScannerService å››å¤§æ ¸å¿ƒæ”¹è¿›',
        'improvements': [
            {
                'name': 'ç²¾ç¡®ä½ç½®åŒ¹é…',
                'problem': 'æ„ä»¶ä½ç½®åŸºäºåˆ‡ç‰‡ç´¢å¼•round-robinåŒ¹é…ä¸å‡†ç¡®',
                'solution': 'åŸºäºbboxä¸­å¿ƒç‚¹ä¸slice_coordinate_mapç²¾ç¡®åŒ¹é…',
                'benefits': ['æé«˜æ„ä»¶æ¥æºå‡†ç¡®æ€§', 'ç²¾ç¡®åæ ‡è¿˜åŸ', 'å‡å°‘åŒ¹é…é”™è¯¯'],
                'implementation': 'PrecisePositionMatcherç±»'
            },
            {
                'name': 'ç©ºé—´é‡å +ç±»å‹ç›¸ä¼¼åˆ¤å®š',
                'problem': 'æ„ä»¶åˆå¹¶ä»…åŸºäºcomponent_idï¼Œå®¹æ˜“é—æ¼ç›¸ä¼¼æ„ä»¶',
                'solution': 'IOUé‡å æ£€æµ‹ + ç±»å‹ç›¸ä¼¼æ€§ + æ–‡æœ¬æ ‡ç­¾å¤šç»´èåˆ',
                'benefits': ['å‡å°‘é‡å¤æ„ä»¶', 'æé«˜åˆå¹¶å‡†ç¡®æ€§', 'æ”¯æŒå¼‚å½¢æ„ä»¶å¤„ç†'],
                'implementation': 'SpatialTypeMergerç±»'
            },
            {
                'name': 'æ–‡æœ¬æ„ä»¶è”åŠ¨',
                'problem': 'OCRå’ŒVisionå¹¶è¡Œä½†ç¼ºä¹æ·±åº¦æ•´åˆ',
                'solution': 'OCRæ–‡æœ¬æŒ‰è·ç¦»å…³è”åˆ°æ„ä»¶ï¼Œå¢å¼ºæ„ä»¶æè¿°ä¿¡æ¯',
                'benefits': ['ä¸°å¯Œæ„ä»¶ä¿¡æ¯', 'è‡ªåŠ¨æå–è§„æ ¼å‚æ•°', 'æé«˜è¯†åˆ«å®Œæ•´æ€§'],
                'implementation': 'TextComponentLinkerç±»'
            },
            {
                'name': 'ç‹¬ç«‹OCRåˆå¹¶å™¨',
                'problem': 'OCRåˆå¹¶é€»è¾‘åˆ†æ•£ï¼Œç¼ºä¹ç‹¬ç«‹æ€§å’Œå¯æµ‹è¯•æ€§',
                'solution': 'å°è£…ç‹¬ç«‹çš„OCRåˆå¹¶å™¨ï¼Œæ”¯æŒå¤šç§åˆå¹¶ç­–ç•¥',
                'benefits': ['æ¨¡å—åŒ–è®¾è®¡', 'å¯ç‹¬ç«‹æµ‹è¯•', 'ç­–ç•¥å¯é…ç½®'],
                'implementation': 'IndependentOCRMergerç±»'
            }
        ],
        'additional_enhancements': [
            {
                'name': 'Visionæ¨¡å‹åé¦ˆæ ‡æ³¨çƒ­åŒº',
                'description': 'ç»“åˆattention mapå¯è§†åŒ–Visionæ£€æµ‹ç½®ä¿¡åŒºåŸŸ',
                'implementation': 'é›†æˆæ¨¡å‹attentionæœºåˆ¶ï¼Œç”Ÿæˆçƒ­åŠ›å›¾'
            },
            {
                'name': 'æ„ä»¶åˆ†å±‚å›¾ï¼ˆæ¥¼å±‚/å›¾åï¼‰',
                'description': 'ç»“åˆå›¾æ¡†è¯†åˆ«æ¨¡å—ï¼Œè‡ªåŠ¨åˆ’åˆ†æ„ä»¶å½’å±æ¥¼å±‚',
                'implementation': 'å›¾æ¡†è¯†åˆ« + æ„ä»¶ç©ºé—´åˆ†æ'
            },
            {
                'name': 'å¤šè½®GPTåˆ†æç»“æ„è¯´æ˜',
                'description': 'å¯¹è¯´æ˜æ€§æ–‡å­—å•ç‹¬è°ƒç”¨GPTåˆ†ææ¨¡å‹æ„é€ è§„åˆ™æ¨¡æ¿',
                'implementation': 'ä¸“é—¨çš„æ–‡æœ¬åˆ†æGPTè°ƒç”¨é“¾'
            },
            {
                'name': 'å•å…ƒæµ‹è¯•/é›†æˆæµ‹è¯•æ¨¡å—',
                'description': 'é’ˆå¯¹æ¯ä¸ª_merge_xxxã€_restore_xxxæ¨¡å—å¢åŠ è¦†ç›–ç‡',
                'implementation': 'å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼ŒåŒ…å«è¾¹ç•Œæƒ…å†µæµ‹è¯•'
            }
        ],
        'performance_expectations': {
            'accuracy_improvement': 'æ„ä»¶è¯†åˆ«å‡†ç¡®ç‡æå‡15-25%',
            'merge_efficiency': 'é‡å¤æ„ä»¶å‡å°‘60%ä»¥ä¸Š',
            'text_integration': 'æ„ä»¶ä¿¡æ¯å®Œæ•´åº¦æå‡40%',
            'maintainability': 'ä»£ç æ¨¡å—åŒ–ï¼Œæµ‹è¯•è¦†ç›–ç‡è¾¾åˆ°80%+'
        },
        'implementation_priority': [
            '1. ç²¾ç¡®ä½ç½®åŒ¹é…ï¼ˆç«‹å³å®æ–½ï¼‰',
            '2. OCRç‹¬ç«‹åˆå¹¶å™¨ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰',
            '3. ç©ºé—´ç±»å‹åˆå¹¶ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰',
            '4. æ–‡æœ¬æ„ä»¶è”åŠ¨ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰',
            '5. é¢å¤–å¢å¼ºåŠŸèƒ½ï¼ˆä½ä¼˜å…ˆçº§ï¼‰'
        ]
    }
    
    return summary

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_enhanced_vision_components()
    
    # è¾“å‡ºæ”¹è¿›æ–¹æ¡ˆæ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“‹ VisionScannerService æ”¹è¿›æ–¹æ¡ˆæ€»ç»“")
    print("=" * 80)
    
    summary = generate_enhancement_summary()
    
    print(f"\nğŸ¯ {summary['enhancement_title']}")
    print("-" * 50)
    
    for i, improvement in enumerate(summary['improvements'], 1):
        print(f"\n{i}. {improvement['name']}")
        print(f"   é—®é¢˜: {improvement['problem']}")
        print(f"   è§£å†³æ–¹æ¡ˆ: {improvement['solution']}")
        print(f"   å®ç°: {improvement['implementation']}")
        print(f"   æ”¶ç›Š: {', '.join(improvement['benefits'])}")
    
    print(f"\nğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡:")
    for key, value in summary['performance_expectations'].items():
        print(f"   â€¢ {key}: {value}")
    
    print(f"\nğŸƒ å®æ–½ä¼˜å…ˆçº§:")
    for priority in summary['implementation_priority']:
        print(f"   {priority}")
    
    print("\nâœ… æ”¹è¿›æ–¹æ¡ˆå®Œæˆï¼å»ºè®®ç«‹å³å¼€å§‹å®æ–½å‰4é¡¹æ ¸å¿ƒæ”¹è¿›ã€‚") 