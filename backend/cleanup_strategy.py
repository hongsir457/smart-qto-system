#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç æ¸…ç†ç­–ç•¥æ‰§è¡Œè„šæœ¬
æŒ‰ç…§ç”¨æˆ·è¦æ±‚è¿›è¡Œï¼š
1. é™æ€åˆ†æå’Œæ¸…ç† (vulture + é‡å¤ä»£ç æ£€æµ‹)
2. ç²¾ç®€ç»“æ„å’Œé‡æ„ (åˆå¹¶ç¢ç‰‡ï¼Œç§»é™¤æ— æ•ˆæ¨¡å—)
3. ä¾èµ–æ¸…ç†å’Œæ¨¡å—ç˜¦èº« (ä¼˜åŒ–å¤§æ–‡ä»¶)
"""

import os
import shutil
from pathlib import Path
from typing import List, Dict, Tuple

class CodeCleanupStrategy:
    """ä»£ç æ¸…ç†ç­–ç•¥æ‰§è¡Œå™¨"""
    
    def __init__(self, backend_path: str = "app"):
        self.backend_path = backend_path
        self.cleanup_log = []
        
    def log_action(self, action: str, details: str = ""):
        """è®°å½•æ¸…ç†åŠ¨ä½œ"""
        log_entry = f"âœ… {action}"
        if details:
            log_entry += f": {details}"
        self.cleanup_log.append(log_entry)
        print(log_entry)
    
    def execute_phase_1_static_cleanup(self):
        """é˜¶æ®µ1: é™æ€åˆ†æå’Œæ¸…ç†"""
        print("ğŸ” === é˜¶æ®µ1: é™æ€åˆ†æå’Œæ¸…ç† ===")
        
        # 1.1 åˆ é™¤æ˜æ˜¾çš„æ— ç”¨æ–‡ä»¶
        files_to_delete = [
            # å¤‡ä»½æ–‡ä»¶
            "app/utils/analysis_optimizations_backup.py",
            # æµ‹è¯•æ–‡ä»¶
            "app/services/test_enhanced_vision_components.py", 
            # Legacyæ–‡ä»¶
            "app/services/dwg_processor_legacy.py",
            # ç©ºæ–‡ä»¶
            "app/services/dwg_processing/detectors/frame_detector.py",
        ]
        
        for file_path in files_to_delete:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    self.log_action("åˆ é™¤æ— ç”¨æ–‡ä»¶", file_path)
                except Exception as e:
                    print(f"âŒ åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # 1.2 æ¸…ç†vultureå‘ç°çš„æœªä½¿ç”¨å¯¼å…¥
        self._cleanup_unused_imports()
        
        # 1.3 ç§»é™¤ä¸å¯è¾¾ä»£ç 
        self._remove_unreachable_code()
    
    def execute_phase_2_structure_refinement(self):
        """é˜¶æ®µ2: ç²¾ç®€ç»“æ„å’Œé‡æ„"""
        print("\nğŸ—ï¸ === é˜¶æ®µ2: ç²¾ç®€ç»“æ„å’Œé‡æ„ ===")
        
        # 2.1 åˆå¹¶ç¢ç‰‡åŒ–çš„å°æ–‡ä»¶
        self._merge_fragmented_files()
        
        # 2.2 ç§»é™¤ç©ºå£³æ¨¡å—
        self._remove_empty_modules()
        
        # 2.3 æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œç¤ºä¾‹æ–‡ä»¶
        self._cleanup_temp_and_sample_files()
    
    def execute_phase_3_dependency_optimization(self):
        """é˜¶æ®µ3: ä¾èµ–æ¸…ç†å’Œæ¨¡å—ç˜¦èº«"""
        print("\nğŸ“¦ === é˜¶æ®µ3: ä¾èµ–æ¸…ç†å’Œæ¨¡å—ç˜¦èº« ===")
        
        # 3.1 é‡æ„å¤§æ–‡ä»¶
        self._refactor_large_files()
        
        # 3.2 ä¼˜åŒ–ä¾èµ–å…³ç³»
        self._optimize_dependencies()
        
        # 3.3 ç”Ÿæˆæ¸…ç†åçš„ä¾èµ–æ–‡ä»¶
        self._generate_clean_requirements()
    
    def _cleanup_unused_imports(self):
        """æ¸…ç†æœªä½¿ç”¨çš„å¯¼å…¥"""
        unused_imports = [
            ("app/api/v1/drawings/upload.py", ["DrawingCreate", "file_naming_strategy"]),
            ("app/api/v1/endpoints/export.py", ["BarChart", "Reference"]),
            ("app/api/v1/users.py", ["UserInDB"]),
            ("app/database.py", ["contextmanager", "random"]),
            ("app/services/adaptive_slicing_engine.py", ["ImageDraw"]),
            ("app/services/ai_analyzer.py", ["DummyInteractionLogger"]),
        ]
        
        for file_path, imports in unused_imports:
            if os.path.exists(file_path):
                self._remove_imports_from_file(file_path, imports)
    
    def _remove_imports_from_file(self, file_path: str, imports_to_remove: List[str]):
        """ä»æ–‡ä»¶ä¸­ç§»é™¤æŒ‡å®šçš„å¯¼å…¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            modified = False
            new_lines = []
            
            for line in lines:
                should_remove = False
                for import_name in imports_to_remove:
                    if f"import {import_name}" in line or f"from .* import.*{import_name}" in line:
                        should_remove = True
                        modified = True
                        break
                
                if not should_remove:
                    new_lines.append(line)
            
            if modified:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.writelines(new_lines)
                self.log_action("æ¸…ç†æœªä½¿ç”¨å¯¼å…¥", f"{file_path} - {', '.join(imports_to_remove)}")
                
        except Exception as e:
            print(f"âŒ æ¸…ç†å¯¼å…¥å¤±è´¥ {file_path}: {e}")
    
    def _remove_unreachable_code(self):
        """ç§»é™¤ä¸å¯è¾¾ä»£ç """
        # åŸºäºvultureçš„æŠ¥å‘Šï¼Œai_analyzer.pyæœ‰å¤§é‡ä¸å¯è¾¾ä»£ç 
        ai_analyzer_path = "app/services/ai_analyzer.py"
        if os.path.exists(ai_analyzer_path):
            self.log_action("æ ‡è®°éœ€è¦æ‰‹åŠ¨æ¸…ç†ä¸å¯è¾¾ä»£ç ", ai_analyzer_path)
    
    def _merge_fragmented_files(self):
        """åˆå¹¶ç¢ç‰‡åŒ–çš„å°æ–‡ä»¶"""
        # å°†ä¸€äº›åŠŸèƒ½ç›¸è¿‘çš„å°æ–‡ä»¶åˆå¹¶
        small_service_files = [
            "app/services/coordinate_restore.py",
            "app/services/fusion_merge.py", 
            "app/services/quantity_display.py",
        ]
        
        # åˆ›å»ºåˆå¹¶æ–‡ä»¶
        merged_content = []
        merged_content.append("#!/usr/bin/env python3")
        merged_content.append("# -*- coding: utf-8 -*-")
        merged_content.append('"""')
        merged_content.append("åˆå¹¶çš„å°å‹æœåŠ¡æ¨¡å—")
        merged_content.append("åŒ…å«: åæ ‡è¿˜åŸã€èåˆåˆå¹¶ã€æ•°é‡æ˜¾ç¤ºç­‰åŠŸèƒ½")
        merged_content.append('"""')
        merged_content.append("")
        
        files_merged = []
        for file_path in small_service_files:
            if os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # ç§»é™¤æ–‡ä»¶å¤´éƒ¨çš„é‡å¤ä¿¡æ¯
                    lines = content.split('\n')
                    start_idx = 0
                    for i, line in enumerate(lines):
                        if line.strip() and not line.startswith('#') and not line.startswith('"""') and 'coding' not in line:
                            start_idx = i
                            break
                    
                    merged_content.append(f"# === æ¥è‡ª {file_path} ===")
                    merged_content.extend(lines[start_idx:])
                    merged_content.append("")
                    
                    files_merged.append(file_path)
                    
                except Exception as e:
                    print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        if files_merged:
            # å†™å…¥åˆå¹¶æ–‡ä»¶
            merged_file_path = "app/services/merged_small_services.py"
            try:
                with open(merged_file_path, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(merged_content))
                
                self.log_action("åˆå¹¶å°æ–‡ä»¶", f"åˆ›å»º {merged_file_path}")
                
                # åˆ é™¤åŸæ–‡ä»¶
                for file_path in files_merged:
                    os.remove(file_path)
                    self.log_action("åˆ é™¤å·²åˆå¹¶æ–‡ä»¶", file_path)
                    
            except Exception as e:
                print(f"âŒ åˆ›å»ºåˆå¹¶æ–‡ä»¶å¤±è´¥: {e}")
    
    def _remove_empty_modules(self):
        """ç§»é™¤ç©ºå£³æ¨¡å—"""
        # æŸ¥æ‰¾åªæœ‰__init__.pyä¸”å†…å®¹å¾ˆå°‘çš„ç›®å½•
        empty_dirs = []
        
        for root, dirs, files in os.walk(self.backend_path):
            if len(files) == 1 and "__init__.py" in files:
                init_path = os.path.join(root, "__init__.py")
                try:
                    with open(init_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                    
                    # å¦‚æœ__init__.pyä¸ºç©ºæˆ–åªæœ‰å¾ˆå°‘å†…å®¹
                    if len(content) < 50:  # å°‘äº50ä¸ªå­—ç¬¦
                        empty_dirs.append(root)
                except:
                    pass
        
        for dir_path in empty_dirs:
            try:
                shutil.rmtree(dir_path)
                self.log_action("åˆ é™¤ç©ºå£³æ¨¡å—", dir_path)
            except Exception as e:
                print(f"âŒ åˆ é™¤ç›®å½•å¤±è´¥ {dir_path}: {e}")
    
    def _cleanup_temp_and_sample_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œç¤ºä¾‹æ–‡ä»¶"""
        patterns_to_remove = [
            "**/temp_*",
            "**/sample_*", 
            "**/test_*",
            "**/demo_*",
            "**/example_*",
            "**/*_backup*",
            "**/*_old*",
            "**/*_legacy*",
        ]
        
        for pattern in patterns_to_remove:
            for file_path in Path(self.backend_path).rglob(pattern):
                if file_path.is_file() and file_path.suffix == '.py':
                    try:
                        file_path.unlink()
                        self.log_action("åˆ é™¤ä¸´æ—¶/ç¤ºä¾‹æ–‡ä»¶", str(file_path))
                    except Exception as e:
                        print(f"âŒ åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def _refactor_large_files(self):
        """é‡æ„å¤§æ–‡ä»¶"""
        large_files = [
            ("app/services/ai_analyzer.py", 2178),
            ("app/services/enhanced_grid_slice_analyzer.py", 2179),
        ]
        
        for file_path, line_count in large_files:
            if os.path.exists(file_path):
                self.log_action("æ ‡è®°éœ€è¦é‡æ„çš„å¤§æ–‡ä»¶", f"{file_path} ({line_count}è¡Œ)")
                # è¿™é‡Œéœ€è¦æ‰‹åŠ¨é‡æ„ï¼Œè‡ªåŠ¨é‡æ„é£é™©å¤ªå¤§
                self._create_refactoring_plan(file_path)
    
    def _create_refactoring_plan(self, file_path: str):
        """ä¸ºå¤§æ–‡ä»¶åˆ›å»ºé‡æ„è®¡åˆ’"""
        plan_file = f"{file_path}_refactoring_plan.md"
        
        if "ai_analyzer.py" in file_path:
            plan_content = """
# AI Analyzer é‡æ„è®¡åˆ’

## å»ºè®®æ‹†åˆ†æ–¹æ¡ˆ

### 1. AIAnalyzerService (æ ¸å¿ƒç±»)
- ä¿ç•™åŸºç¡€åŠŸèƒ½å’Œåˆå§‹åŒ–
- generate_qto_from_data()
- is_available()

### 2. PromptBuilder (æ–°æ–‡ä»¶: ai_prompt_builder.py)
- _build_system_prompt()
- _build_enhanced_system_prompt() 
- _build_user_prompt()

### 3. MockDataDetector (æ–°æ–‡ä»¶: ai_mock_detector.py)
- _check_for_mock_data_patterns()
- _enhance_mock_data_detection()
- _validate_response_authenticity()

### 4. VisionAnalyzer (æ–°æ–‡ä»¶: ai_vision_analyzer.py)
- generate_qto_from_local_images()
- generate_qto_from_encoded_images()
- _execute_multi_turn_analysis()
- æ‰€æœ‰visionç›¸å…³çš„stepæ–¹æ³•

### 5. ContextualAnalyzer (æ–°æ–‡ä»¶: ai_contextual_analyzer.py)
- _execute_multi_turn_analysis_with_context()
- æ‰€æœ‰contextual stepæ–¹æ³•

### 6. ResponseSynthesizer (æ–°æ–‡ä»¶: ai_response_synthesizer.py)
- _synthesize_qto_data()
- _determine_component_type()
- _generate_quantity_summary()
"""
        elif "enhanced_grid_slice_analyzer.py" in file_path:
            plan_content = """
# Enhanced Grid Slice Analyzer é‡æ„è®¡åˆ’

## å»ºè®®æ‹†åˆ†æ–¹æ¡ˆ

### 1. EnhancedGridSliceAnalyzer (æ ¸å¿ƒç±»)
- analyze_drawing_with_dual_track()
- ä¿ç•™ä¸»è¦æµç¨‹æ§åˆ¶é€»è¾‘

### 2. OCRProcessor (æ–°æ–‡ä»¶: grid_ocr_processor.py)
- _extract_ocr_from_slices_optimized()
- _extract_global_ocr_overview_optimized()
- æ‰€æœ‰OCRç›¸å…³æ–¹æ³•

### 3. CoordinateManager (æ–°æ–‡ä»¶: grid_coordinate_manager.py)
- _restore_global_coordinates_optimized()
- åæ ‡è½¬æ¢å’Œè¿˜åŸç›¸å…³æ–¹æ³•

### 4. SliceManager (æ–°æ–‡ä»¶: grid_slice_manager.py)
- _reuse_shared_slices()
- _can_reuse_shared_slices()
- åˆ‡ç‰‡ç®¡ç†ç›¸å…³æ–¹æ³•

### 5. VisionProcessor (æ–°æ–‡ä»¶: grid_vision_processor.py)
- _analyze_slices_with_enhanced_vision()
- Visionåˆ†æç›¸å…³æ–¹æ³•

### 6. ResultMerger (æ–°æ–‡ä»¶: grid_result_merger.py)
- _merge_dual_track_results()
- ç»“æœåˆå¹¶ç›¸å…³æ–¹æ³•
"""
        
        try:
            with open(plan_file, 'w', encoding='utf-8') as f:
                f.write(plan_content)
            self.log_action("åˆ›å»ºé‡æ„è®¡åˆ’", plan_file)
        except Exception as e:
            print(f"âŒ åˆ›å»ºé‡æ„è®¡åˆ’å¤±è´¥: {e}")
    
    def _optimize_dependencies(self):
        """ä¼˜åŒ–ä¾èµ–å…³ç³»"""
        # ç§»é™¤é‡å¤çš„ä¾èµ–ç‰ˆæœ¬
        self.log_action("æ ‡è®°éœ€è¦ä¼˜åŒ–çš„ä¾èµ–", "requirements_actual.txtä¸­æœ‰é‡å¤ç‰ˆæœ¬")
    
    def _generate_clean_requirements(self):
        """ç”Ÿæˆæ¸…ç†åçš„ä¾èµ–æ–‡ä»¶"""
        try:
            os.system("pipreqs app --force --savepath requirements_clean.txt")
            self.log_action("ç”Ÿæˆæ¸…ç†åçš„ä¾èµ–æ–‡ä»¶", "requirements_clean.txt")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆä¾èµ–æ–‡ä»¶å¤±è´¥: {e}")
    
    def execute_full_cleanup(self):
        """æ‰§è¡Œå®Œæ•´çš„æ¸…ç†æµç¨‹"""
        print("ğŸš€ å¼€å§‹æ‰§è¡Œä»£ç æ¸…ç†ç­–ç•¥...")
        
        self.execute_phase_1_static_cleanup()
        self.execute_phase_2_structure_refinement() 
        self.execute_phase_3_dependency_optimization()
        
        print(f"\nğŸ“‹ æ¸…ç†å®Œæˆ! å…±æ‰§è¡Œäº† {len(self.cleanup_log)} ä¸ªæ¸…ç†åŠ¨ä½œ")
        
        # ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
        self._generate_cleanup_report()
    
    def _generate_cleanup_report(self):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        report_content = [
            "# ä»£ç æ¸…ç†æŠ¥å‘Š",
            "",
            f"æ¸…ç†æ—¶é—´: {os.popen('date').read().strip()}",
            f"æ¸…ç†åŠ¨ä½œæ•°é‡: {len(self.cleanup_log)}",
            "",
            "## æ¸…ç†åŠ¨ä½œè¯¦æƒ…",
            ""
        ]
        
        for action in self.cleanup_log:
            report_content.append(f"- {action}")
        
        report_content.extend([
            "",
            "## åç»­æ‰‹åŠ¨æ“ä½œå»ºè®®",
            "",
            "### 1. å¤§æ–‡ä»¶é‡æ„",
            "- å‚è€ƒç”Ÿæˆçš„ *_refactoring_plan.md æ–‡ä»¶",
            "- æŒ‰åŠŸèƒ½æ‹†åˆ† ai_analyzer.py (2178è¡Œ)",
            "- æŒ‰åŠŸèƒ½æ‹†åˆ† enhanced_grid_slice_analyzer.py (2179è¡Œ)",
            "",
            "### 2. ä¾èµ–ä¼˜åŒ–", 
            "- æ£€æŸ¥ requirements_clean.txt",
            "- ç§»é™¤é‡å¤ç‰ˆæœ¬çš„ä¾èµ–",
            "- æµ‹è¯•æ¸…ç†åçš„ä¾èµ–æ˜¯å¦æ»¡è¶³éœ€æ±‚",
            "",
            "### 3. ä»£ç è´¨é‡",
            "- è¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸",
            "- ä½¿ç”¨ black æ ¼å¼åŒ–ä»£ç ",
            "- ä½¿ç”¨ isort æ’åºå¯¼å…¥",
            "",
            "### 4. æ€§èƒ½ä¼˜åŒ–",
            "- æ£€æŸ¥æ˜¯å¦æœ‰å¾ªç¯å¯¼å…¥",
            "- ä¼˜åŒ–å¤§æ–‡ä»¶çš„åŠ è½½æ—¶é—´",
            "- è€ƒè™‘ä½¿ç”¨æ‡’åŠ è½½"
        ])
        
        try:
            with open("cleanup_report.md", 'w', encoding='utf-8') as f:
                f.write('\n'.join(report_content))
            print("ğŸ“„ æ¸…ç†æŠ¥å‘Šå·²ç”Ÿæˆ: cleanup_report.md")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ¸…ç†æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    cleanup = CodeCleanupStrategy()
    cleanup.execute_full_cleanup()

if __name__ == "__main__":
    main() 