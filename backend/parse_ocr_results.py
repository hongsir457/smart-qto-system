#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å»ºç­‘å›¾çº¸OCRç»“æœè§£æå™¨
å°†PaddleOCRè¯†åˆ«ç»“æœè½¬æ¢ä¸ºä¸“ä¸šçš„å»ºç­‘å·¥ç¨‹æ–‡æ¡£æ ¼å¼
"""

import json
import re
from datetime import datetime
from typing import Dict, List, Any

class BuildingDrawingParser:
    """å»ºç­‘å›¾çº¸OCRç»“æœè§£æå™¨"""
    
    def __init__(self, ocr_data: Dict[str, Any]):
        """åˆå§‹åŒ–è§£æå™¨"""
        self.ocr_data = ocr_data
        self.texts = self._extract_texts()
        
    def _extract_texts(self) -> List[str]:
        """æå–æ‰€æœ‰è¯†åˆ«çš„æ–‡æœ¬"""
        texts = []
        for region in self.ocr_data.get('structured_analysis', {}).get('text_regions', []):
            texts.append(region['text'])
        return texts
    
    def parse_project_info(self) -> Dict[str, str]:
        """è§£æé¡¹ç›®åŸºæœ¬ä¿¡æ¯"""
        project_info = {}
        
        # æŸ¥æ‰¾å›¾çº¸åç§°
        for text in self.texts:
            if "å¹³é¢å›¾" in text:
                project_info["å›¾çº¸ç±»å‹"] = text
            elif "1:" in text and text.count(":") == 1:
                project_info["æ¯”ä¾‹"] = text
            elif "æ¥¼å±‚æ ‡å•†è¡¨" in text:
                if "æ¥¼å±‚æ ‡å•†è¡¨" not in project_info:
                    project_info["æ¥¼å±‚æ ‡å•†è¡¨"] = []
                project_info.setdefault("æ¥¼å±‚æ ‡å•†è¡¨", []).append(text)
        
        # ä»å…ƒæ•°æ®è·å–ä¿¡æ¯
        meta = self.ocr_data.get('meta', {})
        project_info["OCRå¤„ç†æ—¶é—´"] = meta.get('ocr_time', '')
        project_info["æ•°æ®æ ¼å¼"] = meta.get('data_format', '')
        project_info["ç³»ç»Ÿç‰ˆæœ¬"] = meta.get('system_version', '')
        
        return project_info
    
    def parse_design_team(self) -> Dict[str, str]:
        """è§£æè®¾è®¡å›¢é˜Ÿä¿¡æ¯"""
        design_team = {}
        
        # å¸¸è§çš„è®¾è®¡äººå‘˜å…³é”®è¯
        design_keywords = ["åˆ¶å›¾", "è®¾è®¡", "æ ¡æ ¸", "å®¡æ ¸", "å®¡æŸ¥"]
        
        for text in self.texts:
            for keyword in design_keywords:
                if keyword in text:
                    design_team[keyword] = text.replace(keyword, "").strip()
        
        # æŸ¥æ‰¾äººåï¼ˆä¸­æ–‡å§“åæ¨¡å¼ï¼‰
        name_pattern = r'[\u4e00-\u9fff]{2,4}'
        for text in self.texts:
            if re.match(name_pattern, text) and len(text) in [2, 3]:
                if text not in ["è®¾è®¡é˜¶æ®µ", "åˆ¶å›¾", "åˆåŒå·"]:
                    design_team.setdefault("ç›¸å…³äººå‘˜", []).append(text)
        
        return design_team
    
    def parse_components(self) -> Dict[str, List[Dict]]:
        """è§£ææ„ä»¶ä¿¡æ¯"""
        components = {
            "æ¡†æ¶æŸ±": [],
            "å…¶ä»–æ„ä»¶": []
        }
        
        # æ¡†æ¶æŸ±ç¼–å·æ¨¡å¼
        column_patterns = [
            r'K-JKZ\d+[a-zA-Z]*',
            r'IK-JKZ\d+[a-zA-Z]*',
            r'K-KZT',
            r'K-JK\d+[a-zA-Z]*'
        ]
        
        for text in self.texts:
            for pattern in column_patterns:
                if re.match(pattern, text):
                    # æŸ¥æ‰¾å¯¹åº”çš„æ–‡æœ¬åŒºåŸŸè·å–ä½ç½®å’Œç½®ä¿¡åº¦
                    for region in self.ocr_data.get('structured_analysis', {}).get('text_regions', []):
                        if region['text'] == text:
                            component = {
                                "ç¼–å·": text,
                                "ç½®ä¿¡åº¦": f"{region['confidence']:.1%}",
                                "ä½ç½®": f"({region['bbox']['center_x']:.0f}, {region['bbox']['center_y']:.0f})",
                                "å°ºå¯¸": f"{region['bbox']['width']:.0f}Ã—{region['bbox']['height']:.0f}"
                            }
                            components["æ¡†æ¶æŸ±"].append(component)
                            break
        
        return components
    
    def parse_materials(self) -> Dict[str, List[str]]:
        """è§£æææ–™ä¿¡æ¯"""
        materials = {
            "æ··å‡åœŸç­‰çº§": [],
            "å…¶ä»–ææ–™": []
        }
        
        for text in self.texts:
            # æ··å‡åœŸç­‰çº§
            if re.match(r'C\d+', text):
                materials["æ··å‡åœŸç­‰çº§"].append(text)
        
        return materials
    
    def parse_dimensions(self) -> List[Dict]:
        """è§£æå°ºå¯¸ä¿¡æ¯"""
        dimensions = []
        
        for region in self.ocr_data.get('structured_analysis', {}).get('text_regions', []):
            text = region['text']
            
            # æŸ¥æ‰¾æ•°å­—ï¼ˆå¯èƒ½çš„å°ºå¯¸ï¼‰
            if region.get('is_number') and len(text) >= 3:
                dimensions.append({
                    "æ•°å€¼": text,
                    "ç½®ä¿¡åº¦": f"{region['confidence']:.1%}",
                    "ä½ç½®": f"({region['bbox']['center_x']:.0f}, {region['bbox']['center_y']:.0f})",
                    "å¯èƒ½ç”¨é€”": self._guess_dimension_purpose(text)
                })
        
        return dimensions
    
    def _guess_dimension_purpose(self, text: str) -> str:
        """æ¨æµ‹å°ºå¯¸ç”¨é€”"""
        try:
            value = int(text)
            if 200 <= value <= 800:
                return "å¯èƒ½ä¸ºæˆªé¢å°ºå¯¸"
            elif 1000 <= value <= 10000:
                return "å¯èƒ½ä¸ºè·¨åº¦æˆ–æ ‡é«˜"
            elif value >= 10000:
                return "å¯èƒ½ä¸ºåæ ‡æˆ–å¤§å°ºå¯¸"
            else:
                return "å…¶ä»–å°ºå¯¸"
        except:
            return "æœªçŸ¥"
    
    def parse_quality_info(self) -> Dict[str, Any]:
        """è§£æOCRè¯†åˆ«è´¨é‡ä¿¡æ¯"""
        stats = self.ocr_data.get('structured_analysis', {}).get('statistics', {})
        integrity = self.ocr_data.get('data_integrity', {})
        
        return {
            "è¯†åˆ«ç»Ÿè®¡": {
                "æ–‡æœ¬æ€»æ•°": stats.get('total_count', 0),
                "æ•°å­—è¯†åˆ«": stats.get('numeric_count', 0),
                "æ„ä»¶ç¼–å·": stats.get('component_code_count', 0),
                "å¹³å‡ç½®ä¿¡åº¦": f"{stats.get('avg_confidence', 0):.1%}"
            },
            "æ•°æ®å®Œæ•´æ€§": {
                "åŸå§‹æ•°æ®ä¿ç•™": integrity.get('original_data_preserved', False),
                "è¾¹æ¡†åæ ‡å¯ç”¨": integrity.get('bbox_coordinates_available', False),
                "ç½®ä¿¡åº¦å¯ç”¨": integrity.get('confidence_scores_available', False),
                "ä¿¡æ¯ä¸¢å¤±ç‡": integrity.get('information_loss', 'æœªçŸ¥')
            }
        }
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Š"""
        project_info = self.parse_project_info()
        design_team = self.parse_design_team()
        components = self.parse_components()
        materials = self.parse_materials()
        dimensions = self.parse_dimensions()
        quality_info = self.parse_quality_info()
        
        report_lines = [
            "# å»ºç­‘ç»“æ„å›¾çº¸OCRè¯†åˆ«ç»“æœæ•´ç†",
            "",
            "## ğŸ“‹ é¡¹ç›®ä¿¡æ¯",
            ""
        ]
        
        for key, value in project_info.items():
            if isinstance(value, list):
                report_lines.append(f"**{key}**: {', '.join(value)}")
            else:
                report_lines.append(f"**{key}**: {value}")
        
        report_lines.extend([
            "",
            "## ğŸ‘¥ è®¾è®¡å›¢é˜Ÿä¿¡æ¯",
            ""
        ])
        
        for key, value in design_team.items():
            if isinstance(value, list):
                report_lines.append(f"**{key}**: {', '.join(value)}")
            else:
                report_lines.append(f"**{key}**: {value}")
        
        report_lines.extend([
            "",
            "## ğŸ—ï¸ æ„ä»¶ä¿¡æ¯",
            ""
        ])
        
        for comp_type, comp_list in components.items():
            if comp_list:
                report_lines.append(f"### {comp_type}")
                report_lines.append("")
                for comp in comp_list:
                    report_lines.append(f"**{comp['ç¼–å·']}**")
                    report_lines.append(f"- ç½®ä¿¡åº¦: {comp['ç½®ä¿¡åº¦']}")
                    report_lines.append(f"- å›¾çº¸ä½ç½®: {comp['ä½ç½®']}")
                    report_lines.append(f"- è¯†åˆ«æ¡†å°ºå¯¸: {comp['å°ºå¯¸']}")
                    report_lines.append("")
        
        report_lines.extend([
            "## ğŸ§± ææ–™ä¿¡æ¯",
            ""
        ])
        
        for mat_type, mat_list in materials.items():
            if mat_list:
                report_lines.append(f"**{mat_type}**: {', '.join(set(mat_list))}")
        
        report_lines.extend([
            "",
            "## ğŸ“ å°ºå¯¸æ•°æ®",
            ""
        ])
        
        # åªæ˜¾ç¤ºå‰10ä¸ªæœ€é‡è¦çš„å°ºå¯¸
        top_dimensions = sorted(dimensions, key=lambda x: float(x['ç½®ä¿¡åº¦'][:-1]), reverse=True)[:10]
        for dim in top_dimensions:
            report_lines.append(f"- **{dim['æ•°å€¼']}** ({dim['ç½®ä¿¡åº¦']}) - {dim['å¯èƒ½ç”¨é€”']}")
        
        report_lines.extend([
            "",
            "## ğŸ“Š OCRè¯†åˆ«è´¨é‡åˆ†æ",
            ""
        ])
        
        stats = quality_info['è¯†åˆ«ç»Ÿè®¡']
        integrity = quality_info['æ•°æ®å®Œæ•´æ€§']
        
        report_lines.extend([
            "### è¯†åˆ«ç»Ÿè®¡",
            f"- è¯†åˆ«æ–‡æœ¬æ€»æ•°: {stats['æ–‡æœ¬æ€»æ•°']}",
            f"- æ•°å­—è¯†åˆ«: {stats['æ•°å­—è¯†åˆ«']}ä¸ª",
            f"- æ„ä»¶ç¼–å·: {stats['æ„ä»¶ç¼–å·']}ä¸ª", 
            f"- å¹³å‡ç½®ä¿¡åº¦: {stats['å¹³å‡ç½®ä¿¡åº¦']}",
            "",
            "### æ•°æ®å®Œæ•´æ€§",
            f"- åŸå§‹æ•°æ®ä¿ç•™: {'âœ…' if integrity['åŸå§‹æ•°æ®ä¿ç•™'] else 'âŒ'}",
            f"- è¾¹æ¡†åæ ‡å¯ç”¨: {'âœ…' if integrity['è¾¹æ¡†åæ ‡å¯ç”¨'] else 'âŒ'}",
            f"- ç½®ä¿¡åº¦å¯ç”¨: {'âœ…' if integrity['ç½®ä¿¡åº¦å¯ç”¨'] else 'âŒ'}",
            f"- ä¿¡æ¯ä¸¢å¤±ç‡: {integrity['ä¿¡æ¯ä¸¢å¤±ç‡']}",
            "",
            "---",
            f"",
            f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}",
            f"**æ•°æ®æ¥æº**: PaddleOCRå®Œæ•´åŸå§‹æ•°æ®",
            f"**å¤„ç†æ–¹å¼**: Aâ†’Cç›´æ¥æ•°æ®æµï¼Œæ— ä¿¡æ¯ä¸¢å¤±"
        ])
        
        return "\n".join(report_lines)

def parse_ocr_file(file_path: str) -> str:
    """è§£æOCRæ–‡ä»¶å¹¶ç”ŸæˆæŠ¥å‘Š"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            ocr_data = json.load(f)
        
        parser = BuildingDrawingParser(ocr_data)
        return parser.generate_report()
        
    except Exception as e:
        return f"è§£ææ–‡ä»¶å¤±è´¥: {str(e)}"

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        file_path = sys.argv[1]
        report = parse_ocr_file(file_path)
        print(report)
    else:
        print("è¯·æä¾›OCRç»“æœJSONæ–‡ä»¶è·¯å¾„")
        print("ç”¨æ³•: python parse_ocr_results.py <json_file_path>") 